{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T08:55:30.523000Z",
     "start_time": "2018-09-28T08:55:30.516000Z"
    }
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T15:20:30.522760Z",
     "start_time": "2018-10-02T15:20:29.671769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from importlib import reload\n",
    "from langdetect import detect\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from dateutil.parser import parse\n",
    "import spacy\n",
    "from time import time\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from commons import elastic\n",
    "from text_processing import text_normalizer\n",
    "text_normalizer = reload(text_normalizer)\n",
    "from text_processing import duplicate_finder\n",
    "from utilities import excel_writer, excel_reader\n",
    "from text_processing import abbreviations_resolver\n",
    "abbreviations_resolver = reload(abbreviations_resolver)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lmtzr = WordNetLemmatizer()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "_abbreviations_resolver = abbreviations_resolver.AbbreviationsResolver([])\n",
    "_abbreviations_resolver.load_model(\"../model/abbreviations_dicts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from text_processing import text_normalizer\n",
    "from interventions_labeling_lib import intervention_labeling\n",
    "from interventions_labeling_lib import usaid_intervention_labels\n",
    "from text_processing import text_normalizer\n",
    "\n",
    "def get_f1_score_test_data(test_data, intervention_labeler):\n",
    "    res_pred, res_prob = intervention_labeler.predict_class(test_data.values, return_probs=True)\n",
    "    res_true = test_data[\"Label\"].values\n",
    "    return f1_score(res_true, res_pred, average=\"macro\")\n",
    "\n",
    "def get_f1_multi_label(test_labels, y_true, max_label=12):\n",
    "    final_res = []\n",
    "    for i in range(len(test_labels)):\n",
    "        identified_labels = set()\n",
    "        for j in range(len(test_labels[0])):\n",
    "            if test_labels[i][j] >= 0.5:\n",
    "                identified_labels.add(j+1)\n",
    "        if not identified_labels:\n",
    "            identified_labels.add(max_label)\n",
    "        final_res.append(identified_labels)\n",
    "    print(len(final_res), len(y_true))\n",
    "    cnt = 0\n",
    "    cnt_precision = 0\n",
    "    cnt_recall = 0\n",
    "    cnt_f1 = 0\n",
    "    cnt_all_found = 0\n",
    "    for idx, res in enumerate(y_true):\n",
    "        cnt += 1\n",
    "        cnt_intersect = len(y_true[idx].intersection(final_res[idx]))\n",
    "        cnt_correct = len(y_true[idx])\n",
    "        cnt_found = len(final_res[idx])\n",
    "        precision = 0 if cnt_found == 0 else (cnt_intersect/cnt_found)\n",
    "        recall = 0 if cnt_correct == 0 else (cnt_intersect/cnt_correct)\n",
    "        f1 = 0\n",
    "        if (precision + recall) > 0:\n",
    "            f1 = 2*precision*recall/(precision + recall)\n",
    "        cnt_precision += precision\n",
    "        cnt_recall += recall\n",
    "        if recall > 0.99:\n",
    "            cnt_all_found += 1\n",
    "        cnt_f1 += f1\n",
    "    return cnt_f1/cnt\n",
    "\n",
    "def get_accuracy_multi_label(test_labels, y_true, max_label=12):\n",
    "    final_res = []\n",
    "    for i in range(len(test_labels)):\n",
    "        identified_labels = set()\n",
    "        for j in range(len(test_labels[0])):\n",
    "            if test_labels[i][j] >= 0.5:\n",
    "                identified_labels.add(j+1)\n",
    "        if not identified_labels:\n",
    "            identified_labels.add(max_label)\n",
    "        final_res.append(identified_labels)\n",
    "    cnt = 0\n",
    "    cnt_precision = 0\n",
    "    cnt_recall = 0\n",
    "    cnt_f1 = 0\n",
    "    cnt_all_found = 0\n",
    "    for idx, res in enumerate(y_true):\n",
    "        cnt += 1\n",
    "        cnt_intersect = len(y_true[idx].intersection(final_res[idx]))\n",
    "        cnt_correct = len(y_true[idx])\n",
    "        cnt_found = len(final_res[idx])\n",
    "        precision = 0 if cnt_found == 0 else (1 if cnt_intersect > 0 else 0)\n",
    "        recall = 0 if cnt_correct == 0 else (1 if cnt_intersect > 0 else 0)\n",
    "        f1 = 0\n",
    "        if (precision + recall) > 0:\n",
    "            f1 = 2*precision*recall/(precision + recall)\n",
    "        cnt_precision += precision\n",
    "        cnt_recall += recall\n",
    "        if recall > 0.99:\n",
    "            cnt_all_found += 1\n",
    "        cnt_f1 += f1\n",
    "    return cnt_f1/cnt\n",
    "\n",
    "def normalize_full(text):\n",
    "    return \" \".join(sorted(text_normalizer.normalize_sentence(text).split(\" \")))\n",
    "\n",
    "def deduplicate(dfs):\n",
    "    dicts = {}\n",
    "    deduplicated_df_data = []\n",
    "    for df in dfs:\n",
    "        for i in range(len(df)):\n",
    "            processed = normalize_full(df[\"Narrow concept\"].values[i])\n",
    "            if processed not in dicts:\n",
    "                dicts[processed] = set()\n",
    "                deduplicated_df_data.append(\n",
    "                    (df[\"Narrow concept\"].values[i], df[\"Broad concepts\"].values[i], df[\"Label\"].values[i]))\n",
    "            dicts[processed].add(df[\"Label\"].values[i])\n",
    "    return dicts, pd.DataFrame(deduplicated_df_data, columns=[\"Narrow concept\", \"Broad concepts\", \"Label\"])\n",
    "\n",
    "def print_per_label_stats(test_res, res_label):\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1_score_ = 0.0\n",
    "    total_cnt = 0\n",
    "    for idx, label in enumerate(labels):\n",
    "        print(label)\n",
    "        test_y = [1 if (idx+1) in test_res[i] else 0 for i in range(len(test_res))]\n",
    "        res_y = [res_label[i][idx] for i in range(len(test_res))]\n",
    "        _outcomes_sentence_labeler.print_summary(test_y, res_y)\n",
    "        f1_score_ += f1_score(test_y, res_y, average=\"macro\")\n",
    "        total_cnt += 1\n",
    "    print(\"Average \", f1_score_/total_cnt if total_cnt > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USAID interventions\n",
    "Generate files to label interventions manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pool of sentences to generate from\n",
    "If you already have one, you don't need to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/new_df_usaid_all.xlsx: 62.80s\n",
      "Processed file ../tmp/new_df_usaid_all.xlsx: 87.33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59216"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/new_df_usaid_all.xlsx\")\n",
    "len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129431"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "new_df_values = []\n",
    "for i in range(len(df_1)):\n",
    "    for sent in [s for s in sent_tokenize(df_1[\"abstract\"].values[i]) if \"?\" not in s]:\n",
    "        new_df_values.append(sent)\n",
    "new_df = pd.DataFrame(new_df_values, columns=[\"abstract\"])\n",
    "new_df[\"title\"] = \"\"\n",
    "new_df[\"keywords\"] = \"\"\n",
    "new_df[\"identificators\"] = \"\"\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 articles\n",
      "Processed 20000 articles\n",
      "Processed 40000 articles\n",
      "Processed 60000 articles\n",
      "Processed 80000 articles\n",
      "Processed 100000 articles\n",
      "Processed 120000 articles\n",
      "Processed 129430 articles\n",
      "Processed 0 abbreviations\n"
     ]
    }
   ],
   "source": [
    "from text_processing import search_engine_insensitive_to_spelling\n",
    "search_engine_insensitive_to_spelling = reload(search_engine_insensitive_to_spelling)\n",
    "\n",
    "search_engine_inverted_index = search_engine_insensitive_to_spelling.SearchEngineInsensitiveToSpelling(load_abbreviations = True)\n",
    "search_engine_inverted_index.create_inverted_index(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing  {'column_filler_class': 'ColumnFiller', 'column_name': 'water_interventions', 'column_details': 'water_interventions_details', 'column_dictionary': '../tmp/usaid_water/train_data.xlsx', 'high_level_label_column': 'Label', 'keyword_column': 'Narrow concept'}\n",
      "High level label: Non-intervention\n",
      "High level label: Sanitation/Hygiene\n",
      "High level label: Water quality/Human health\n",
      "High level label: Water infrastructure\n",
      "High level label: Sustainability/Environmental health\n",
      "Labelled articles with outcomes: 20104\n",
      "Processed for 5.282998085021973s\n"
     ]
    }
   ],
   "source": [
    "from text_processing import column_filler\n",
    "column_filler = reload(column_filler)\n",
    "from text_processing import all_column_filler\n",
    "all_column_filler = reload(all_column_filler)\n",
    "\n",
    "\n",
    "_all_column_filler = all_column_filler.AllColumnFiller()\n",
    "new_df = _all_column_filler.fill_columns_for_df(new_df, search_engine_inverted_index, _abbreviations_resolver,settings_json = {\"columns\":[\n",
    "     {\"column_filler_class\":\"ColumnFiller\", \"column_name\": \"water_interventions\", \"column_details\": \"water_interventions_details\",\n",
    "      \"column_dictionary\":\"../tmp/usaid_water/train_data.xlsx\", \"high_level_label_column\": \"Label\", \"keyword_column\": \"Narrow concept\"},\n",
    "    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to ../tmp/usaid_interv_all_sentences.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(new_df, \"../tmp/usaid_interv_all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a file to label manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_interv_all_sentences.xlsx: 35.93s\n",
      "Processed file ../tmp/usaid_interv_all_sentences.xlsx: 56.35s\n"
     ]
    }
   ],
   "source": [
    "new_df = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_interv_all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df[new_df[\"Taken\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitation/Hygiene 50\n",
      "Water quality/Human health 50\n",
      "Water infrastructure 50\n",
      "Sustainability/Environmental health 30\n",
      "Community and behavior 0\n",
      "Policy 0\n",
      "Assessment tool or program 0\n"
     ]
    }
   ],
   "source": [
    "taken_inds = []\n",
    "taken_words = {}\n",
    "sentences_taken = []\n",
    "classes = [\"Sanitation/Hygiene\", \"Water quality/Human health\", \"Water infrastructure\", \"Sustainability/Environmental health\",\n",
    "          \"Community and behavior\", \"Policy\", \"Assessment tool or program\"]\n",
    "for label in classes:\n",
    "    cnt_label = 0\n",
    "    for i in range(len(new_df)):\n",
    "        if cnt_label >= 50:\n",
    "            break\n",
    "        if label in new_df[\"water_interventions\"].values[i] and i not in taken_inds and new_df[\"Taken\"].values[i] == 0:\n",
    "            if label not in taken_words:\n",
    "                taken_words[label] = set()\n",
    "            if len(set(new_df[\"water_interventions_details\"].values[i]) - taken_words[label]) > 0 or label in [\"Community and behavior\", \"Policy\", \"Assessment tool or program\"]:\n",
    "                taken_inds.append(i)\n",
    "                taken_words[label].update(new_df[\"water_interventions_details\"].values[i])\n",
    "                sentences_taken.append(\n",
    "                    (new_df[\"abstract\"].values[i], new_df[\"water_interventions\"].values[i], new_df[\"water_interventions_details\"].values[i]))\n",
    "                cnt_label += 1\n",
    "    print(label, cnt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taken_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in taken_inds:\n",
    "    new_df[\"Taken\"].values[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to test_usaid_1625752952.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(\n",
    "    pd.concat([pd.DataFrame(sentences_taken, columns=[\"Sentence\", \"water_interventions\", \"water_interventions_details\"]),\n",
    "               pd.DataFrame([[\"\"]*len(classes)]*len(taken_inds), columns=classes)], axis=1), f\"test_usaid_{int(time())}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(new_df, \"../tmp/usaid_interv_all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BERT model for interventions\n",
    "Classification model is trained via BERT. Extraction model is trained via NER Spacy custom model training, you can use \"../scripts/train_NER.py\" to train the extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_water\\additionally_labelled_low_prob.xlsx: 0.07s\n",
      "Processed file ../tmp/usaid_water\\additionally_labelled_low_prob.xlsx: 0.03s\n",
      "Read file ../tmp/usaid_water\\data_labeled_sample_USAID.xlsx: 0.08s\n",
      "Processed file ../tmp/usaid_water\\data_labeled_sample_USAID.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_water\\data_sample_to_label_JP.xlsx: 0.06s\n",
      "Processed file ../tmp/usaid_water\\data_sample_to_label_JP.xlsx: 0.02s\n",
      "Read file ../tmp/usaid_water\\interv_data_train_data.xlsx: 0.43s\n",
      "Processed file ../tmp/usaid_water\\interv_data_train_data.xlsx: 0.15s\n",
      "Read file ../tmp/usaid_water\\interv_from_sentences.xlsx: 1.15s\n",
      "Processed file ../tmp/usaid_water\\interv_from_sentences.xlsx: 0.68s\n",
      "Read file ../tmp/usaid_water\\PA00JQVN_labeled_non_intervention.xlsx: 0.03s\n",
      "Processed file ../tmp/usaid_water\\PA00JQVN_labeled_non_intervention.xlsx: 0.00s\n",
      "Read file ../tmp/usaid_water\\part_sentences_model_check_Jaron.xlsx: 0.05s\n",
      "Processed file ../tmp/usaid_water\\part_sentences_model_check_Jaron.xlsx: 0.02s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6318"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interventions_labeling_lib import usaid_intervention_labels\n",
    "\n",
    "train_df = excel_reader.ExcelReader().read_folder(\"../tmp/usaid_water\")\n",
    "train_df[\"Label\"] = [usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_LABEL_TO_NUMBER[train_df[\"Label\"].values[i]] for i in range(len(train_df))]\n",
    "deduplicated2labels, train_df = deduplicate([train_df])\n",
    "print(train_df[\"Label\"].value_counts())\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_ind, x_test_ind, y_train, y_test = train_test_split(\n",
    "            train_df.drop(\"Label\", axis=1), train_df[\"Label\"].values,\n",
    "            test_size=0.1, random_state=1541, stratify=train_df[\"Label\"].values)\n",
    "train_data = pd.concat([x_train_ind.reset_index(drop=True), pd.DataFrame({\"Label\": y_train})], axis=1)\n",
    "test_data = pd.concat([x_test_ind.reset_index(drop=True), pd.DataFrame({\"Label\": y_test})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5686, 632)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5914"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fecal sludge management and MHM classes don't have enough training data, so we duplicate it\n",
    "from sklearn.utils import shuffle\n",
    "for _class in [usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_LABEL_TO_NUMBER[\"Fecal sludge management\"],\n",
    "               usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_LABEL_TO_NUMBER[\"Menstrual hygiene management\"],]:\n",
    "    train_data = pd.concat([train_data, train_data[train_data[\"Label\"] == _class], train_data[train_data[\"Label\"] == _class]],axis=0)\n",
    "train_data = shuffle(train_data)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 17:07:30.915246 140185830987584 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 17:07:31.246259 140185830987584 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:32.516058 140185830987584 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_usaid_interventions_multi_label_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7e56077908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.322794 140185830987584 estimator.py:201] Using config: {'_model_dir': '../model/bert_usaid_interventions_multi_label_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7e56077908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n",
      "INFO:tensorflow:Writing example 0 of 632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.533284 140185830987584 base_bert_model.py:478] Writing example 0 of 632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.534377 140185830987584 base_bert_model.py:454] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.535042 140185830987584 base_bert_model.py:455] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] funding streams [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.536281 140185830987584 base_bert_model.py:457] tokens: [CLS] funding streams [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4804 9199 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.537222 140185830987584 base_bert_model.py:458] input_ids: 101 4804 9199 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.537961 140185830987584 base_bert_model.py:459] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.538646 140185830987584 base_bert_model.py:460] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.539069 140185830987584 base_bert_model.py:461] label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.539674 140185830987584 base_bert_model.py:454] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.540094 140185830987584 base_bert_model.py:455] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] foster transparent wash sector multi - stake ##holder leadership [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.540511 140185830987584 base_bert_model.py:457] tokens: [CLS] foster transparent wash sector multi - stake ##holder leadership [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6469 13338 9378 4753 4800 1011 8406 14528 4105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.540946 140185830987584 base_bert_model.py:458] input_ids: 101 6469 13338 9378 4753 4800 1011 8406 14528 4105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.541396 140185830987584 base_bert_model.py:459] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.541843 140185830987584 base_bert_model.py:460] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.542265 140185830987584 base_bert_model.py:461] label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.542784 140185830987584 base_bert_model.py:454] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.543201 140185830987584 base_bert_model.py:455] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] trench [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.543606 140185830987584 base_bert_model.py:457] tokens: [CLS] trench [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 14185 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.544049 140185830987584 base_bert_model.py:458] input_ids: 101 14185 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.544490 140185830987584 base_bert_model.py:459] input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.544940 140185830987584 base_bert_model.py:460] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.545372 140185830987584 base_bert_model.py:461] label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.545909 140185830987584 base_bert_model.py:454] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.546330 140185830987584 base_bert_model.py:455] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] point of use treatment device [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.546734 140185830987584 base_bert_model.py:457] tokens: [CLS] point of use treatment device [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2391 1997 2224 3949 5080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.547180 140185830987584 base_bert_model.py:458] input_ids: 101 2391 1997 2224 3949 5080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.547614 140185830987584 base_bert_model.py:459] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.548056 140185830987584 base_bert_model.py:460] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.548463 140185830987584 base_bert_model.py:461] label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.548947 140185830987584 base_bert_model.py:454] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.549345 140185830987584 base_bert_model.py:455] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] hygiene [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.549746 140185830987584 base_bert_model.py:457] tokens: [CLS] hygiene [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.550363 140185830987584 base_bert_model.py:458] input_ids: 101 19548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.550838 140185830987584 base_bert_model.py:459] input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.551312 140185830987584 base_bert_model.py:460] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.551737 140185830987584 base_bert_model.py:461] label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:33.964153 140185830987584 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:35.742893 140185830987584 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:35.824156 140185830987584 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:36.412026 140185830987584 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 17:07:36.414336 140185830987584 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/bert_usaid_interventions_multi_label_3/model.ckpt-1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:36.418555 140185830987584 saver.py:1270] Restoring parameters from ../model/bert_usaid_interventions_multi_label_3/model.ckpt-1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:37.064754 140185830987584 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0712 17:07:37.128101 140185830987584 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632 632\n",
      "F1 measure:  0.7521097046413512\n",
      "Accuracy:  0.7943037974683544\n"
     ]
    }
   ],
   "source": [
    "from bert_models import base_bert_model\n",
    "base_bert_model = reload(base_bert_model)\n",
    "from bert_models import base_bert_model_interventions\n",
    "base_bert_model_interventions = reload(base_bert_model_interventions)\n",
    "\n",
    "common_folder = \"../model/bert_usaid_interventions_multi_label_3\"\n",
    "_intervention_labeler = base_bert_model_interventions.BaseBertModelInterventions(\n",
    "    common_folder,\n",
    "    [0 for i in range(11)], label_column=\"label\",\n",
    "    multilabel=True\n",
    ")\n",
    "\n",
    "def prepare_labelled_data(train_data):\n",
    "    train_copy = train_data.copy()\n",
    "    train_copy[\"label\"] = \"\"\n",
    "    for i in range(len(train_copy)):\n",
    "        real_labels = deduplicated2labels[normalize_full(train_copy[\"Narrow concept\"].values[i])]\n",
    "        real_labels_idx = []\n",
    "        for idx in range(1, 12):\n",
    "            real_labels_idx.append(int(idx in real_labels))\n",
    "        train_copy[\"label\"].values[i] = real_labels_idx\n",
    "    return train_copy\n",
    "\n",
    "train_copy = prepare_labelled_data(train_data)\n",
    "test_copy = prepare_labelled_data(test_data)\n",
    "\n",
    "_intervention_labeler.train_model(train_copy, test_copy)\n",
    "\n",
    "res_prob, res_label, _ = _intervention_labeler.predict_for_df(test_copy)\n",
    "\n",
    "print(\"F1 measure: \", get_f1_multi_label(res_prob, [deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[i])] for i in range(len(test_data))]))\n",
    "print(\"Accuracy: \",get_accuracy_multi_label(res_prob, [deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[i])] for i in range(len(test_data))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water infrastructure\n",
      "[[523  12]\n",
      " [ 32  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       535\n",
      "           1       0.84      0.67      0.75        97\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       632\n",
      "   macro avg       0.89      0.82      0.85       632\n",
      "weighted avg       0.93      0.93      0.93       632\n",
      "\n",
      "Sanitation/Hygiene\n",
      "[[551   8]\n",
      " [ 16  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       559\n",
      "           1       0.88      0.78      0.83        73\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       632\n",
      "   macro avg       0.92      0.88      0.90       632\n",
      "weighted avg       0.96      0.96      0.96       632\n",
      "\n",
      "Fecal sludge management\n",
      "[[626   0]\n",
      " [  0   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       626\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       632\n",
      "   macro avg       1.00      1.00      1.00       632\n",
      "weighted avg       1.00      1.00      1.00       632\n",
      "\n",
      "Menstrual hygiene management\n",
      "[[624   0]\n",
      " [  1   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       624\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       632\n",
      "   macro avg       1.00      0.94      0.97       632\n",
      "weighted avg       1.00      1.00      1.00       632\n",
      "\n",
      "Water quality\n",
      "[[583   5]\n",
      " [ 13  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       588\n",
      "           1       0.86      0.70      0.78        44\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       632\n",
      "   macro avg       0.92      0.85      0.88       632\n",
      "weighted avg       0.97      0.97      0.97       632\n",
      "\n",
      "Human health\n",
      "[[584   9]\n",
      " [  6  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       593\n",
      "           1       0.79      0.85      0.81        39\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       632\n",
      "   macro avg       0.89      0.92      0.90       632\n",
      "weighted avg       0.98      0.98      0.98       632\n",
      "\n",
      "Sustainability/Environmental health\n",
      "[[556   6]\n",
      " [ 18  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       562\n",
      "           1       0.90      0.74      0.81        70\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       632\n",
      "   macro avg       0.93      0.87      0.90       632\n",
      "weighted avg       0.96      0.96      0.96       632\n",
      "\n",
      "Community and behavior\n",
      "[[517  28]\n",
      " [ 28  59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       545\n",
      "           1       0.68      0.68      0.68        87\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       632\n",
      "   macro avg       0.81      0.81      0.81       632\n",
      "weighted avg       0.91      0.91      0.91       632\n",
      "\n",
      "Assessment tool or program\n",
      "[[576   9]\n",
      " [ 13  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       585\n",
      "           1       0.79      0.72      0.76        47\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       632\n",
      "   macro avg       0.88      0.85      0.87       632\n",
      "weighted avg       0.96      0.97      0.96       632\n",
      "\n",
      "Policy\n",
      "[[518  23]\n",
      " [ 24  67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       541\n",
      "           1       0.74      0.74      0.74        91\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       632\n",
      "   macro avg       0.85      0.85      0.85       632\n",
      "weighted avg       0.93      0.93      0.93       632\n",
      "\n",
      "Agriculture\n",
      "[[517  12]\n",
      " [ 21  82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       529\n",
      "           1       0.87      0.80      0.83       103\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       632\n",
      "   macro avg       0.92      0.89      0.90       632\n",
      "weighted avg       0.95      0.95      0.95       632\n",
      "\n",
      "Average F1 per class:  0.8936120192403039\n"
     ]
    }
   ],
   "source": [
    "from interventions_labeling_lib import usaid_intervention_labels\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "average_f1_score = 0\n",
    "for i in range(11):\n",
    "    print(usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL[i+1])\n",
    "    pred = []\n",
    "    for j in range(len(test_copy)):\n",
    "        if res_prob[j][i] >= 0.5:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    real_label = []\n",
    "    for j in range(len(test_copy)):\n",
    "        if (i+1) in deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[j])]:\n",
    "            real_label.append(1)\n",
    "        else:\n",
    "            real_label.append(0)\n",
    "    print(confusion_matrix(real_label,pred))\n",
    "    print(classification_report(real_label, pred))\n",
    "    average_f1_score += f1_score(real_label, pred, average=\"macro\")\n",
    "\n",
    "print(\"Average F1 per class: \", average_f1_score/11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend the dictionary for strategy focus keywords\n",
    "Run this if you want to regrenerate dictionary in case you added new keywords, or removed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synonyms_module import synonyms_processor\n",
    "\n",
    "_synonyms = synonyms_processor.SynonymsProcessor(\"../model/synonyms_usaid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_files/words_synonyms.xlsx: 0.04s\n",
      "Processed file ../tmp/usaid_files/words_synonyms.xlsx: 0.02s\n"
     ]
    }
   ],
   "source": [
    "syn_dict = {}\n",
    "df_syn = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_files/words_synonyms.xlsx\")\n",
    "for i in range(len(df_syn)):\n",
    "    w = df_syn[\"Word\"].values[i].strip()\n",
    "    syn = df_syn[\"Synonym\"].values[i].strip()\n",
    "    if w not in syn_dict:\n",
    "        syn_dict[w] = []\n",
    "    syn_dict[w].append(syn)\n",
    "\n",
    "def find_all_synonyms(word):\n",
    "    if word in syn_dict:\n",
    "        return syn_dict[word] + [word]\n",
    "    print(\"Word to find \", word)\n",
    "    return _synonyms.find_synonyms(_synonyms.google_2_and_3_bigrams_model,word,n_words=10) + [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_files/strategic_approaches.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_files/strategic_approaches.xlsx: 0.00s\n"
     ]
    }
   ],
   "source": [
    "df_strategic = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_files/strategic_approaches.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subexpressions(expression):\n",
    "    words = [w.strip() for w in expression.split() if w.strip()]\n",
    "    generated_words = []\n",
    "    if not words:\n",
    "        return []\n",
    "    for i in range(min(3, len(words))):\n",
    "        if len(words[i+1:]):\n",
    "            results = generate_subexpressions(\" \".join(words[i+1:]))\n",
    "            for _l in results:\n",
    "                result = [\" \".join(words[:i+1])] + _l\n",
    "                generated_words.append(result)\n",
    "        else:\n",
    "            generated_words.append([\" \".join(words[:i+1])])\n",
    "    return generated_words\n",
    "\n",
    "def extend_query(words, sep=\" \", func=find_all_synonyms):\n",
    "    prev_set = func(words[0])\n",
    "    for i in range(1, len(words)):\n",
    "        new_set = set()\n",
    "        for word in func(words[i]):\n",
    "            for prev_exp in prev_set:\n",
    "                new_set.add(prev_exp + sep + word)\n",
    "        prev_set = new_set\n",
    "    return prev_set\n",
    "\n",
    "def find_synonymic_phrases(word_phrase):\n",
    "    new_words = set()\n",
    "    for w_ph in generate_subexpressions(word_phrase):\n",
    "        new_words.update(extend_query(w_ph))\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to ../tmp/usaid_files/strategic_approaches_extended.xlsx\n"
     ]
    }
   ],
   "source": [
    "new_words = []\n",
    "new_words_set = set()\n",
    "for i in range(len(df_strategic)):\n",
    "    new_words.append((df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                     df_strategic[\"Keyword\"].values[i],\n",
    "                     df_strategic[\"High level label\"].values[i],\n",
    "                     1))\n",
    "    if \";\" in df_strategic[\"Keyword\"].values[i]:\n",
    "        for w in extend_query(\n",
    "                df_strategic[\"Keyword\"].values[i].split(\";\"), sep=\";\", func=lambda x: extend_query(x.split(), sep=\" \", func = find_all_synonyms)):\n",
    "            if (df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                     w,\n",
    "                     df_strategic[\"High level label\"].values[i],\n",
    "                     0) not in new_words_set:\n",
    "                new_words.append((df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                         w,\n",
    "                         df_strategic[\"High level label\"].values[i],\n",
    "                         0))\n",
    "                new_words_set.add((df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                     w,\n",
    "                     df_strategic[\"High level label\"].values[i],\n",
    "                     0))\n",
    "    else:\n",
    "        for new_phrase in extend_query(df_strategic[\"Keyword\"].values[i].split(), sep=\" \", func = find_all_synonyms):\n",
    "            if (df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                     new_phrase,\n",
    "                     df_strategic[\"High level label\"].values[i],\n",
    "                     0) not in new_words_set:\n",
    "                new_words.append((df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                         new_phrase,\n",
    "                         df_strategic[\"High level label\"].values[i],\n",
    "                         0))\n",
    "                new_words_set.add((df_strategic[\"Intervention label in sentence\"].values[i],\n",
    "                     new_phrase,\n",
    "                     df_strategic[\"High level label\"].values[i],\n",
    "                     0))\n",
    "excel_writer.ExcelWriter().save_data_in_excel(new_words, [\"Intervention label in sentence\", \"Keyword\", \"High level label\", \"Manual keyword\"],\n",
    "                                              \"../tmp/usaid_files/strategic_approaches_extended.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the file with metadata about pdfs we are parsing and processing\n",
    "If you have already the file \"../tmp/usaid_files/usaid_pdfs_meta.xlsx\", you don't need to run this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_files/subset_usaid_pdfs.xlsx: 0.18s\n",
      "Processed file ../tmp/usaid_files/subset_usaid_pdfs.xlsx: 0.18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Access Type', 'Ancillary_Data', 'Art. No.', 'Author(s) ID', 'Authors',\n",
       "       'Bibliographic_Type', 'Cited by', 'ContentType',\n",
       "       'Contract_Grant_Number', 'Column A', 'Credit', 'Description',\n",
       "       'Descriptors_Geographic', 'Descriptors_Topical',\n",
       "       'Digital_Object_Identifier', 'Document Type', 'EID',\n",
       "       'Evaluated_AID_Contract_Num', 'File', 'File_Size', 'Funding Details',\n",
       "       'Funding Text 1', 'Funding Text 2', 'Inst_Author', 'Inst_Publisher',\n",
       "       'Inst_Sponsor', 'Issue', 'Language', 'Mime_Type', 'New_Thesaurus_Terms',\n",
       "       'Notes', 'Page count', 'Page end', 'Page start', 'Personal_Author',\n",
       "       'Primary_Subject', 'Publication Stage', 'Publication_Date_Freeform',\n",
       "       'Related_Doc_Links', 'Report_Number', 'Series_Title', 'Source',\n",
       "       'Source title', 'Title_Translated', 'URI', 'USAID_Geography',\n",
       "       'USAID_Project_Number', 'Unique_ID', 'Volume', 'abstract',\n",
       "       'affiliation', 'article_name', 'authors', 'identificators',\n",
       "       'journal_name', 'keywords', 'publisher', 'source_name', 'title',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_files/subset_usaid_pdfs.xlsx\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file C4W_dataset_from_the_DEC_pdf.xlsx: 0.82s\n",
      "Processed file C4W_dataset_from_the_DEC_pdf.xlsx: 0.65s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'LEGEND', 'Priority geography', 'title', 'Ancillary_Data',\n",
       "       'Bibliographic_Type', 'Contract_Grant_Number', 'Descriptors_Geographic',\n",
       "       'Descriptors_Topical', 'Inst_Author', 'Inst_Sponsor', 'Issue',\n",
       "       'Language', 'Primary_Subject', 'Publication_Date_Freeform', 'URI',\n",
       "       'Unique_ID', 'keywords', 'year', 'Unnamed: 18', 'Unnamed: 19',\n",
       "       'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23',\n",
       "       'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26',\n",
       "       'Compared to asked about grants', 'pdf_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = excel_reader.ExcelReader().read_df_from_excel(\"C4W_dataset_from_the_DEC_pdf.xlsx\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind_to_take = []\n",
    "for i in range(len(df)):\n",
    "    if \"marked for inclusion\" in df[\"Priority geography\"].values[i].lower():\n",
    "        df_ind_to_take.append(i)\n",
    "df = df.take(df_ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    for column in [\"Personal_Author\", \"Inst_Author\", \"Inst_Sponsor\", 'Ancillary_Data', \"Contract_Grant_Number\", \"Descriptors_Geographic\", \"Descriptors_Topical\", \"USAID_Geography\", \"New_Thesaurus_Terms\"]:\n",
    "        if column in df.columns:\n",
    "            df[column].values[i] = df[column].values[i].replace(\"~|~_©_~|~\", \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"url\"] = df[\"URI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if not df[\"authors\"].values[i].strip():\n",
    "        df[\"authors\"].values[i] = df[\"Personal_Author\"].values[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"affiliation\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    if not df[\"affiliation\"].values[i].strip():\n",
    "        df[\"affiliation\"].values[i] = df[\"Inst_Author\"].values[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keywords\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    all_keywords = set()\n",
    "    for column in [\"Descriptors_Geographic\", \"Descriptors_Topical\", \"USAID_Geography\", \"New_Thesaurus_Terms\"]:\n",
    "        if column in df.columns:\n",
    "            for a in df[column].values[i].split(\";\"):\n",
    "                if a.strip():\n",
    "                    all_keywords.add(a.strip())\n",
    "    df[\"keywords\"].values[i] = \" ; \".join(list(all_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"File\"] = df[\"pdf_link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_columns = ['Ancillary_Data', \"Bibliographic_Type\", \"Contract_Grant_Number\", \"Inst_Sponsor\",\n",
    "                     \"Primary_Subject\", \"Unique_ID\", \n",
    "                     \"affiliation\", \"authors\", 'identificators', 'File',\n",
    "                     'journal_name', 'keywords', 'publisher', 'source_name', 'title', 'year',\n",
    "                     'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[necessary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    for column in [\"Bibliographic_Type\", \"Inst_Sponsor\", \"Primary_Subject\", \"affiliation\", \"Contract_Grant_Number\"]:\n",
    "        df[column].values[i] = [a for a in df[column].values[i].split(\";\") if a.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing.author_normalizer import AuthorNormalizer\n",
    "authors, affiliations = AuthorNormalizer().normalize_authors(df[\"authors\"].values)\n",
    "df[\"author\"] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to ../tmp/usaid_files/usaid_pdfs_meta_additional.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(df, \"../tmp/usaid_files/usaid_pdfs_meta_additional.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_files/usaid_pdfs_meta.xlsx: 0.13s\n",
      "Processed file ../tmp/usaid_files/usaid_pdfs_meta.xlsx: 0.14s\n",
      "Read file ../tmp/usaid_files/usaid_pdfs_meta_additional.xlsx: 0.05s\n",
      "Processed file ../tmp/usaid_files/usaid_pdfs_meta_additional.xlsx: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in [\"usaid_pdfs_meta.xlsx\", \"usaid_pdfs_meta_additional.xlsx\"]:\n",
    "    df = pd.concat([df, excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_files/\" + file)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to ../tmp/usaid_files/usaid_pdfs_meta.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(df, \"../tmp/usaid_files/usaid_pdfs_meta.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process pdf data\n",
    "The pdf data should be turned into excel files beforehand using scripts/parse_pdf.py using textract(ensure you installed) and so in the folder \"../tmp/parsed_pdfs\" will be excel files with texts from pdfs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the file with meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_files/usaid_pdfs_meta.xlsx: 0.17s\n",
      "Processed file ../tmp/usaid_files/usaid_pdfs_meta.xlsx: 0.14s\n"
     ]
    }
   ],
   "source": [
    "df_1 = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/usaid_files/usaid_pdfs_meta.xlsx\")\n",
    "dict_file = {}\n",
    "for i in range(len(df_1)):\n",
    "    pdf_name = os.path.basename(df_1[\"File\"].values[i]).split(\".\")[0].strip()\n",
    "    article_name = df_1[\"article_name\"].values[i].strip()\n",
    "    if pdf_name:\n",
    "        dict_file[pdf_name] = i\n",
    "    if article_name:\n",
    "        dict_file[article_name] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract interventions and classify from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_usaid_interventions_multi_label_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000228E7109A20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_usaid_interventions_multi_label_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000228E7109A20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n",
      "XDABD534A.xlsx\n",
      "Read file ../tmp/parsed_pdfs\\XDABD534A.xlsx: 0.03s\n",
      "Processed file ../tmp/parsed_pdfs\\XDABD534A.xlsx: 0.01s\n",
      "INFO:tensorflow:Writing example 0 of 1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] cloud computing climate data ( cc ##cd ) program [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] cloud computing climate data ( cc ##cd ) program [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6112 9798 4785 2951 1006 10507 19797 1007 2565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6112 9798 4785 2951 1006 10507 19797 1007 2565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] disease control ( dc ) center ( cdc ) [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] disease control ( dc ) center ( cdc ) [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4295 2491 1006 5887 1007 2415 1006 26629 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4295 2491 1006 5887 1007 2415 1006 26629 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] science technology s t project c management system [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] science technology s t project c management system [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2671 2974 1055 1056 2622 1039 2968 2291 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2671 2974 1055 1056 2622 1039 2968 2291 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] monitoring supervision [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] monitoring supervision [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8822 10429 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8822 10429 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] intervention support strategy [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] intervention support strategy [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8830 2490 5656 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8830 2490 5656 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/bert_usaid_interventions_multi_label_3\\model.ckpt-1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/bert_usaid_interventions_multi_label_3\\model.ckpt-1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed time: 1074.32 s\n",
      "Saving...\n",
      "Saved to ../tmp/parsed_pdfs_extracted\\XDABD534A.xlsx\n"
     ]
    }
   ],
   "source": [
    "from interventions_labeling_lib.usaid_intervention_labels import USAIDInterventionLabels\n",
    "from bert_models import base_bert_model\n",
    "base_bert_model = reload(base_bert_model)\n",
    "from bert_models import base_bert_model_interventions\n",
    "base_bert_model_interventions = reload(base_bert_model_interventions)\n",
    "\n",
    "_intervention_labeler = base_bert_model_interventions.BaseBertModelInterventions(\n",
    "    \"../model/bert_usaid_interventions_multi_label_3\",\n",
    "    [0 for i in range(11)], label_column=\"label\",\n",
    "    multilabel=True\n",
    ")\n",
    "ner_model = spacy.load(\"../model/usaid_entity-recognition-model-more-3012-169_iter\")\n",
    "\n",
    "#if you have summarized folders\n",
    "#folders_to_process = [(\"../tmp/parsed_pdfs_bart\", \"../tmp/parsed_pdfs_bart_extracted\"),\n",
    "#                      (\"../tmp/parsed_pdfs_longformer\", \"../tmp/parsed_pdfs_longformer_extracted\")]\n",
    "folders_to_process = [(\"../tmp/parsed_pdfs\", \"../tmp/parsed_pdfs_extracted\")]\n",
    "\n",
    "for folder_to_process, folder_to_save in folders_to_process:\n",
    "    os.makedirs(folder_to_save, exist_ok=True)\n",
    "    cnt_processed = 0\n",
    "    for filename in os.listdir(folder_to_process):\n",
    "        print(filename)\n",
    "        try:\n",
    "            start_time = time()\n",
    "            filename_to_save = os.path.join(folder_to_save, filename)\n",
    "            if os.path.exists(filename_to_save):\n",
    "                cnt_processed += 1\n",
    "                print(\"Already processed \", filename_to_save)\n",
    "                continue\n",
    "            df = excel_reader.ExcelReader().read_df_from_excel(os.path.join(folder_to_process, filename))\n",
    "            found_data_all = []\n",
    "            idx = 0\n",
    "            idx2doc = {}\n",
    "            for i in range(len(df)):\n",
    "                text = df[\"Text\"].values[i].replace(\"\\n\", \" \")\n",
    "                text = re.sub(\"[sencmaruotv]{15,1000}\", \" \", text).strip() # heuristics to exclude some badly processed words\n",
    "                for sentence in nltk.sent_tokenize(re.sub(\"\\s+\", \" \", text)):\n",
    "                    found_data = []\n",
    "                    results = set()\n",
    "                    for res in ner_model(sentence).ents:\n",
    "                        intervention = _abbreviations_resolver.replace_abbreviations(text=text_normalizer.normalize_sentence(\n",
    "                            res.text)).strip()\n",
    "                        intervnetion_words_set = set()\n",
    "                        intervnetion_words = []\n",
    "                        for w in intervention.split(\" \"):\n",
    "                            if w not in intervnetion_words_set:\n",
    "                                intervnetion_words_set.add(w)\n",
    "                                intervnetion_words.append(w)\n",
    "                        intervention = \" \".join(intervnetion_words).strip()\n",
    "                        if intervention:\n",
    "                            found_data.append((intervention, intervention, sentence, res.text))\n",
    "                            idx2doc[idx] = i\n",
    "                            idx += 1\n",
    "                    found_data_all.extend(found_data)\n",
    "            df_to_predict = pd.DataFrame(found_data_all, columns=[\"Narrow concept\", \"Broad concepts\", \"Sentence\", \"Raw intervention\"])\n",
    "            res_prob, res_label, _ = _intervention_labeler.predict_for_df(df_to_predict)\n",
    "            all_data_found = []\n",
    "            all_probs = []\n",
    "            for i in range(len(found_data_all)):\n",
    "                idx = idx2doc[i]\n",
    "                identified_labels = set()\n",
    "                identified_labels_probs = []\n",
    "                for j in range(len(res_label[i])):\n",
    "                    if res_label[i][j] == 1:\n",
    "                        identified_labels.add(USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL[j+1])\n",
    "                        identified_labels_probs.append((USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL[j+1], res_prob[i][j]))\n",
    "                if identified_labels:\n",
    "                    all_data_found.append((found_data_all[i][0], found_data_all[i][2], found_data_all[i][3],\n",
    "                                           list(identified_labels), identified_labels_probs, df[\"Page\"].values[idx], df[\"Filename\"].values[idx]))\n",
    "            new_df = pd.DataFrame(all_data_found, columns=[\"intervention\", \"sentence\", \"raw_intervention\", \"intervention_labels\",\n",
    "                                                           \"intervention_thresholds\", \"page\", \"filename\"])\n",
    "            print(\"Processed time: %.2f s\" % (time() - start_time))\n",
    "            excel_writer.ExcelWriter().save_df_in_excel(new_df, filename_to_save)\n",
    "            cnt_processed += 1\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate other columns for sentences with interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XDABD534A.xlsx\n",
      "Read file ../tmp/parsed_pdfs_extracted\\XDABD534A.xlsx: 0.11s\n",
      "Processed file ../tmp/parsed_pdfs_extracted\\XDABD534A.xlsx: 0.09s\n",
      "Processed 0 articles\n",
      "Processed 1225 articles\n",
      "Processed 0 abbreviations\n",
      "Processed 3000 abbreviations\n",
      "Processed 6000 abbreviations\n",
      "Processed 9000 abbreviations\n",
      "Processed 12000 abbreviations\n",
      "Processed 15000 abbreviations\n",
      "Processed 18000 abbreviations\n",
      "Processed 21000 abbreviations\n",
      "Processed 24000 abbreviations\n",
      "Processed 27000 abbreviations\n",
      "Processed 27129 abbreviations\n",
      "Started processing  {'column_filler_class': 'KeywordNormalizer'}\n",
      "Processed for 0.20231962203979492s\n",
      "Started processing  {'column_filler_class': 'GeoNameFinder'}\n",
      "Read file ../data/provinces.xlsx: 2.78s\n",
      "Processed file ../data/provinces.xlsx: 1.63s\n",
      "Read file ../data/districts.xlsx: 3.30s\n",
      "Processed file ../data/districts.xlsx: 1.70s\n",
      "Processed 0 items\n",
      "Processed 1225 items\n",
      "Processed for 76.30395889282227s\n",
      "Started processing  {'column_filler_class': 'CropsSearch', 'file_dictionary': '../data/map_plant_products.xlsx', 'column_name': 'plant_products_search'}\n",
      "Read file ../data/map_plant_products.xlsx: 0.05s\n",
      "Processed file ../data/map_plant_products.xlsx: 0.03s\n",
      "Found crops: plant_products_search\n",
      "Number of articles that have plant_products_search : 3\n",
      "Processed for 0.4222390651702881s\n",
      "Started processing  {'column_filler_class': 'CropsSearch', 'file_dictionary': '../data/map_animal_products.xlsx', 'column_name': 'animal_products_search'}\n",
      "Read file ../data/map_animal_products.xlsx: 0.01s\n",
      "Processed file ../data/map_animal_products.xlsx: 0.00s\n",
      "Found crops: animal_products_search\n",
      "Number of articles that have animal_products_search : 2\n",
      "Processed for 0.05807161331176758s\n",
      "Started processing  {'column_filler_class': 'CropsSearch', 'column_name': 'animals_found', 'keep_hierarchy': False, 'file_dictionary': '../data/map_animals.xlsx'}\n",
      "Read file ../data/map_animals.xlsx: 0.09s\n",
      "Processed file ../data/map_animals.xlsx: 0.06s\n",
      "Found crops: animals_found\n",
      "Number of articles that have animals_found : 1\n",
      "Processed for 0.8297860622406006s\n",
      "Started processing  {'column_filler_class': 'ColumnFiller', 'column_name': 'gender_age_population_tags', 'keep_hierarchy': False, 'column_dictionary': '../data/population_tags.xlsx'}\n",
      "High level label: women\n",
      "High level label: men\n",
      "High level label: youth\n",
      "High level label: adults\n",
      "High level label: senior citizens\n",
      "Labelled articles with outcomes: 131\n",
      "Processed for 0.037000179290771484s\n",
      "Started processing  {'column_filler_class': 'StrategyFocusLabeller', 'column_name': 'strategy_focus', 'column_details': 'strategy_focus_details', 'column_dictionary': '../tmp/usaid_files/strategic_approaches_extended.xlsx'}\n",
      "1.c Coordination/Platform 114\n",
      "1.b Institutional Strengthening 93\n",
      "4.f Water resources regulation 60\n",
      "1.a Policy 21\n",
      "4.c Water use efficiency & conservation 15\n",
      "3.e Drinking water quality (WQ) 5\n",
      "2.c Hygiene Social and Behavior Change 4\n",
      "1.d Regulatory frameworks 3\n",
      "3.f Water Access in Instituions 1\n",
      "Labelled docs with strategies: 228\n",
      "Processed for 40.03121018409729s\n",
      "Started processing  {'column_filler_class': 'ProgramExtractor', 'program_filename': '../tmp/usaid_files/extracted_usaid_programs.xlsx', 'column_name': 'programs_found', 'model_type': 'model', 'model_folder': '../model/programs_extraction_model_2619'}\n",
      "Processed for 4.764413595199585s\n",
      "Saving...\n",
      "Saved to ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx\n"
     ]
    }
   ],
   "source": [
    "from text_processing import search_engine_insensitive_to_spelling\n",
    "search_engine_insensitive_to_spelling = reload(search_engine_insensitive_to_spelling)\n",
    "from text_processing import column_filler\n",
    "column_filler=reload(column_filler)\n",
    "from text_processing import keywords_normalizer\n",
    "keywords_normalizer = reload(keywords_normalizer)\n",
    "from text_processing import all_column_filler\n",
    "from text_processing import geo_names_finder\n",
    "geo_names_finder = reload(geo_names_finder)\n",
    "all_column_filler = reload(all_column_filler)\n",
    "\n",
    "\n",
    "#if you have summarized folders\n",
    "#folders_to_process = [(\"../tmp/parsed_pdfs_bart_extracted\", \"../tmp/parsed_pdfs_bart_enriched\"),\n",
    "#                      (\"../tmp/parsed_pdfs_longformer_extracted\", \"../tmp/parsed_pdfs_longformer_enriched\")]\n",
    "folders_to_process = [(\"../tmp/parsed_pdfs_extracted\", \"../tmp/parsed_pdfs_enriched\")]\n",
    "\n",
    "for folder_with_files, folder_with_files_enriched in folders_to_process:\n",
    "    os.makedirs(folder_with_files_enriched, exist_ok=True)\n",
    "    for filename in os.listdir(folder_with_files):\n",
    "        try:\n",
    "            if os.path.exists(os.path.join(folder_with_files_enriched, filename)):\n",
    "                print(\"Already processed \", filename)\n",
    "                continue\n",
    "            print(filename)\n",
    "            df = excel_reader.ExcelReader().read_df_from_excel(os.path.join(folder_with_files, filename))\n",
    "            pdf_name = filename.split(\".\")[0]\n",
    "            for column in df_1.columns:\n",
    "                df[column] = \"\"\n",
    "            key_ = pdf_name\n",
    "            if pdf_name not in dict_file:\n",
    "                if filename.replace(\".xlsx\", \".pdf\") in dict_file:\n",
    "                    key_ = filename.replace(\".xlsx\", \".pdf\")\n",
    "            if key_ in dict_file:\n",
    "                for i in range(len(df)):\n",
    "                    for column in df_1.columns:\n",
    "                        df[column].values[i] = df_1[column].values[dict_file[key_]]\n",
    "\n",
    "            search_engine_inverted_index = search_engine_insensitive_to_spelling.SearchEngineInsensitiveToSpelling(\n",
    "                load_abbreviations = True, columns_to_process=[\"sentence\"])\n",
    "            search_engine_inverted_index.create_inverted_index(df)\n",
    "            _all_column_filler = all_column_filler.AllColumnFiller()\n",
    "            df = _all_column_filler.fill_columns_for_df(df, search_engine_inverted_index, _abbreviations_resolver,settings_json = {\"columns\":[\n",
    "                {\"column_filler_class\":\"KeywordNormalizer\"},\n",
    "                {\"column_filler_class\":\"GeoNameFinder\"},\n",
    "                {\"column_filler_class\":\"CropsSearch\", \"file_dictionary\":\"../data/map_plant_products.xlsx\", \"column_name\":\"plant_products_search\"},\n",
    "                {\"column_filler_class\":\"CropsSearch\", \"file_dictionary\":\"../data/map_animal_products.xlsx\", \"column_name\":\"animal_products_search\"},\n",
    "                {\"column_filler_class\":\"CropsSearch\", \"column_name\": \"animals_found\", \"keep_hierarchy\": False, \"file_dictionary\":\"../data/map_animals.xlsx\"},\n",
    "                {\"column_filler_class\":\"ColumnFiller\", \"column_name\": \"gender_age_population_tags\", \n",
    "                    \"keep_hierarchy\": False, \"column_dictionary\":\"../data/population_tags.xlsx\"},\n",
    "                {\"column_filler_class\":\"StrategyFocusLabeller\", \"column_name\": \"strategy_focus\",\n",
    "                 \"column_details\": \"strategy_focus_details\", \"column_dictionary\":\"../tmp/usaid_files/strategic_approaches_extended.xlsx\"},\n",
    "                {\"column_filler_class\": \"ProgramExtractor\", \"program_filename\": \"../tmp/usaid_files/extracted_usaid_programs.xlsx\",\n",
    "                 \"column_name\": \"programs_found\", \"model_type\": \"model\", \"model_folder\": \"../model/programs_extraction_model_2619\"}\n",
    "            ]})\n",
    "            excel_writer.ExcelWriter().save_df_in_excel(df, os.path.join(folder_with_files_enriched, filename))\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx: 0.66s\n",
      "Processed file ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx: 0.83s\n",
      "Saving...\n",
      "Saved to ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx\n"
     ]
    }
   ],
   "source": [
    "from text_processing import search_engine_insensitive_to_spelling\n",
    "search_engine_insensitive_to_spelling = reload(search_engine_insensitive_to_spelling)\n",
    "from text_processing import column_filler\n",
    "column_filler=reload(column_filler)\n",
    "from text_processing import keywords_normalizer\n",
    "keywords_normalizer = reload(keywords_normalizer)\n",
    "from text_processing import all_column_filler\n",
    "from text_processing import geo_names_finder\n",
    "geo_names_finder = reload(geo_names_finder)\n",
    "all_column_filler = reload(all_column_filler)\n",
    "\n",
    "folder_with_files_enriched = \"../tmp/parsed_pdfs_enriched\"\n",
    "os.makedirs(folder_with_files_enriched, exist_ok=True)\n",
    "for filename in os.listdir(folder_with_files_enriched):\n",
    "    df = excel_reader.ExcelReader().read_df_from_excel(os.path.join(folder_with_files_enriched, filename))\n",
    "    for i in range(len(df)):\n",
    "        if \"United States\" in df[\"countries_mentioned\"].values[i]:\n",
    "            df[\"countries_mentioned\"].values[i].remove(\"United States\")\n",
    "        if \"US\" in df[\"country_codes\"].values[i]:\n",
    "            df[\"country_codes\"].values[i].remove(\"US\")\n",
    "        if \"North America\" in df[\"geo_regions\"].values[i]:\n",
    "            df[\"geo_regions\"].values[i].remove(\"North America\")\n",
    "        provinces = []\n",
    "        for prov in df[\"provinces\"].values[i]:\n",
    "            if not prov.startswith(\"United States\"):\n",
    "                provinces.append(prov)\n",
    "        df[\"provinces\"].values[i] = provinces\n",
    "        provinces = []\n",
    "        for prov in df[\"districts\"].values[i]:\n",
    "            if not prov.startswith(\"United States\"):\n",
    "                provinces.append(prov)\n",
    "        df[\"districts\"].values[i] = provinces\n",
    "    excel_writer.ExcelWriter().save_df_in_excel(df, os.path.join(folder_with_files_enriched, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001616B15EF98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001616B15EF98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n",
      "../tmp/parsed_pdfs_enriched XDABD534A.xlsx\n",
      "Read file ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx: 1.00s\n",
      "Processed file ../tmp/parsed_pdfs_enriched\\XDABD534A.xlsx: 1.25s\n",
      "1226\n",
      "INFO:tensorflow:Writing example 0 of 1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] e ##qua ##ily important were the many officials in the agency for international development in washington , the usa ##id missions , african ministries of health , unicef , who , as well as cc ##cd technical officers who took the time to share their views on the cc ##cd program and to help us organize our visits . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] e ##qua ##ily important were the many officials in the agency for international development in washington , the usa ##id missions , african ministries of health , unicef , who , as well as cc ##cd technical officers who took the time to share their views on the cc ##cd program and to help us organize our visits . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1041 16211 6588 2590 2020 1996 2116 4584 1999 1996 4034 2005 2248 2458 1999 2899 1010 1996 3915 3593 6416 1010 3060 16410 1997 2740 1010 29073 1010 2040 1010 2004 2092 2004 10507 19797 4087 3738 2040 2165 1996 2051 2000 3745 2037 5328 2006 1996 10507 19797 2565 1998 2000 2393 2149 10939 2256 7879 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1041 16211 6588 2590 2020 1996 2116 4584 1999 1996 4034 2005 2248 2458 1999 2899 1010 1996 3915 3593 6416 1010 3060 16410 1997 2740 1010 29073 1010 2040 1010 2004 2092 2004 10507 19797 4087 3738 2040 2165 1996 2051 2000 3745 2037 5328 2006 1996 10507 19797 2565 1998 2000 2393 2149 10939 2256 7879 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the centers tor disease control ( cdc ) 3 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the centers tor disease control ( cdc ) 3 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 6401 17153 4295 2491 1006 26629 1007 1017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 6401 17153 4295 2491 1006 26629 1007 1017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] monitoring and supervision by cdc 4 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] monitoring and supervision by cdc 4 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8822 1998 10429 2011 26629 1018 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8822 1998 10429 2011 26629 1018 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] participating countries b . overview of interventions and support strategies 1 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] participating countries b . overview of interventions and support strategies 1 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8019 3032 1038 1012 19184 1997 19388 1998 2490 9942 1015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8019 3032 1038 1012 19184 1997 19388 1998 2490 9942 1015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] impact indicators d . policy development and strategies [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] impact indicators d . policy development and strategies [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4254 20390 1040 1012 3343 2458 1998 9942 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4254 20390 1040 1012 3343 2458 1998 9942 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 0\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7\\model.ckpt-1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7\\model.ckpt-1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  459.07994174957275\n",
      "Saving...\n",
      "Saved to ../tmp/parsed_pdfs_enriched_with_outcomes\\XDABD534A.xlsx\n"
     ]
    }
   ],
   "source": [
    "from outcomes_modelling import outcomes_multi_label_predictor\n",
    "outcomes_multi_label_predictor = reload(outcomes_multi_label_predictor)\n",
    "_outcomes_multi_label_predictor = outcomes_multi_label_predictor.OutcomesMultiLabelPredictor(\n",
    "    \"../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7\")\n",
    "from time import time\n",
    "folder = \"../tmp/parsed_pdfs_enriched\"\n",
    "enriched_folder = \"../tmp/parsed_pdfs_enriched_with_outcomes\"\n",
    "for filename in os.listdir(folder):\n",
    "    print(folder, filename)\n",
    "    if folder != enriched_folder and os.path.exists(os.path.join(enriched_folder, filename)):\n",
    "        print(\"Already processed\")\n",
    "        continue\n",
    "    start = time()\n",
    "    df = excel_reader.ExcelReader().read_df_from_excel(os.path.join(folder, filename))\n",
    "    print(len(df))\n",
    "    df[\"text\"] = df[\"sentence\"] #df[\"title\"] + \" . \" + df[\"abstract\"]\n",
    "    found_labels, outcome_details = _outcomes_multi_label_predictor.predict_all_labels(df[\"text\"].values)\n",
    "    df[\"outcomes_found\"] = found_labels\n",
    "    df[\"outcomes_details\"] = [\"\\n\".join(detail) for detail in outcome_details]\n",
    "    df = df.drop([\"text\"], axis=1)\n",
    "    print(\"Finished \", (time() - start))\n",
    "    os.makedirs(os.path.join(\"../tmp\", enriched_folder), exist_ok=True)\n",
    "    excel_writer.ExcelWriter().save_df_in_excel(df, os.path.join(enriched_folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/parsed_pdfs_enriched_with_outcomes\\XDABD534A.xlsx: 0.92s\n",
      "Processed file ../tmp/parsed_pdfs_enriched_with_outcomes\\XDABD534A.xlsx: 1.93s\n",
      "Saving...\n",
      "Saved to ../tmp/processed_usaid_filtered\\XDABD534A.xlsx\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "new_folder_to_save = \"../tmp/processed_usaid_filtered\"\n",
    "folder_with_files_enriched = \"../tmp/parsed_pdfs_enriched_with_outcomes\"\n",
    "os.makedirs(new_folder_to_save, exist_ok=True)\n",
    "for filename in os.listdir(folder_with_files_enriched):\n",
    "    df = excel_reader.ExcelReader().read_df_from_excel(os.path.join(folder_with_files_enriched, filename))\n",
    "    ind_to_take = []\n",
    "    for i in range(len(df)):\n",
    "        found = False\n",
    "        if \"abbreviation\" in df[\"sentence\"].values[i].lower() or \"acronym\" in df[\"sentence\"].values[i].lower():\n",
    "            continue\n",
    "        if not found:\n",
    "            ind_to_take.append(i)\n",
    "    excel_writer.ExcelWriter().save_df_in_excel(df.take(ind_to_take), os.path.join(new_folder_to_save, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all docs into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/processed_usaid_filtered\\XDABD534A.xlsx: 0.84s\n",
      "Processed file ../tmp/processed_usaid_filtered\\XDABD534A.xlsx: 1.21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for filename in os.listdir(new_folder_to_save):\n",
    "    df_ = excel_reader.ExcelReader().read_df_from_excel(os.path.join(new_folder_to_save, filename))\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform clusterization of interventions\n",
    "This will help to reduce uniqueness of interventions and save clustered intervention name in a separate field to use it in the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synonyms_module import synonyms_processor\n",
    "\n",
    "_synonyms_all = synonyms_processor.SynonymsProcessor(\"../model/synonyms_usaid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed_for_phrase(text):\n",
    "    for w in ['programme',\n",
    "             'policy',\n",
    "             'action',\n",
    "             'program',\n",
    "             'intervention aimed',\n",
    "             'strategy',\n",
    "             'initiative',\n",
    "             'effort',\n",
    "             'measure',\n",
    "             'project',\n",
    "             'outcome',\n",
    "             'implementation',\n",
    "             'policy instrument',\n",
    "             'training program',\n",
    "             'public policy',\n",
    "             'counseling',\n",
    "             'reform']:\n",
    "        text = text.replace(w, \" \")\n",
    "    return _synonyms_all.get_average_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Assessment tool or program', 'Sustainability/Environmental health') 14\n",
      "1 [0 1 1 1 1 1 0 1 0 1 0 0 1 0]\n",
      "('Human health',) 215\n",
      "14 [ 4 -1  3 12 -1 12 -1 -1 -1 12 -1 -1 -1 -1  0  9 11  8  4 -1 -1 -1 13  8\n",
      " -1 -1 -1 12 -1 -1 -1 -1 -1 -1 10  1  5 -1 -1 -1  6 -1 -1 -1 -1 -1  4 12\n",
      "  6  6  4 -1  7 -1 -1  6 -1 -1 -1 10 -1 -1 13  8  8 -1 12 -1 -1 -1  7 -1\n",
      "  4  3 -1 -1  8 -1 -1  0  1 -1  8  6  8 -1  6 -1 13  4 -1  7 -1  3 -1 -1\n",
      " -1  3  8 -1 -1 -1 -1  6 -1 -1  5 -1 -1 -1 -1 -1  2 -1 -1 -1  6 13 -1 -1\n",
      " -1 -1 -1  4 -1 -1  9 -1 10 -1 -1 -1  8 14  4 11 11 -1  8 -1 14  6 -1  7\n",
      " -1 -1  8 -1  4 11 -1 -1 -1  5 -1 -1  2 -1 -1  9 -1 -1 12 12 -1  3 -1 -1\n",
      " -1  0  4 -1 -1 -1 -1 -1 -1 -1 -1 -1 10  6 -1 12 14  6  4 -1 -1 -1 -1 10\n",
      " -1 -1 -1  7 -1  4 -1  1 -1 -1 -1 -1 -1 13 -1  2 -1  6  0 -1 -1  4 14]\n",
      "('Assessment tool or program',) 93\n",
      "4 [ 3  2 -1 -1 -1 -1  3  3  3  3  3  3 -1  1 -1  3 -1  0  3  0  3  3 -1 -1\n",
      "  3  1  3  3  3  3  3  3  3 -1  3 -1  4  3  3 -1  3  2 -1 -1  1 -1  3  3\n",
      "  3  3  4  3  3 -1  3  3 -1 -1  3  3  3 -1  3 -1  3  3  3 -1  4 -1  3 -1\n",
      "  1  4  2  3  3  3 -1 -1  3  3  3  0  3  3  3  3  3  3 -1  3 -1]\n",
      "('Community and behavior',) 168\n",
      "8 [-1  7 -1 -1  5 -1 -1 -1 -1  7  8  2  4  5  1 -1 -1  1 -1  7 -1  4 -1 -1\n",
      "  5 -1  4 -1  7 -1 -1 -1 -1 -1 -1  7 -1 -1  1  0 -1 -1 -1  4  0  7 -1  7\n",
      " -1 -1  0  5  7 -1  0 -1 -1  6  5  5 -1 -1 -1 -1  4  4 -1 -1 -1  8  0 -1\n",
      " -1 -1 -1 -1  5  6 -1 -1 -1 -1 -1 -1  6  6 -1 -1  0 -1  1 -1 -1  1  1 -1\n",
      " -1 -1 -1 -1  4  2  1  7 -1 -1 -1 -1 -1  3 -1 -1  7 -1 -1  5 -1  3 -1  6\n",
      " -1 -1 -1 -1  7 -1  6 -1 -1 -1  7 -1  8  5  3 -1 -1  7 -1 -1 -1 -1  7 -1\n",
      "  6 -1 -1  7  5 -1 -1 -1 -1 -1  7 -1 -1  7 -1  6 -1 -1 -1  2  0 -1 -1  6]\n",
      "('Policy',) 74\n",
      "2 [-1 -1  1 -1 -1 -1  2 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1  1  0 -1 -1 -1 -1 -1 -1 -1  0 -1 -1\n",
      " -1  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1\n",
      "  2  1]\n",
      "('Sustainability/Environmental health',) 18\n",
      "2 [-1  2  2  2 -1  2 -1  1  0  2  1  2  2 -1  0  0 -1  1]\n",
      "('Agriculture',) 24\n",
      "2 [-1 -1 -1 -1 -1 -1  0 -1  1  0  2  1  0 -1 -1 -1  2  1 -1  2  1 -1 -1  2]\n",
      "('Assessment tool or program', 'Human health') 9\n",
      "-1 [-1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "('Water quality',) 11\n",
      "-1 [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "('Policy', 'Human health') 11\n",
      "1 [ 0  1  0  0  0  1 -1  0  1 -1  0]\n",
      "('Community and behavior', 'Human health') 22\n",
      "-1 [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "('Policy', 'Community and behavior') 3\n",
      "-1 [-1 -1 -1]\n",
      "('Water infrastructure',) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "\n",
    "all_interventions = {}\n",
    "all_interventions_dict = {}\n",
    "for i in range(len(df)):\n",
    "    if tuple(df[\"intervention_labels\"].values[i]) not in all_interventions:\n",
    "        all_interventions[tuple(df[\"intervention_labels\"].values[i])] = set()\n",
    "    all_interventions[tuple(df[\"intervention_labels\"].values[i])].add(df[\"intervention\"].values[i])\n",
    "    if df[\"intervention\"].values[i] not in all_interventions_dict:\n",
    "        all_interventions_dict[df[\"intervention\"].values[i]] = 0\n",
    "    all_interventions_dict[df[\"intervention\"].values[i]] += 1\n",
    "\n",
    "remappings = {}\n",
    "word2cluster_interv = {}\n",
    "for group in all_interventions:\n",
    "    texts = list(all_interventions[group])\n",
    "    print(group, len(texts))\n",
    "    word_embeds = []\n",
    "    for i in range(len(texts)):\n",
    "        word_embeds.append(get_embed_for_phrase(texts[i]))\n",
    "    if len(word_embeds) < 2:\n",
    "        remappings[texts[0]] = texts[0]\n",
    "        continue\n",
    "    clusterer = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=3)\n",
    "    clusterer.fit(word_embeds)\n",
    "    print(clusterer.labels_.max(), clusterer.labels_)\n",
    "    cluster_words = {}\n",
    "    for idx in range(len(texts)):\n",
    "        if clusterer.labels_[idx] not in cluster_words:\n",
    "            cluster_words[clusterer.labels_[idx]] = []\n",
    "        cluster_words[clusterer.labels_[idx]].append((texts[idx], word_embeds[idx]))\n",
    "    for cluster_id in range(clusterer.labels_.max()+1):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        kmeans = KMeans(n_clusters=1, random_state=0).fit(\n",
    "            [ word_embeds[idx] for idx in range(len(texts)) if  clusterer.labels_[idx] == cluster_id])\n",
    "        all_words = []\n",
    "        print_res = False\n",
    "        for word, embed in cluster_words[cluster_id]:\n",
    "            all_words.append((\n",
    "                word, all_interventions_dict[word], round(1 - spatial.distance.cosine(embed, kmeans.cluster_centers_[0]), 2)))\n",
    "        all_words = sorted(all_words, key=lambda x: (x[1], x[2], -len(x[0].split())), reverse=True)\n",
    "        if print_res:\n",
    "            for w in all_words:\n",
    "                print(w)\n",
    "        for w in all_words:\n",
    "            remappings[w[0]] = all_words[0][0]\n",
    "        word2cluster_interv[all_words[0][0]] = [w[0].strip() for w in all_words]\n",
    "    if -1 in cluster_words:\n",
    "        for w, embed in cluster_words[-1]:\n",
    "            remappings[w] = w\n",
    "df[\"clustered_intervention\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    df[\"clustered_intervention\"].values[i] = remappings[df[\"intervention\"].values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [ 6  6 -1  2  4 -1  0  6 -1  0 -1 -1 -1  3  7 -1 -1  7 -1 -1  2  7 -1 -1\n",
      "  7  3 -1  7 -1 -1 -1 -1 -1  7  0  6  1  6  4  1 -1  7  7  0 -1 -1 -1  5\n",
      "  4  3 -1 -1 -1  4  7 -1 -1 -1  1  4 -1 -1  7 -1  7 -1  7 -1 -1  2  7  5\n",
      "  5  5  7  4  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "\n",
    "all_programs_dict = {}\n",
    "for i in range(len(df)):\n",
    "    for program in df[\"programs_found\"].values[i]:\n",
    "        if program not in all_programs_dict:\n",
    "            all_programs_dict[program] = 0\n",
    "        all_programs_dict[program] += 1\n",
    "\n",
    "remappings_programs = {}\n",
    "texts = list(all_programs_dict.keys())\n",
    "word_embeds = []\n",
    "for i in range(len(texts)):\n",
    "    word_embeds.append(get_embed_for_phrase(texts[i]))\n",
    "clusterer = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=3)\n",
    "clusterer.fit(word_embeds)\n",
    "print(clusterer.labels_.max(), clusterer.labels_)\n",
    "cluster_words = {}\n",
    "for idx in range(len(texts)):\n",
    "    if clusterer.labels_[idx] not in cluster_words:\n",
    "        cluster_words[clusterer.labels_[idx]] = []\n",
    "    cluster_words[clusterer.labels_[idx]].append((texts[idx], word_embeds[idx]))\n",
    "for cluster_id in range(clusterer.labels_.max()+1):\n",
    "    if cluster_id == -1:\n",
    "        continue\n",
    "    kmeans = KMeans(n_clusters=1, random_state=0).fit(\n",
    "        [ word_embeds[idx] for idx in range(len(texts)) if  clusterer.labels_[idx] == cluster_id])\n",
    "    all_words = []\n",
    "    for word, embed in cluster_words[cluster_id]:\n",
    "        all_words.append((word, all_programs_dict[word], round(1 - spatial.distance.cosine(embed, kmeans.cluster_centers_[0]), 2)))\n",
    "    all_words = sorted(all_words, key=lambda x: (x[1], x[2], -len(x[0].split())), reverse=True)\n",
    "    for w in all_words:\n",
    "        remappings_programs[w[0]] = all_words[0][0]\n",
    "if -1 in cluster_words:\n",
    "    for w, embed in cluster_words[-1]:\n",
    "        remappings_programs[w] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_remapping = {\"water supply hygiene (WASH) project\": \"water supply hygiene (WASH)\",\n",
    "                    \"water supply hygiene (WASH) program\": \"water supply hygiene (WASH)\",\n",
    "                    \"water supply hygiene (WASH) initiative\": \"water supply hygiene (WASH)\",\n",
    "                    \"public private partnership (PPP) project\": \"public private partnership (PPP)\",\n",
    "                    \"public private partnership (PPP) program\": \"public private partnership (PPP)\",\n",
    "                    \"sustainable water sanitation (SUWASA) africa program\": \"sustainable water sanitation (SUWASA) program\",\n",
    "                    \"sustainable water sanitation (SUWASA) project south sudan\": \"sustainable water sanitation (SUWASA) program\",\n",
    "                    \"water development alliance (WADA) initiative\": \"water development alliance (WADA)\",\n",
    "                    \"water development alliance (WADA) program\": \"water development alliance (WADA)\",\n",
    "                    \"water access sanitation hygiene\": \"water santitation hygiene (WASH)\"\n",
    "                   }\n",
    "remove_programs = set([\"human immunodeficiency virus (HIV)\", \"standard operating procedure (SOP)\", \"miyahuna\",\n",
    "                  \"NOT\", \"standard normal variate (SNV)\", \"public work (PW)\", \"project\", \"business development service (BDS)\",\n",
    "                  \"key performance indicator (KPI)\", \"south africa (SA)\", \"adjusted odds ratio (AOR)\", \"africasan\",\n",
    "                  \"confirmatory factor analysis (CFA)\", \"cost benefit analysis (CBA)\", \"department health (DOH)\",\n",
    "                  \"joint monitoring program (JMP)\", \"perceived behavioral control (PBC)\",\n",
    "                  \"president emergency plan almost ideal demand system (AIDS) relief PEPFAR\", \"royal scientific society (RSS)\",\n",
    "                  \"soil moisture content (SMC)\",\"waste orange peel (WOP)\", \"CITE\", \"FYI9\", \"alcoholic liver disease (ALD)\",\n",
    "                   \"available water capacity (AWC)\",\"beirut mount lebanon water establishment beirutmount lebanon water establishment (BMLWE)\",\n",
    "                    \"capital improvement project cleaning place (CIP)\", \"composite hollow fiber (CHF)\",\n",
    "                    \"department environment natural resource (DENR)\", \"development grant program (DGP)\",\n",
    "                    \"disaster risk reduction (DRR)\", \"duck energy day (DED)\", \"electrochemical oxidant (ECO) asia water sanitation program (WSP)\",\n",
    "                  \"environmental service (ES) program exchangeable sodium percentage (ESP)\",\"expected project\",\n",
    "                  \"almost ideal demand system (AIDS) program\", \"aminocyclopropane carboxylic acid (ACC)\", \"climate change adaptation (CCA)\",\n",
    "                  \"climate change adaptation (CCA)\", \"cottonseed cake (CSC)\", \"data quality assessment (DQA)\", \"depok city\",\n",
    "                  \"focus group discussion (FGD)\",\"global health program\", \"government bangladesh (GOB)\",\"gulf mexico (GOM)\",\n",
    "                   \"high density PE (HDPE)\",\"indonesia environmental service (ES) program exchangeable sodium percentage (ESP)\",\n",
    "                   \"indoor air pollution (IAP)\", \"institutional support strengthening program (ISSP)\",\n",
    "                  \"life project (LOP)\",\"lot quality assurance sampling (LQAS)\",\"management science health (MSH)\",\n",
    "                   \"microfinance institution (MFI)\",\"minimum service standard suspended particulate matter (SPM)\",\n",
    "                   \"monitoring evaluation support project minimum ethanol selling price (MESP)\",\n",
    "                   \"person indian origin (PIO)\", \"personal protective equipment (PPE)\", \"phos K POME (PHP)\",\n",
    "                   \"quality assurance quality control (QAQC) quality assurance (QA) quality control (QC)\",\n",
    "                   \"research policy development (RAPID)\",\"residual intake gain (RIG)\", \"single super phosphate (SSP)\",\n",
    "                   \"smart water project\", \"soil conditioning index (SCI)\", \"soil nutrient index (SNI)\",\n",
    "                   \"spatial production allocation model (SPAM)\",\"specie sensitivity distribution (SSD) project\",\n",
    "                  \"village development committee (VDC)\",\"voluntary medical male circumcision VMMC\",\n",
    "                  \"water resource\", \"water soluble carbohydrate (WSC)\",\"water supply hygiene (WASH) microfinance program\",\n",
    "                  \"water supply sanitation (WSS) act\",\"watershed\", \"academy educational development average extent damage (AED)\",\n",
    "                   \"agricultural development programme (ADP)\",\"agricultural safety health (ASH)\",\"analytical advisory activity (AAA)\",\n",
    "                   \"analytics evaluation project\",\"basin water board (WB) burch wet bladetm (BWB)\"])\n",
    "\n",
    "word2cluster = {}\n",
    "for cluster_id in cluster_words:\n",
    "    if cluster_id != -1:\n",
    "        for program, embed in cluster_words[cluster_id]:\n",
    "            word2cluster[program] = cluster_id\n",
    "\n",
    "additional_removals = set()\n",
    "for program in remove_programs:\n",
    "    if program in word2cluster:\n",
    "        additional_removals.update([pr for pr, embed in cluster_words[word2cluster[program]]])\n",
    "remove_programs.update(additional_removals)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    programs = []\n",
    "    for program in df[\"programs_found\"].values[i]:\n",
    "        if program.strip() in remove_programs:\n",
    "            continue\n",
    "        if program in remappings_programs:\n",
    "            program_remmaped = remappings_programs[program]\n",
    "            if program_remmaped in custom_remapping:\n",
    "                program_remmaped = custom_remapping[program_remmaped]\n",
    "            if program_remmaped not in remove_programs:\n",
    "                programs.append(program_remmaped.strip())\n",
    "        else:\n",
    "            programs.append(program.strip())\n",
    "    df[\"programs_found\"].values[i] = programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_take = []\n",
    "for i in range(len(df)):\n",
    "    if re.search(r\"\\bHIV\\b\", df[\"intervention\"].values[i]) or re.search(r\"\\bAIDS\\b\", df[\"intervention\"].values[i]):\n",
    "        continue\n",
    "    ind_to_take.append(i)\n",
    "df = df.take(ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_to_remove = set([\"SPLASH intervention school\",\n",
    "\"key informant interview (KII)\",\n",
    "\"monitoring monitoring\",\n",
    "\"QUESTIONNAIRE\",\n",
    "\"pattern decentralized economic social development\",\n",
    "\"human immunodeficiency virus (HIV) disease monitoring\",\n",
    "\"pesticide\"\n",
    "\"baseline assessment finding strength weakness opportunity threat (SWOT) analysis\",\n",
    "\"access improved seed\"\n",
    "\"adding chemical fertilizer (CF)\",\n",
    "\"access antiretroviral therapy (ART) prevention mother child transmission (PMTCT) service\"\n",
    "\"water resoures\",\n",
    "\"management knowledge management (KM)\",\n",
    "\"technical support\",\n",
    "\"knowledge sharing\",\n",
    "\"budgeting\",\n",
    "\"communication strategy (CS)\",\n",
    "\"active participation\",\n",
    "\"assessment aimed verifying\",\n",
    "\"assess performance initiative\"\n",
    "\"advanced training\", \"access\", \"baseline survey\", \"regulation\",\n",
    "\"periodical awareness creation\"])\n",
    "custom_remappings = {\n",
    "    \"basic sanitation system\": \"sanitation service\",\n",
    "    \"agricultural research (AGAR) besides\": \"agricultural research\",\n",
    "    \"afghan urban water (UW) sanitation activity\": \"urban water (UW) sanitation activity\",\n",
    "    \"accessory solar pump solar pump\": \"solar pump\",\n",
    "    \"animateur conservation (ANICO) conservation animateur conservation (ANICO)\": \"animateur conservation (ANICO)\",\n",
    "    \"AGRICULTURAL POLICY\": \"AGRICULTURAL POLICY\".lower(),\n",
    "    \"address human resource development (HRD)\": \"human resource development (HRD)\",\n",
    "    \"activity desludging\": \"desludging\",\n",
    "    \"accredit certification program\": \"accredited certification program\",\n",
    "    \"ACTIVITIES community mobilization\": \"community mobilization\",\n",
    "    \"activity behavior change activity\": \"behavior change activity\",\n",
    "    \"rainwater harvesting (RWH) rainwater harvesting (RWH)\": \"rainwater harvesting (RWH)\",\n",
    "    \"ensureing fetching water\": \"ensuring fetching water\",\n",
    "    \"HEALTH SERVICES FOR WOHEN\": \"HEALTH SERVICES FOR WOMEN\".lower(),\n",
    "    \"assodation registration\": \"association registration\",\n",
    "    \"water facility cicsvesseciemrsseacciavi iai wess\": \"water facility\",\n",
    "    \"national pure chitosan (PCH) household survey (HS)\": \"national pure chitosan (PCH)\",\n",
    "    \"environmental management monitoring plan environmental monitoring mitigation plan (EMMP)\":\"environmental monitoring mitigation plan (EMMP)\",\n",
    "    \"waste management fechnologies\": \"waste management technologies\",\n",
    "    \"pattern decentralized economic social development\": \"decentralized economic social development\",\n",
    "    \"wash hand every day\": \"handwashing\",\n",
    "    \"providins technical assistance\": \"providing technical assistance\",\n",
    "    \"water sanitation (WSS) WWASH\": \"water sanitation (WSS) service\",\n",
    "    \"BOREHOLES\": \"BOREHOLE\".lower(),\n",
    "    \"SSIMP coordination\": \"SSIMP training\",\n",
    "    \"westernstyle toilet\": \"western style toilet\",\n",
    "    \"houschold latrine\": \"household latrine\",\n",
    "    \"sanitation setvices\": \"sanitation service\",\n",
    "    \"soutce water supply\": \"source water supply\",\n",
    "    \"highcapacity pump\": \"high capacity pump\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_take = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"intervention\"].values[i] in interventions_to_remove or df[\"clustered_intervention\"].values[i] in interventions_to_remove:\n",
    "        continue\n",
    "    if df[\"intervention\"].values[i] in custom_remappings:\n",
    "        df[\"intervention\"].values[i] = custom_remappings[df[\"intervention\"].values[i]].strip()\n",
    "    if df[\"clustered_intervention\"].values[i] in custom_remappings:\n",
    "        df[\"clustered_intervention\"].values[i] = custom_remappings[df[\"clustered_intervention\"].values[i]].strip()\n",
    "    ind_to_take.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.take(ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[\"intervention\"].values[i] = re.sub(\n",
    "        \"(access|accessing|accessed)(?!$)\", \"access to\", df[\"intervention\"].values[i])\n",
    "    df[\"clustered_intervention\"].values[i] = re.sub(\n",
    "        \"(access|accessing|accessed)(?!$)\", \"access to\", df[\"clustered_intervention\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[\"intervention\"].values[i] = df[\"intervention\"].values[i].strip()\n",
    "    df[\"clustered_intervention\"].values[i] = df[\"clustered_intervention\"].values[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260891 270226\n"
     ]
    }
   ],
   "source": [
    "sentence_deduplcated_data = set()\n",
    "ind_to_take = []\n",
    "for i in range(len(df)):\n",
    "    pair_val = (df[\"sentence\"].values[i].strip().lower(),\n",
    "                df[\"filename\"].values[i].strip().lower(),\n",
    "                df[\"intervention\"].values[i].strip().lower())\n",
    "    if pair_val not in sentence_deduplcated_data:\n",
    "        sentence_deduplcated_data.add(pair_val)\n",
    "        ind_to_take.append(i)\n",
    "print(len(ind_to_take), len(df))\n",
    "df = df.take(ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_stats = {}\n",
    "intervention_stats = {}\n",
    "intervention_stats_per_strategy = {}\n",
    "for i in range(len(df)):\n",
    "    for program in df[\"programs_found\"].values[i]:\n",
    "        if program not in programs_stats:\n",
    "            programs_stats[program] = set()\n",
    "        programs_stats[program].add(df[\"filename\"].values[i])\n",
    "    if df[\"clustered_intervention\"].values[i] not in intervention_stats:\n",
    "        intervention_stats[df[\"clustered_intervention\"].values[i]] = set()\n",
    "    intervention_stats[df[\"clustered_intervention\"].values[i]].add(df[\"filename\"].values[i])\n",
    "    for strategy_focus in df[\"strategy_focus\"].values[i]:\n",
    "        if df[\"clustered_intervention\"].values[i] not in intervention_stats_per_strategy:\n",
    "            intervention_stats_per_strategy[df[\"clustered_intervention\"].values[i]] = {}\n",
    "        if strategy_focus not in intervention_stats_per_strategy[df[\"clustered_intervention\"].values[i]]:\n",
    "            intervention_stats_per_strategy[df[\"clustered_intervention\"].values[i]][strategy_focus] = set()\n",
    "        intervention_stats_per_strategy[df[\"clustered_intervention\"].values[i]][strategy_focus].add(df[\"filename\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('4.d Land use planning', 29) 0\n",
      "('1.g Consumer revenue streams', 31) 0\n",
      "('2.e MHM', 62) 1\n",
      "('3.d Piped water services', 80) 1\n",
      "('1.e Domestic resource mobilization', 107) 2\n",
      "('2.d Fecal Sludge Management', 111) 2\n",
      "('1.f Commercial investments', 116) 2\n",
      "('4.b Watershed protection', 161) 3\n",
      "('2.f Communal Sanitation Facilities', 171) 3\n",
      "('4.e Adaptation', 173) 3\n",
      "('2.b Market Based Sanitation', 243) 4\n",
      "('3.b Urban water utilities', 286) 5\n",
      "('2.g Sanitation/Hygiene in Institutions', 306) 6\n",
      "('3.c Rural Water Monitoring', 336) 6\n",
      "('3.f Water Access in Instituions', 345) 6\n",
      "('4.f Water resources regulation', 355) 7\n",
      "('4.a Water Resource Management Plans', 361) 7\n",
      "('4.c Water use efficiency & conservation', 416) 8\n",
      "('1.a Policy', 445) 8\n",
      "('3.e Drinking water quality (WQ)', 446) 8\n",
      "('2.c Hygiene Social and Behavior Change', 462) 9\n",
      "('1.d Regulatory frameworks', 495) 9\n",
      "('2.a Sanitation Demand Creation', 515) 10\n",
      "('3.a Professionalization of Rural Services', 534) 10\n",
      "('1.b Institutional Strengthening', 661) 13\n",
      "('1.c Coordination/Platform', 682) 13\n"
     ]
    }
   ],
   "source": [
    "cnt_docs_per_strategy = {}\n",
    "for i in range(len(df)):\n",
    "    for val in df[\"strategy_focus\"].values[i]:\n",
    "        if val not in cnt_docs_per_strategy:\n",
    "            cnt_docs_per_strategy[val] = set()\n",
    "        cnt_docs_per_strategy[val].add(df[\"filename\"].values[i])\n",
    "for w in sorted([(w, len(cnt_docs_per_strategy[w])) for w in cnt_docs_per_strategy], key=lambda x:x[1]):\n",
    "    #print(w[0], \" Total: \", w[1], \" Min doc count threshold: \", int(w[1]*0.02))\n",
    "    print(w, int(w[1]*0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_interventions_dict = {}\n",
    "for i in range(len(df)):\n",
    "    if not df[\"clustered_intervention\"].values[i].strip() or not df[\"intervention\"].values[i].strip():\n",
    "        continue\n",
    "    min_doc_count = -1\n",
    "    strategy_focus_to_filter_by = \"\"\n",
    "    if df[\"clustered_intervention\"].values[i] in intervention_stats_per_strategy:\n",
    "        for strategy_focus in intervention_stats_per_strategy[df[\"clustered_intervention\"].values[i]]:\n",
    "            min_doc_strategy = int(len(cnt_docs_per_strategy[strategy_focus])*0.02)\n",
    "            if min_doc_count == -1:\n",
    "                min_doc_count = min_doc_strategy\n",
    "                strategy_focus_to_filter_by = strategy_focus\n",
    "            else:\n",
    "                if min_doc_strategy < min_doc_count:\n",
    "                    min_doc_count = min_doc_strategy\n",
    "                    strategy_focus_to_filter_by = strategy_focus\n",
    "    min_doc_count = min(min_doc_count, 10)\n",
    "    clustered_intervention_to_take = \"\"\n",
    "    if strategy_focus_to_filter_by == \"\":\n",
    "        if df[\"clustered_intervention\"].values[i] in intervention_stats and len(intervention_stats[df[\"clustered_intervention\"].values[i]]) >= 10:\n",
    "            clustered_intervention_to_take = df[\"clustered_intervention\"].values[i]\n",
    "    else:\n",
    "        if df[\"clustered_intervention\"].values[i] in intervention_stats and len(intervention_stats[df[\"clustered_intervention\"].values[i]]) >= min_doc_count:\n",
    "            clustered_intervention_to_take = df[\"clustered_intervention\"].values[i]\n",
    "    if clustered_intervention_to_take.strip():\n",
    "        if tuple(df[\"intervention_labels\"].values[i]) not in cluster_interventions_dict:\n",
    "            cluster_interventions_dict[tuple(df[\"intervention_labels\"].values[i])] = set()\n",
    "        cluster_interventions_dict[tuple(df[\"intervention_labels\"].values[i])].add(clustered_intervention_to_take)\n",
    "    programs = []\n",
    "    for program in df[\"programs_found\"].values[i]:\n",
    "        if len(programs_stats[program]) >= 15:\n",
    "            programs.append(program)\n",
    "    df[\"programs_found\"].values[i] = programs\n",
    "for key in cluster_interventions_dict:\n",
    "    texts = list(cluster_interventions_dict[key])\n",
    "    word_embeds = []\n",
    "    for i in range(len(texts)):\n",
    "        word_embeds.append(get_embed_for_phrase(texts[i]))\n",
    "    cluster_interventions_dict[key] = (texts, word_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "interv_to_change = {}\n",
    "for i in range(len(df)):\n",
    "    intervention_labels_data = tuple(df[\"intervention_labels\"].values[i])\n",
    "    if intervention_labels_data in cluster_interventions_dict:\n",
    "        if df[\"clustered_intervention\"].values[i] not in cluster_interventions_dict[intervention_labels_data][0]:\n",
    "            if df[\"clustered_intervention\"].values[i] in interv_to_change:\n",
    "                continue\n",
    "            word_embed_interv = get_embed_for_phrase(df[\"clustered_intervention\"].values[i])\n",
    "            text_embeds = cluster_interventions_dict[intervention_labels_data][1]\n",
    "            scores = []\n",
    "            for j in range(len(text_embeds)):\n",
    "                if sum(text_embeds[j]) >= 0.00001:\n",
    "                    similarity =\\\n",
    "                        round(1 - spatial.distance.cosine(word_embed_interv, text_embeds[j]), 2)\n",
    "                    interv_name = cluster_interventions_dict[intervention_labels_data][0][j]\n",
    "                    interv_stat = 0\n",
    "                    if interv_name in intervention_stats:\n",
    "                        interv_stat = len(intervention_stats[interv_name])\n",
    "                    scores.append((j, similarity, interv_stat))\n",
    "            for r in sorted(scores, key=lambda x: (x[1], x[2]), reverse=True):\n",
    "                interv_to_change[df[\"clustered_intervention\"].values[i]] = cluster_interventions_dict[intervention_labels_data][0][r[0]]\n",
    "                break\n",
    "            if not len(scores):\n",
    "                interv_to_change[df[\"clustered_intervention\"].values[i]] = df[\"clustered_intervention\"].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df[\"clustered_intervention\"].values[i] in interv_to_change:\n",
    "        df[\"clustered_intervention\"].values[i] = interv_to_change[df[\"clustered_intervention\"].values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPLASH provides menstrual hygiene management (MHM) training',\n",
       " 'access to sanitary pad',\n",
       " 'behavior related menstrual hygiene management (MHM)',\n",
       " 'cleaning menstrual blood',\n",
       " 'community led total sanitation (CLTS) maize bushy stunt (MBS) menstrual hygiene management (MHM) research stream',\n",
       " 'container menstruation management',\n",
       " 'create awareness menstruation hygiene management',\n",
       " 'creation menstrual hygiene management (MHM) specific indicator',\n",
       " 'disposal cleaning menstrual blood',\n",
       " 'dispose menstrual blood',\n",
       " 'early menstrual delay',\n",
       " 'early menstrual regulation (MR)',\n",
       " 'excessive menstrual flow',\n",
       " 'feminine hygiene product',\n",
       " 'frequent washing menstrual rag drying sun',\n",
       " 'handling menstrual blood',\n",
       " 'hygiene management menses',\n",
       " 'hygienic management menses',\n",
       " 'hygienic menstrual care',\n",
       " 'improve menstrual hygiene',\n",
       " 'income generating activity (IGA) related menstrual hygiene management (MHM)',\n",
       " 'informational program school preferential trade agreement (PTA) community menstrual hygiene management (MHM) themed event',\n",
       " 'investment menstrual hygiene management (MHM) research programming',\n",
       " 'local pad production',\n",
       " 'maintaining hygiene menses',\n",
       " 'maintenance handwashing collection transport safe storage water menstruation management hip height (HH) visit objective',\n",
       " 'making usable sanitary pad',\n",
       " 'male mfemales total working partner combined sewer overflow (CSO) menstrual hygiene management (MHM)',\n",
       " 'management menstrual blood',\n",
       " 'managing menstrual blood',\n",
       " 'managing menstrual hygiene',\n",
       " 'managing menstruation',\n",
       " 'medicine supply menstrual pain',\n",
       " 'menstrual H',\n",
       " 'menstrual care',\n",
       " 'menstrual discharge',\n",
       " 'menstrual flow',\n",
       " 'menstrual government',\n",
       " 'menstrual hygiene',\n",
       " 'menstrual hygiene day',\n",
       " 'menstrual hygiene facility',\n",
       " 'menstrual hygiene learning',\n",
       " 'menstrual hygiene maleic hydrazide (MH) day wine wastewater (WWW) urea nitrogen compound (UNC) conference',\n",
       " 'menstrual hygiene management (MHM)',\n",
       " 'menstrual hygiene management (MHM) action research task direct funding obligated late year',\n",
       " 'menstrual hygiene management (MHM) education',\n",
       " 'menstrual hygiene management (MHM) practice',\n",
       " 'menstrual hygiene material',\n",
       " 'menstrual hygiene practice',\n",
       " 'menstrual hygiene product supplier',\n",
       " 'menstrual hygiene school',\n",
       " 'menstrual hygiene security pad',\n",
       " 'menstrual hygiene waste ministry health welfare (MHW)',\n",
       " 'menstrual induction',\n",
       " 'menstrual management',\n",
       " 'menstrual management hygiene sanitation',\n",
       " 'menstrual period',\n",
       " 'menstrual period care',\n",
       " 'menstrual period cloth management',\n",
       " 'menstrual period focus group discussion (FGD)',\n",
       " 'menstrual waste',\n",
       " 'menstruation hygiene',\n",
       " 'menstruation management',\n",
       " 'menstruation management behavior',\n",
       " 'menstruation water management (WM)',\n",
       " 'normal menstruation',\n",
       " 'pad',\n",
       " 'pad panty soap booklet puberty',\n",
       " 'program approach menstrual hygiene management (MHM)',\n",
       " 'promote menstrual hygiene',\n",
       " 'promote safe menstrual hygiene practice',\n",
       " 'puberty inclusion menstruation',\n",
       " 'safe handling menstrual blood session learning objective end participant able',\n",
       " 'safe menstrual hygiene practice',\n",
       " 'sanitary pad',\n",
       " 'sanitary pad management',\n",
       " 'sanitary pad management system',\n",
       " 'school fund raised set aside menstrual hygiene management (MHM) support',\n",
       " 'sensitive practical care menstrual period',\n",
       " 'soaking cloth',\n",
       " 'soaking menstrual blood',\n",
       " 'sustainable menstrual hygiene management (MHM) support',\n",
       " 'taboo related menstruation',\n",
       " 'talk directly menstruation',\n",
       " 'talk menstrual period',\n",
       " 'test knowledge management (KM) monitoring evaluation menstrual hygiene (MHM)',\n",
       " 'visual aid menstruation',\n",
       " 'wash blood stained menstrual material',\n",
       " 'washing dryingmenstrual hygiene material',\n",
       " 'water source (WS) construction menstrual hygiene program',\n",
       " 'world menstrual hygiene day'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interventions_set_stratgey = set()\n",
    "for i in range(len(df)):\n",
    "    if '2.e MHM' in df[\"strategy_focus\"].values[i]:\n",
    "        interventions_set_stratgey.add(df[\"clustered_intervention\"].values[i])\n",
    "interventions_set_stratgey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataframe for loading into the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = 0\n",
    "for i in range(len(df)):\n",
    "    df[\"id\"].values[i] = i\n",
    "df[\"comments\"] = \"\"\n",
    "df[\"tags\"] = [([\"Include\"] if i==0 else []) for i in range(len(df))]\n",
    "df[\"edit_url\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    df[\"edit_url\"].values[i] = str(df[\"id\"].values[i])\n",
    "for i in range(len(df)):\n",
    "    #if type(df[\"year\"].values[i]) == str:\n",
    "    #    print(i, df[\"filename\"].values[i])\n",
    "    if df[\"filename\"].values[i] == \"usaid_pdfs/AID-278-C-15-00005.pdf\":\n",
    "        df[\"year\"].values[i] = 2015\n",
    "    if df[\"filename\"].values[i] == \"usaid_pdfs/AID-492-C-13-00013.pdf\":\n",
    "        df[\"year\"].values[i] = 2014\n",
    "    #if df[\"year\"].values[i] < 2000 or df[\"year\"].values[i] > 2020:\n",
    "    #    print(i, df[\"year\"].values[i])\n",
    "for i in range(len(df)):\n",
    "    if type(df[\"year\"].values[i]) == str:\n",
    "        df[\"year\"].values[i] = 2020\n",
    "df[\"intervention_label_probs\"] = 0.0\n",
    "for i in range(len(df)):\n",
    "    thresholds = [th[1] for th in df[\"intervention_thresholds\"].values[i]]\n",
    "    if len(thresholds):\n",
    "        df[\"intervention_label_probs\"].values[i] = np.round(np.mean(thresholds), 3)\n",
    "    else:\n",
    "        df[\"intervention_label_probs\"].values[i] = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260891\n",
      "227188\n"
     ]
    }
   ],
   "source": [
    "# to filter out sentences with Agriculture interventions and Human health interventions without a connection to other intervention types\n",
    "ind_to_take = []\n",
    "for i in range(len(df)):\n",
    "    if \"Agriculture\" in df[\"intervention_labels\"].values[i]:\n",
    "        continue\n",
    "    if \"Human health\" in df[\"intervention_labels\"].values[i] and len(set(df[\"intervention_labels\"].values[i]).intersection([\n",
    "        \"Water infrastructure\", \"Menstrual hygiene management\", \"Sanitation/Hygiene\", \"Water quality\"])) == 0:\n",
    "        continue\n",
    "    ind_to_take.append(i)\n",
    "print(len(df))\n",
    "df = df.take(ind_to_take)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_main_strategy_all = {}\n",
    "for i in range(len(df)):\n",
    "    for strategy in df[\"strategy_focus\"].values[i]:\n",
    "        if df[\"filename\"].values[i] not in doc_main_strategy_all:\n",
    "            doc_main_strategy_all[df[\"filename\"].values[i]] = {}\n",
    "        if strategy not in doc_main_strategy_all[df[\"filename\"].values[i]]:\n",
    "            doc_main_strategy_all[df[\"filename\"].values[i]][strategy] = 0\n",
    "        doc_main_strategy_all[df[\"filename\"].values[i]][strategy] += 1\n",
    "doc_main_strategy = {}\n",
    "for doc in doc_main_strategy_all:\n",
    "    max_strategies = []\n",
    "    max_num = 0\n",
    "    if len(doc_main_strategy_all[doc]):\n",
    "        for strategy in doc_main_strategy_all[doc]:\n",
    "            if doc_main_strategy_all[doc][strategy] > max_num:\n",
    "                max_num = doc_main_strategy_all[doc][strategy]\n",
    "                max_strategies = [strategy]\n",
    "            elif doc_main_strategy_all[doc][strategy] == max_num:\n",
    "                max_strategies.append(strategy)\n",
    "    doc_main_strategy[doc] = max_strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.c Coordination/Platform 460\n",
      "1.b Institutional Strengthening 73\n",
      "2.a Sanitation Demand Creation 51\n",
      "2.c Hygiene Social and Behavior Change 39\n",
      "3.a Professionalization of Rural Services 27\n",
      "3.e Drinking water quality (WQ) 25\n",
      "4.c Water use efficiency & conservation 12\n",
      "4.f Water resources regulation 11\n",
      "1.d Regulatory frameworks 11\n",
      "2.g Sanitation/Hygiene in Institutions 11\n",
      "3.c Rural Water Monitoring 7\n",
      "4.b Watershed protection 6\n",
      "2.e MHM 5\n",
      "4.a Water Resource Management Plans 3\n",
      "3.f Water Access in Instituions 2\n",
      "4.e Adaptation 2\n",
      "3.b Urban water utilities 2\n",
      "1.a Policy 2\n",
      "4.d Land use planning 1\n",
      "2.b Market Based Sanitation 1\n",
      "3.d Piped water services 1\n"
     ]
    }
   ],
   "source": [
    "doc_main_strategy_stat = {}\n",
    "for doc in doc_main_strategy:\n",
    "    for strategy in doc_main_strategy[doc]:\n",
    "        if strategy not in doc_main_strategy_stat:\n",
    "            doc_main_strategy_stat[strategy] = 0\n",
    "        doc_main_strategy_stat[strategy] += 1\n",
    "for k,v in sorted(doc_main_strategy_stat.items(), key=lambda x:x[1], reverse=True):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main_document_strategy_focus\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    if df[\"filename\"].values[i] in doc_main_strategy:\n",
    "        df[\"main_document_strategy_focus\"].values[i] = doc_main_strategy[df[\"filename\"].values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for summarized\n",
    "start_offset = 300000\n",
    "for i in range(len(df)):\n",
    "    df[\"id\"]. values[i] = start_offset + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_data_10.04.2021\\0.xlsx: 54.39s\n",
      "Processed file ../tmp/usaid_data_10.04.2021\\0.xlsx: 92.18s\n",
      "Read file ../tmp/usaid_data_10.04.2021\\1.xlsx: 47.31s\n",
      "Processed file ../tmp/usaid_data_10.04.2021\\1.xlsx: 93.56s\n",
      "Read file ../tmp/usaid_data_10.04.2021\\2.xlsx: 11.89s\n",
      "Processed file ../tmp/usaid_data_10.04.2021\\2.xlsx: 22.43s\n",
      "Read file ../tmp/usaid_data_summarized_10.04.2021\\0.xlsx: 34.26s\n",
      "Processed file ../tmp/usaid_data_summarized_10.04.2021\\0.xlsx: 63.32s\n"
     ]
    }
   ],
   "source": [
    "# only for summarized, run if you have folders with summarized data\n",
    "df_all = excel_reader.ExcelReader().read_df(\"../tmp/usaid_data_10.04.2021\")\n",
    "df = excel_reader.ExcelReader().read_df(\"../tmp/usaid_data_summarized_10.04.2021\")\n",
    "df[\"sentence_source\"] = \"From summarized pages\"\n",
    "for i in range(len(df)):\n",
    "    df[\"sentence_source\"].values[i] = [\"From summarized pages\"]\n",
    "df_all[\"sentence_source\"] = \"From original pages\"\n",
    "for i in range(len(df_all)):\n",
    "    df_all[\"sentence_source\"].values[i] = [\"From original pages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288713 298294\n"
     ]
    }
   ],
   "source": [
    "#only for summarized\n",
    "df_merged = pd.concat([df, df_all])\n",
    "sentence_deduplcated_data = {}\n",
    "ind_to_take = []\n",
    "for i in range(len(df_merged)):\n",
    "    pair_val = (text_normalizer.normalize_sentence(df_merged[\"sentence\"].values[i].strip().lower()),\n",
    "                df_merged[\"filename\"].values[i].strip().lower(),\n",
    "                df_merged[\"intervention\"].values[i].strip().lower())\n",
    "    if pair_val not in sentence_deduplcated_data:\n",
    "        sentence_deduplcated_data[pair_val] = i\n",
    "        ind_to_take.append(i)\n",
    "    else:\n",
    "        df_merged[\"sentence_source\"].values[sentence_deduplcated_data[pair_val]].extend(\n",
    "            df_merged[\"sentence_source\"].values[i])\n",
    "print(len(ind_to_take), len(df_merged))\n",
    "df_merged = df_merged.take(ind_to_take)\n",
    "for i in range(len(df_merged)):\n",
    "    df_merged[\"sentence_source\"].values[i] = list(set(df_merged[\"sentence_source\"].values[i]))\n",
    "df_merged[\"edit_url\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    df_merged[\"edit_url\"].values[i] = str(df_merged[\"id\"].values[i])\n",
    "for i in range(len(df_merged)):\n",
    "    if \"land tenure\" in df_merged[\"intervention\"].values[i] and df_merged[\"clustered_intervention\"].values[i] in [\n",
    "            \"decentralization\", \"payment system\", \"water law\", \"septage management policy\", \"policy development\",\n",
    "            \"decentralization process\"]:\n",
    "        df_merged[\"clustered_intervention\"].values[i] = df_merged[\"intervention\"].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'usaid_articles' Elasticsearch index\n",
      "Preparing bulk operation\n",
      "Indexing 288713 docs...\n",
      "Creating 'usaid_articles' Kibana index pattern object\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "elastic.ElasticClient(\"18.214.78.73:9200\", \"18.214.78.73:5601\",\n",
    "                      os.getenv(\"ELASTIC_USER\"), os.getenv(\"ELASTIC_PASSWORD\")).update_docs(\n",
    "    df_merged,\n",
    "    properties={\n",
    "        'title':      {'type': 'text'},\n",
    "        'sentence':   {'type': 'text'},\n",
    "        'intervention':   {'type': 'keyword'},\n",
    "        \"intervention_labels\": {'type': 'keyword'},\n",
    "        'url':        {'type': 'keyword'},\n",
    "        'author':     {'type': 'keyword'},\n",
    "        'year':       {'type': 'date'},\n",
    "        'affiliation': {'type': 'keyword'},\n",
    "        'countries_mentioned': {'type':'keyword'},\n",
    "        'country_codes': {'type':'keyword'},\n",
    "        'animal_products_search': {'type':'keyword'},\n",
    "        'plant_products_search': {'type':'keyword'},\n",
    "        'normalized_key_words':{'type':'keyword'},\n",
    "        'geo_regions':{'type':'keyword'},\n",
    "        'world_bankdivision_regions':{'type':'keyword'},\n",
    "        \"provinces\":{\"type\":\"keyword\"},\n",
    "        \"districts\":{\"type\":\"keyword\"},\n",
    "        \"gender_age_population_tags\":{\"type\":\"keyword\"},\n",
    "        \"animals_found_details\": {\"type\": \"keyword\"},\n",
    "        \"animals_found\": {\"type\": \"keyword\"},\n",
    "        'animal_products_search_details': {'type':'keyword'},\n",
    "        'plant_products_search_details': {'type':'keyword'},\n",
    "        \"edit_url\": {\"type\": \"keyword\"},\n",
    "        \"comments\": {\"type\": \"text\"},\n",
    "        \"tags\": {\"type\": \"keyword\"},\n",
    "        \"outcomes_found\":{\"type\":\"keyword\"},\n",
    "        \"Ancillary_Data\":{\"type\":\"text\"},\n",
    "        \"Bibliographic_Type\":{\"type\":\"keyword\"},\n",
    "        \"File\":{\"type\":\"keyword\"},\n",
    "        \"Primary_Subject\":{\"type\":\"keyword\"},\n",
    "        \"strategy_focus\":{\"type\":\"keyword\"},\n",
    "        \"strategy_focus_details\":{\"type\":\"keyword\"},\n",
    "        \"Inst_Sponsor\": {\"type\":\"keyword\"},\n",
    "        \"Contract_Grant_Number\": {\"type\":\"keyword\"},\n",
    "        \"Unique_ID\": {\"type\":\"keyword\"},\n",
    "        \"programs_found\": {\"type\":\"keyword\"},\n",
    "        \"page\": {\"type\":\"keyword\"},\n",
    "        \"filename\": {\"type\":\"keyword\"},\n",
    "        \"clustered_intervention\": {'type': 'keyword'},\n",
    "        \"intervention_label_probs\": {'type': 'float'},\n",
    "        \"main_document_strategy_focus\": {'type': 'keyword'},\n",
    "        \"sentence_source\": {'type': 'keyword'}\n",
    "    },\n",
    "    index_name='usaid_articles',\n",
    "    time_field='year',\n",
    "    create_search=False,\n",
    "    drop_index=True,\n",
    "    field_for_url_with_template=\"edit_url\",\n",
    "    fields_for_url=[\"url\", \"File\"],\n",
    "    webservice_edit_host=\"18.214.78.73:8501\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA/PA validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/check_metrics_enriched/Sample_USAID_to_label_SA_PA.xlsx: 0.16s\n",
      "Processed file ../tmp/check_metrics_enriched/Sample_USAID_to_label_SA_PA.xlsx: 0.25s\n",
      "Saving...\n",
      "Saved to ../tmp/sample_USAID_labelled_with_new_model.xlsx\n"
     ]
    }
   ],
   "source": [
    "# run this cell only if you want to reevaluate metrics on new models\n",
    "df_temp = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/check_metrics_enriched/Sample_USAID_to_label_SA_PA.xlsx\")\n",
    "sentence_data = {}\n",
    "all_intervention_labels = set()\n",
    "for i in range(len(df_temp)):\n",
    "    sentence = df_temp[\"sentence\"].values[i]\n",
    "    if sentence not in sentence_data:\n",
    "        sentence_data[sentence] = {\"strategy_focus\": set(), \"strategy_focus_details\":set()}\n",
    "    for label in df_temp[\"intervention_labels\"].values[i]:\n",
    "        all_intervention_labels.add(label)\n",
    "        if label not in sentence_data[sentence]:\n",
    "            sentence_data[sentence][label] = []\n",
    "        sentence_data[sentence][label].append(df_temp[\"intervention\"].values[i])\n",
    "    for column in [\"strategy_focus\", \"strategy_focus_details\"]:\n",
    "        sentence_data[sentence][column].update(df_temp[column].values[i])\n",
    "columns = list(USAIDInterventionLabels.INTERVENTION_LABEL_TO_NUMBER.keys() - set([\"Non-intervention\"]))\n",
    "data_to_save = []\n",
    "for sentence in sentence_data:\n",
    "    data_point = [sentence]\n",
    "    for column in columns:\n",
    "        if column in sentence_data[sentence]:\n",
    "            data_point.append(\";\".join(sentence_data[sentence][column]))\n",
    "        else:\n",
    "            data_point.append(\"\")\n",
    "    data_point.append(\";\".join(sentence_data[sentence][\"strategy_focus\"]))\n",
    "    data_point.append(\";\".join(sentence_data[sentence][\"strategy_focus_details\"]))\n",
    "    data_to_save.append(data_point)\n",
    "excel_writer.ExcelWriter().save_data_in_excel(data_to_save, [\"Sentence\"] + columns + [\"strategy_focus\", \"strategy_focus_details\"], \"../tmp/sample_USAID_labelled_with_new_model.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/sample_USAID_labelled_with_new_model.xlsx: 0.04s\n",
      "Processed file ../tmp/sample_USAID_labelled_with_new_model.xlsx: 0.02s\n",
      "Read file ../tmp/Sample_USAID_labelled_SA_PA.xlsx: 0.03s\n",
      "Processed file ../tmp/Sample_USAID_labelled_SA_PA.xlsx: 0.02s\n",
      "Total sentences number:  266\n"
     ]
    }
   ],
   "source": [
    "to_evaluate_df = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/sample_USAID_labelled_with_new_model.xlsx\")\n",
    "to_evaluate_df_dict = {}\n",
    "for i in range(len(to_evaluate_df)):\n",
    "    to_evaluate_df_dict[to_evaluate_df[\"Sentence\"].values[i]] = set(\n",
    "        [r.split(\" \")[0].strip() for r in to_evaluate_df[\"strategy_focus\"].values[i].split(\";\") if r.strip()])\n",
    "\n",
    "manually_labelled_df = excel_reader.ExcelReader().read_df_from_excel(\"../tmp/Sample_USAID_labelled_SA_PA.xlsx\")\n",
    "manually_labelled_df_dict = {}\n",
    "for i in range(len(manually_labelled_df)):\n",
    "    manually_labelled_df_dict[manually_labelled_df[\"Sentence\"].values[i]] = set(\n",
    "        [r.strip() for r in manually_labelled_df[\"strategy_focus\"].values[i].split(\";\") if r.strip()])\n",
    "\n",
    "for sentence in manually_labelled_df_dict:\n",
    "    if sentence not in to_evaluate_df_dict:\n",
    "        to_evaluate_df_dict[sentence] = set()\n",
    "\n",
    "all_labels = set()\n",
    "for sentence in manually_labelled_df_dict:\n",
    "    all_labels.update(manually_labelled_df_dict[sentence])\n",
    "for sentence in to_evaluate_df_dict:\n",
    "    all_labels.update(to_evaluate_df_dict[sentence])\n",
    "    \n",
    "print(\"Total sentences number: \", len(manually_labelled_df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.a\n",
      "Total number of correct sentences with SA/PA:  17\n",
      "F1:  0.8484848484848485\n",
      "[[ 0  2]\n",
      " [ 3 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.88      0.82      0.85        17\n",
      "\n",
      "   micro avg       0.74      0.74      0.74        19\n",
      "   macro avg       0.44      0.41      0.42        19\n",
      "weighted avg       0.78      0.74      0.76        19\n",
      "\n",
      "1.b\n",
      "Total number of correct sentences with SA/PA:  27\n",
      "F1:  0.5714285714285714\n",
      "[[ 0 13]\n",
      " [11 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.55      0.59      0.57        27\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        40\n",
      "   macro avg       0.28      0.30      0.29        40\n",
      "weighted avg       0.37      0.40      0.39        40\n",
      "\n",
      "1.c\n",
      "Total number of correct sentences with SA/PA:  63\n",
      "F1:  0.7343749999999999\n",
      "[[ 0 18]\n",
      " [16 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.72      0.75      0.73        63\n",
      "\n",
      "   micro avg       0.58      0.58      0.58        81\n",
      "   macro avg       0.36      0.37      0.37        81\n",
      "weighted avg       0.56      0.58      0.57        81\n",
      "\n",
      "1.d\n",
      "Total number of correct sentences with SA/PA:  15\n",
      "F1:  0.8000000000000002\n",
      "[[ 0  3]\n",
      " [ 3 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.80      0.80        15\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        18\n",
      "   macro avg       0.40      0.40      0.40        18\n",
      "weighted avg       0.67      0.67      0.67        18\n",
      "\n",
      "1.e\n",
      "Total number of correct sentences with SA/PA:  16\n",
      "F1:  0.6666666666666666\n",
      "[[0 2]\n",
      " [7 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.82      0.56      0.67        16\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        18\n",
      "   macro avg       0.41      0.28      0.33        18\n",
      "weighted avg       0.73      0.50      0.59        18\n",
      "\n",
      "1.f\n",
      "Total number of correct sentences with SA/PA:  11\n",
      "F1:  1.0\n",
      "[[11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "1.g\n",
      "Total number of correct sentences with SA/PA:  7\n",
      "F1:  0.4444444444444445\n",
      "[[0 0]\n",
      " [5 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.29      0.44         7\n",
      "\n",
      "   micro avg       0.29      0.29      0.29         7\n",
      "   macro avg       0.50      0.14      0.22         7\n",
      "weighted avg       1.00      0.29      0.44         7\n",
      "\n",
      "2.a\n",
      "Total number of correct sentences with SA/PA:  24\n",
      "F1:  0.7307692307692307\n",
      "[[ 0  9]\n",
      " [ 5 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.68      0.79      0.73        24\n",
      "\n",
      "   micro avg       0.58      0.58      0.58        33\n",
      "   macro avg       0.34      0.40      0.37        33\n",
      "weighted avg       0.49      0.58      0.53        33\n",
      "\n",
      "2.b\n",
      "Total number of correct sentences with SA/PA:  9\n",
      "F1:  0.7058823529411765\n",
      "[[0 2]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.75      0.67      0.71         9\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        11\n",
      "   macro avg       0.38      0.33      0.35        11\n",
      "weighted avg       0.61      0.55      0.58        11\n",
      "\n",
      "2.c\n",
      "Total number of correct sentences with SA/PA:  24\n",
      "F1:  0.8181818181818182\n",
      "[[ 0  2]\n",
      " [ 6 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.90      0.75      0.82        24\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        26\n",
      "   macro avg       0.45      0.38      0.41        26\n",
      "weighted avg       0.83      0.69      0.76        26\n",
      "\n",
      "2.d\n",
      "Total number of correct sentences with SA/PA:  5\n",
      "F1:  0.888888888888889\n",
      "[[0 0]\n",
      " [1 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.80      0.89         5\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.50      0.40      0.44         5\n",
      "weighted avg       1.00      0.80      0.89         5\n",
      "\n",
      "2.e\n",
      "Total number of correct sentences with SA/PA:  11\n",
      "F1:  1.0\n",
      "[[11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "2.f\n",
      "Total number of correct sentences with SA/PA:  15\n",
      "F1:  0.846153846153846\n",
      "[[ 0  0]\n",
      " [ 4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.73      0.85        15\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        15\n",
      "   macro avg       0.50      0.37      0.42        15\n",
      "weighted avg       1.00      0.73      0.85        15\n",
      "\n",
      "2.g\n",
      "Total number of correct sentences with SA/PA:  11\n",
      "F1:  0.9\n",
      "[[0 0]\n",
      " [2 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.82      0.90        11\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n",
      "3.a\n",
      "Total number of correct sentences with SA/PA:  27\n",
      "F1:  0.711864406779661\n",
      "[[ 0 11]\n",
      " [ 6 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.66      0.78      0.71        27\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        38\n",
      "   macro avg       0.33      0.39      0.36        38\n",
      "weighted avg       0.47      0.55      0.51        38\n",
      "\n",
      "3.b\n",
      "Total number of correct sentences with SA/PA:  9\n",
      "F1:  0.8\n",
      "[[0 0]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80         9\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         9\n",
      "   macro avg       0.50      0.33      0.40         9\n",
      "weighted avg       1.00      0.67      0.80         9\n",
      "\n",
      "3.c\n",
      "Total number of correct sentences with SA/PA:  10\n",
      "F1:  0.9473684210526316\n",
      "[[0 0]\n",
      " [1 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        10\n",
      "   macro avg       0.50      0.45      0.47        10\n",
      "weighted avg       1.00      0.90      0.95        10\n",
      "\n",
      "3.d\n",
      "Total number of correct sentences with SA/PA:  9\n",
      "F1:  0.7999999999999999\n",
      "[[0 3]\n",
      " [1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.73      0.89      0.80         9\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        12\n",
      "   macro avg       0.36      0.44      0.40        12\n",
      "weighted avg       0.55      0.67      0.60        12\n",
      "\n",
      "3.e\n",
      "Total number of correct sentences with SA/PA:  14\n",
      "F1:  0.75\n",
      "[[0 1]\n",
      " [5 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.90      0.64      0.75        14\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        15\n",
      "   macro avg       0.45      0.32      0.38        15\n",
      "weighted avg       0.84      0.60      0.70        15\n",
      "\n",
      "3.f\n",
      "Total number of correct sentences with SA/PA:  6\n",
      "F1:  0.9090909090909091\n",
      "[[0 0]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.83      0.91         6\n",
      "\n",
      "   micro avg       0.83      0.83      0.83         6\n",
      "   macro avg       0.50      0.42      0.45         6\n",
      "weighted avg       1.00      0.83      0.91         6\n",
      "\n",
      "4.a\n",
      "Total number of correct sentences with SA/PA:  27\n",
      "F1:  0.6666666666666666\n",
      "[[ 0  5]\n",
      " [11 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.76      0.59      0.67        27\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        32\n",
      "   macro avg       0.38      0.30      0.33        32\n",
      "weighted avg       0.64      0.50      0.56        32\n",
      "\n",
      "4.b\n",
      "Total number of correct sentences with SA/PA:  12\n",
      "F1:  0.8571428571428571\n",
      "[[0 0]\n",
      " [3 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.75      0.86        12\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        12\n",
      "   macro avg       0.50      0.38      0.43        12\n",
      "weighted avg       1.00      0.75      0.86        12\n",
      "\n",
      "4.c\n",
      "Total number of correct sentences with SA/PA:  31\n",
      "F1:  0.6545454545454547\n",
      "[[ 0  6]\n",
      " [13 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.75      0.58      0.65        31\n",
      "\n",
      "   micro avg       0.49      0.49      0.49        37\n",
      "   macro avg       0.38      0.29      0.33        37\n",
      "weighted avg       0.63      0.49      0.55        37\n",
      "\n",
      "4.d\n",
      "Total number of correct sentences with SA/PA:  8\n",
      "F1:  0.9333333333333333\n",
      "[[0 0]\n",
      " [1 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.88      0.88      0.88         8\n",
      "   macro avg       0.50      0.44      0.47         8\n",
      "weighted avg       1.00      0.88      0.93         8\n",
      "\n",
      "4.e\n",
      "Total number of correct sentences with SA/PA:  8\n",
      "F1:  0.7999999999999999\n",
      "[[0 1]\n",
      " [2 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      0.75      0.80         8\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         9\n",
      "   macro avg       0.43      0.38      0.40         9\n",
      "weighted avg       0.76      0.67      0.71         9\n",
      "\n",
      "4.f\n",
      "Total number of correct sentences with SA/PA:  17\n",
      "F1:  0.7096774193548386\n",
      "[[ 0  3]\n",
      " [ 6 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.79      0.65      0.71        17\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        20\n",
      "   macro avg       0.39      0.32      0.35        20\n",
      "weighted avg       0.67      0.55      0.60        20\n",
      "\n",
      "Average SA/PA F1-score:  0.741347573380306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "avg = 0\n",
    "for label in sorted(all_labels):\n",
    "    print(label)\n",
    "    results_to_check = []\n",
    "    results_true = []\n",
    "    for sentence in to_evaluate_df_dict:\n",
    "        if sentence in manually_labelled_df_dict:\n",
    "            if label in to_evaluate_df_dict[sentence] or label in manually_labelled_df_dict[sentence]:\n",
    "                results_to_check.append(int(label in to_evaluate_df_dict[sentence]))\n",
    "                results_true.append(int(label in manually_labelled_df_dict[sentence]))\n",
    "    if len(results_true):\n",
    "        print(\"Total number of correct sentences with SA/PA: \", sum(results_true))\n",
    "        print(\"F1: \", sklearn.metrics.f1_score(results_true, results_to_check, average=\"binary\"))\n",
    "        print(sklearn.metrics.confusion_matrix(results_true, results_to_check))\n",
    "        print(sklearn.metrics.classification_report(results_true, results_to_check))\n",
    "        avg += sklearn.metrics.recall_score(results_true, results_to_check, average=\"binary\")\n",
    "print(\"Average SA/PA F1-score: \", avg/len(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcomes experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pool of sentences to label outcomes\n",
    "If you have a file with sentences you don't need to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_values = []\n",
    "for i in range(len(articles_df)):\n",
    "    for sent in [s for s in sent_tokenize(articles_df[\"abstract\"].values[i]) if \"?\" not in s]:\n",
    "        new_df_values.append(sent)\n",
    "new_df = pd.DataFrame(new_df_values, columns=[\"abstract\"])\n",
    "new_df[\"title\"] = \"\"\n",
    "new_df[\"keywords\"] = \"\"\n",
    "new_df[\"identificators\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file all_sentences.xlsx: 122.30s\n",
      "Processed file all_sentences.xlsx: 159.86s\n"
     ]
    }
   ],
   "source": [
    "new_df = excel_reader.ExcelReader().read_df_from_excel(\"all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing import search_engine_insensitive_to_spelling\n",
    "use_saved = True\n",
    "small_search_engine_inverted_index = search_engine_insensitive_to_spelling.SearchEngineInsensitiveToSpelling(load_abbreviations = True)\n",
    "if use_saved:\n",
    "    small_search_engine_inverted_index.load_model(\"../model/search_index_outcomes_df\")\n",
    "else:\n",
    "    small_search_engine_inverted_index.create_inverted_index(new_df)\n",
    "    small_search_engine_inverted_index.save_model(\"../model/search_index_outcomes_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing  {'column_filler_class': 'ColumnFiller', 'column_name': 'outcomes_found', 'column_details': 'outcomes_details', 'column_dictionary': '../data/outcomes_dictionary.xlsx'}\n",
      "High level label: Soil health\n",
      "High level label: Water use\n",
      "High level label: Fertilizer use\n",
      "High level label: Gender\n",
      "High level label: Market access\n",
      "High level label: Nutrition\n",
      "High level label: Resilience\n",
      "High level label: Production\n",
      "High level label: Livelihood\n",
      "High level label: Greenhouse gas emissions\n",
      "Labelled articles with outcomes: 295216\n",
      "Processed for 39.051207542419434s\n"
     ]
    }
   ],
   "source": [
    "from interventions_labeling_lib import interventions_search_for_labeling\n",
    "interventions_search_for_labeling = reload(interventions_search_for_labeling)\n",
    "from text_processing import all_column_filler\n",
    "all_column_filler = reload(all_column_filler)\n",
    "\n",
    "_all_column_filler = all_column_filler.AllColumnFiller()\n",
    "new_df = _all_column_filler.fill_columns_for_df(new_df, small_search_engine_inverted_index, _abbreviations_resolver,settings_json = {\"columns\":[\n",
    "   {\"column_filler_class\":\"ColumnFiller\", \"column_name\": \"outcomes_found\", \"column_details\": \"outcomes_details\", \"column_dictionary\":\"../data/outcomes_dictionary.xlsx\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"Keyword_increase\"] = \"\"\n",
    "for i in small_search_engine_inverted_index.find_articles_with_keywords([\"increase\", \"increasing\", \"strengthen\", \"boost\", \"improve\", \"improving\",\n",
    "             \"strengthening\", \"reduce\", \"reducing\", \"decrease\", \"decreasing\", \"enhance\", \"enhancing\", \"raise\", \"raising\",\n",
    "             \"higher\", \"lower\", \"increase\", \"decrease\", \"enhance\", \"improve\", \"promote\", \"boost\", \"expand\", \n",
    "                     \"increased\", \"increasing\", \"decreased\", \"decreasing\", \"enhancing\", \"enhanced\",\n",
    "                    \"improved\", \"improving\", \"promoted\", \"promoting\", \"boosted\", \"boosting\", \"expanding\",\n",
    "                    \"expanded\"]):\n",
    "    new_df[\"Keyword_increase\"].values[i] = \"Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137131"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df[new_df[\"Keyword_increase\"] != \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to all_sentences.xlsx\n"
     ]
    }
   ],
   "source": [
    "excel_writer.ExcelWriter().save_df_in_excel(new_df, \"all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a file with outcomes to label manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = excel_reader.ExcelReader().read_df_from_excel(\"all_sentences.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../data/outcomes_dictionary.xlsx: 0.18s\n",
      "Processed file ../data/outcomes_dictionary.xlsx: 0.01s\n"
     ]
    }
   ],
   "source": [
    "outcomes_map = {}\n",
    "outcomes_df = excel_reader.ExcelReader().read_df_from_excel(\"../data/outcomes_dictionary.xlsx\")\n",
    "for i in range(len(outcomes_df)):\n",
    "    if outcomes_df[\"High level label\"].values[i] not in outcomes_map:\n",
    "        outcomes_map[outcomes_df[\"High level label\"].values[i]] = []\n",
    "    outcomes_map[outcomes_df[\"High level label\"].values[i]].append(outcomes_df[\"Keyword\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df[new_df[\"Taken\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_words = {}\n",
    "for i in range(len(new_df)):\n",
    "    if new_df[\"Taken\"].values[i] == 1:\n",
    "        continue\n",
    "    if new_df[\"Keyword_increase\"].values[i].strip() == \"\":\n",
    "        continue\n",
    "    for outcome_detail in new_df[\"outcomes_details\"].values[i]:\n",
    "        outcome_detail = re.sub(\"\\s+\", \" \", re.sub(\"\\(.*?\\)\", \"\", outcome_detail)).strip()\n",
    "        if outcome_detail in outcomes_map[\"Greenhouse gas emissions\"]:\n",
    "            if outcome_detail not in found_words:\n",
    "                found_words[outcome_detail] = []\n",
    "            found_words[outcome_detail].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "environmental impact 336\n",
      "greenhouse gas emission 1038\n",
      "greenhouse gas 760\n",
      "gas emission 258\n",
      "carbon emission 107\n",
      "carbon footprint 125\n",
      "methane emission 48\n",
      "emission greenhouse gas 49\n",
      "nitrous oxide emission 48\n",
      "global warming potential 19\n",
      "CO2 emission 55\n",
      "net GHG emission 3\n"
     ]
    }
   ],
   "source": [
    "print(len(found_words))\n",
    "for key in found_words:\n",
    "    print(key, len(found_words[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_take = []\n",
    "for word in found_words:\n",
    "    ind_to_take.extend(list(np.random.choice(found_words[word], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ind_to_take:\n",
    "    new_df[\"Taken\"].values[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_choose = {\"increase\": [], \"wo increase\": []}\n",
    "for i in small_search_engine_inverted_index.find_articles_with_keywords([\"price\"]):\n",
    "    if new_df[\"Taken\"].values[i] == 0:\n",
    "        if new_df[\"Keyword_increase\"].values[i].strip() == \"\":\n",
    "            indices_to_choose[\"wo increase\"].append(i)\n",
    "        else:\n",
    "            indices_to_choose[\"increase\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "increase 3707\n",
      "wo increase 8416\n",
      "demand\n",
      "increase 3384\n",
      "wo increase 5883\n",
      "market\n",
      "increase 7279\n",
      "wo increase 23804\n",
      "importation\n",
      "increase 45\n",
      "wo increase 136\n",
      "import\n",
      "increase 471\n",
      "wo increase 1151\n",
      "export\n",
      "increase 1032\n",
      "wo increase 3448\n",
      "consumer\n",
      "increase 1279\n",
      "wo increase 4742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_take = set()\n",
    "for w in [\"price\", \"demand\", \"market\", \"importation\", \"import\", \"export\", \"consumer\"]:\n",
    "    indices_to_choose = {\"increase\": [], \"wo increase\": []}\n",
    "    for i in small_search_engine_inverted_index.find_articles_with_keywords([w]):\n",
    "        if new_df[\"Taken\"].values[i] == 0:\n",
    "            if new_df[\"Keyword_increase\"].values[i].strip() == \"\":\n",
    "                indices_to_choose[\"wo increase\"].append(i)\n",
    "            else:\n",
    "                indices_to_choose[\"increase\"].append(i)\n",
    "    print(w)\n",
    "    for key in indices_to_choose:\n",
    "        print(key, len(indices_to_choose[key]))\n",
    "        if len(indices_to_choose[key]):\n",
    "            ind_to_take.update(list(np.random.choice(indices_to_choose[key], 5)))\n",
    "len(ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase 3707\n",
      "wo increase 8416\n"
     ]
    }
   ],
   "source": [
    "for key in indices_to_choose:\n",
    "    print(key, len(indices_to_choose[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(np.random.choice(indices_to_choose[\"increase\"], 25))\n",
    "b = list(np.random.choice(indices_to_choose[\"wo increase\"], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_take = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_take = ind_to_take + a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_take = list(set(ind_to_take))\n",
    "len(ind_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saved to train_outcome_market_access_4.xlsx\n"
     ]
    }
   ],
   "source": [
    "outcome_classes = [\"Soil health\", \"Fertilizer use\", \"Water use\", \"Gender\", \"Greenhouse gas emissions\",\n",
    "                  \"Livelihood\", \"Market access\", \"Nutrition\", \"Production\", \"Resilience\", 'Knowledge sharing', \n",
    "                   'Practice change', 'Social inclusion', 'Poverty reduction', 'Environment impact']\n",
    "excel_writer.ExcelWriter().save_df_in_excel(\n",
    "    pd.concat([new_df[[\"abstract\"]].take(ind_to_take).rename({\"abstract\": \"Sentence\"}, axis=1).reset_index()[[\"Sentence\"]],\n",
    "               pd.DataFrame([[\"\"]*len(outcome_classes)]*len(ind_to_take), columns=outcome_classes)], axis=1), f\"train_outcome_{int(time())}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train outcomes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_DATA, outcomes_train_label_data, outcomes_sentences_train_data, EVAL_DATA, outcomes_eval_label_data, outcomes_sentences_eval_data = pickle.load(\n",
    "    open(\"../tmp/outcomes-2610_train_data\", \"rb\"))\n",
    "TRAIN_DATA = shuffle(TRAIN_DATA)\n",
    "outcomes_train_label_data = shuffle(outcomes_train_label_data)\n",
    "outcomes_sentences_train_data = shuffle(outcomes_sentences_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Livelihood                  463\n",
       "Production                  405\n",
       "Greenhouse gas emissions    232\n",
       "Market access               222\n",
       "Nutrition                   208\n",
       "Resilience                  198\n",
       "Soil health                 179\n",
       "Practice change             157\n",
       "Gender                      147\n",
       "Fertilizer use              128\n",
       "Water use                   128\n",
       "Knowledge sharing           125\n",
       "Environment impact          117\n",
       "Social inclusion            106\n",
       "Poverty reduction           103\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outcomes_train_label_data, columns=[\"Text\", \"Label\"])[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Livelihood                  45\n",
       "Production                  44\n",
       "Nutrition                   26\n",
       "Greenhouse gas emissions    24\n",
       "Resilience                  22\n",
       "Market access               21\n",
       "Soil health                 21\n",
       "Practice change             18\n",
       "Gender                      16\n",
       "Knowledge sharing           14\n",
       "Fertilizer use              14\n",
       "Environment impact          13\n",
       "Social inclusion            13\n",
       "Water use                   13\n",
       "Poverty reduction           12\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outcomes_eval_label_data, columns=[\"Text\", \"Label\"])[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Livelihood', 'Soil health', 'Fertilizer use', 'Water use', 'Gender',\n",
    "           'Greenhouse gas emissions', 'Market access', 'Nutrition',\n",
    "           'Production', 'Resilience', 'Knowledge sharing', 'Practice change',\n",
    "           'Social inclusion', 'Poverty reduction', 'Environment impact']\n",
    "labels2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "def prepare_multilabel_data(outcomes_train_label_data):\n",
    "    gathred_data = []\n",
    "    dict_label = {}\n",
    "    for i in range(len(outcomes_train_label_data)):\n",
    "        if outcomes_train_label_data[i][0] not in dict_label:\n",
    "            dict_label[outcomes_train_label_data[i][0]] = set()\n",
    "        dict_label[outcomes_train_label_data[i][0]].add(outcomes_train_label_data[i][1])\n",
    "    for key, value in dict_label.items():\n",
    "        gathred_data.append((key, [(1 if label in value else 0) for label in labels]))\n",
    "    return pd.DataFrame(gathred_data, columns=[\"text\", \"label\"])\n",
    "\n",
    "train_df = prepare_multilabel_data(outcomes_train_label_data)\n",
    "test_df = prepare_multilabel_data(outcomes_eval_label_data)\n",
    "test_res = []\n",
    "for i in range(len(test_df)):\n",
    "    id_labels = set()\n",
    "    for _idx in range(len(test_df[\"label\"].values[i])):\n",
    "        if test_df[\"label\"].values[i][_idx] == 1:\n",
    "            id_labels.add(_idx + 1)\n",
    "    if not id_labels:\n",
    "        id_labels.add(len(labels) + 1)\n",
    "    test_res.append(id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "WARNING:tensorflow:From C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014613EAA898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014613EAA898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n"
     ]
    }
   ],
   "source": [
    "from outcomes_modelling import outcomes_sentence_labeler\n",
    "outcomes_sentence_labeler = reload(outcomes_sentence_labeler)\n",
    "_outcomes_sentence_labeler = outcomes_sentence_labeler.OutcomesSentenceLabeler(\n",
    "    \"../model/bert_exp_outcome_sentences_new_multilabel_15epoch_1300_mixed_0.7\",\n",
    "    gpu_device_num=0, multilabel=True, label_list=list(range(len(labels))),\n",
    "    epoch_num=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _outcomes_sentence_labeler.train_model(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 273\n",
      "F1 measure(multilabel):  0.6471306471306469\n",
      "Accuracy(multilabel):  0.6776556776556777\n",
      "Per label statistics\n",
      "Livelihood\n",
      "[[225   3]\n",
      " [ 16  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       228\n",
      "           1       0.91      0.64      0.75        45\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       273\n",
      "   macro avg       0.92      0.82      0.86       273\n",
      "weighted avg       0.93      0.93      0.93       273\n",
      "\n",
      "F1 score:  0.856367513083931\n",
      "Soil health\n",
      "[[251   1]\n",
      " [  9  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       252\n",
      "           1       0.92      0.57      0.71        21\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       273\n",
      "   macro avg       0.94      0.78      0.84       273\n",
      "weighted avg       0.96      0.96      0.96       273\n",
      "\n",
      "F1 score:  0.8431755514705883\n",
      "Fertilizer use\n",
      "[[259   0]\n",
      " [  4  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       259\n",
      "           1       1.00      0.71      0.83        14\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       273\n",
      "   macro avg       0.99      0.86      0.91       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "F1 score:  0.9128352490421456\n",
      "Water use\n",
      "[[258   2]\n",
      " [  2  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       260\n",
      "           1       0.85      0.85      0.85        13\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       273\n",
      "   macro avg       0.92      0.92      0.92       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "F1 score:  0.9192307692307693\n",
      "Gender\n",
      "[[257   0]\n",
      " [  3  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       257\n",
      "           1       1.00      0.81      0.90        16\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       273\n",
      "   macro avg       0.99      0.91      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "F1 score:  0.9453745081037818\n",
      "Greenhouse gas emissions\n",
      "[[249   0]\n",
      " [  0  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       249\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       273\n",
      "   macro avg       1.00      1.00      1.00       273\n",
      "weighted avg       1.00      1.00      1.00       273\n",
      "\n",
      "F1 score:  1.0\n",
      "Market access\n",
      "[[252   0]\n",
      " [ 12   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       252\n",
      "           1       1.00      0.43      0.60        21\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       273\n",
      "   macro avg       0.98      0.71      0.79       273\n",
      "weighted avg       0.96      0.96      0.95       273\n",
      "\n",
      "F1 score:  0.7883720930232558\n",
      "Nutrition\n",
      "[[245   2]\n",
      " [ 12  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       247\n",
      "           1       0.88      0.54      0.67        26\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       273\n",
      "   macro avg       0.91      0.77      0.82       273\n",
      "weighted avg       0.95      0.95      0.94       273\n",
      "\n",
      "F1 score:  0.8194444444444444\n",
      "Production\n",
      "[[228   1]\n",
      " [ 15  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       229\n",
      "           1       0.97      0.66      0.78        44\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       273\n",
      "   macro avg       0.95      0.83      0.87       273\n",
      "weighted avg       0.94      0.94      0.94       273\n",
      "\n",
      "F1 score:  0.874942739349519\n",
      "Resilience\n",
      "[[250   1]\n",
      " [ 10  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       251\n",
      "           1       0.92      0.55      0.69        22\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       273\n",
      "   macro avg       0.94      0.77      0.83       273\n",
      "weighted avg       0.96      0.96      0.95       273\n",
      "\n",
      "F1 score:  0.8320939334637965\n",
      "Knowledge sharing\n",
      "[[259   0]\n",
      " [  8   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       259\n",
      "           1       1.00      0.43      0.60        14\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       273\n",
      "   macro avg       0.99      0.71      0.79       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "F1 score:  0.7923954372623574\n",
      "Practice change\n",
      "[[254   1]\n",
      " [ 13   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       255\n",
      "           1       0.83      0.28      0.42        18\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       273\n",
      "   macro avg       0.89      0.64      0.69       273\n",
      "weighted avg       0.94      0.95      0.94       273\n",
      "\n",
      "F1 score:  0.6949233716475096\n",
      "Social inclusion\n",
      "[[259   1]\n",
      " [  7   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       260\n",
      "           1       0.86      0.46      0.60        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       273\n",
      "   macro avg       0.92      0.73      0.79       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "F1 score:  0.7923954372623574\n",
      "Poverty reduction\n",
      "[[261   0]\n",
      " [  2  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       261\n",
      "           1       1.00      0.83      0.91        12\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       273\n",
      "   macro avg       1.00      0.92      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "F1 score:  0.9526370575988896\n",
      "Environment impact\n",
      "[[259   1]\n",
      " [  7   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       260\n",
      "           1       0.86      0.46      0.60        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       273\n",
      "   macro avg       0.92      0.73      0.79       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "F1 score:  0.7923954372623574\n",
      "Average  0.8544389028163801\n"
     ]
    }
   ],
   "source": [
    "res_prob, res_label, _ = _outcomes_sentence_labeler.predict_for_df(test_df)\n",
    "\n",
    "print(\"F1 measure(multilabel): \", get_f1_multi_label(res_prob, test_res, max_label=len(labels)+1))\n",
    "print(\"Accuracy(multilabel): \",get_accuracy_multi_label(res_prob, test_res, max_label=len(labels)+1))\n",
    "print(\"Per label statistics\")\n",
    "print_per_label_stats(test_res, res_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_interv_data_to_train\\jaron_labelled_usaid.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\jaron_labelled_usaid.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_1.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_1.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_12.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_12.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_2.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_2.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_3.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_3.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\matu_labelled_new.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\matu_labelled_new.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_2.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_2.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_3.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_3.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_4.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_4.xlsx: 0.01s\n"
     ]
    }
   ],
   "source": [
    "excel_reader = reload(excel_reader)\n",
    "train_df = excel_reader.ExcelReader().read_folder(\"../tmp/usaid_interv_data_to_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/usaid_interv_data_to_train\\jaron_labelled_usaid.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\jaron_labelled_usaid.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_new.xlsx: 0.03s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_new.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_1.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_1.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_12.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_12.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_2.xlsx: 0.04s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_2.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_3.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\mary_labelled_usaid_3.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\PA00HWHP_labeled.xlsx: 0.01s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\PA00HWHP_labeled.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_2.xlsx: 0.04s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_2.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_3.xlsx: 0.02s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_3.xlsx: 0.01s\n",
      "Read file ../tmp/usaid_interv_data_to_train\\test_usaid_4.xlsx: 0.03s\n",
      "Processed file ../tmp/usaid_interv_data_to_train\\test_usaid_4.xlsx: 0.01s\n",
      "All data  1586\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "y = []\n",
    "outcomes_data_folder = \"../tmp/usaid_interv_data_to_train\"\n",
    "for file in os.listdir(outcomes_data_folder):\n",
    "    df_outcome_mary = excel_reader.ExcelReader().read_df_from_excel(os.path.join(outcomes_data_folder, file))\n",
    "    for i in range(len(df_outcome_mary)):\n",
    "        outcomes = []\n",
    "        outcomes_per_label = []\n",
    "        outcomes_labels = []\n",
    "        for column in [\"Sanitation/Hygiene\", \"Water quality/Human health\", \"Water infrastructure\",\n",
    "                       \"Sustainability/Environmental health\", \"Community and behavior\",\n",
    "                       \"Assessment tool or program\", \"Policy\", \"Agriculture\"]:\n",
    "            outcomes_found = set([outcome for outcome in df_outcome_mary[column].values[i].split(\";\") if outcome.strip()])\n",
    "            outcomes.extend(outcomes_found)\n",
    "            for outcome in outcomes_found:\n",
    "                outcomes_per_label.append((outcome, column))\n",
    "            \n",
    "            outcomes_labels.append(1 if len(outcomes_found) else 0)\n",
    "        y.append(outcomes_labels)\n",
    "        outcomes_found = set()\n",
    "        for sent in nltk.sent_tokenize(df_outcome_mary[\"Sentence\"].values[i]):\n",
    "            found_entities = []\n",
    "            found_outcome_plus_labels = []\n",
    "            for outcome, label in outcomes_per_label:\n",
    "                outcome = outcome.strip().strip(\",\").strip(\".\").strip()\n",
    "                if outcome.lower() in sent.lower():\n",
    "                    start_ind = sent.lower().rfind(outcome.lower())\n",
    "                    end_ind = start_ind + len(outcome)\n",
    "                    if sent[start_ind: end_ind].lower() != outcome.lower():\n",
    "                        print(sent)\n",
    "                        print(start_ind, end_ind)\n",
    "                        print(sent[start_ind: end_ind])\n",
    "                        print(sent[start_ind: end_ind].lower(), outcome.lower())\n",
    "                    found_entities.append((start_ind, end_ind, 'OUTCOME'))\n",
    "                    outcomes_found.add(outcome)\n",
    "                    found_outcome_plus_labels.append((outcome, label))\n",
    "            all_data.append((sent, {'entities': found_entities}, found_outcome_plus_labels))\n",
    "        if len(outcomes_found) != len(set(outcomes)):\n",
    "            print(outcomes, outcomes_found)\n",
    "            print(i)\n",
    "print(\"All data \", len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../tmp/outcomes_data\\train_dfs_outcomes.xlsx: 0.10s\n",
      "Processed file ../tmp/outcomes_data\\train_dfs_outcomes.xlsx: 0.10s\n",
      "Read file ../tmp/outcomes_data\\train_fertilizer_4.xlsx: 0.05s\n",
      "Processed file ../tmp/outcomes_data\\train_fertilizer_4.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_gender.xlsx: 0.06s\n",
      "Processed file ../tmp/outcomes_data\\train_gender.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_mary_fertilizer.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_mary_fertilizer.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_mary_water.xlsx: 0.05s\n",
      "Processed file ../tmp/outcomes_data\\train_mary_water.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_.xlsx: 0.05s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_3.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_3.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_4.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_4.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_5.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_5.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_6.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_6.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_7.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_7.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_GHG_8.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_GHG_8.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_livelihood.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_livelihood.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_market_access.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_market_access.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_market_access_2.xlsx: 0.05s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_market_access_2.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_Mary.xlsx: 0.05s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_Mary.xlsx: 0.06s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_Mary_2.xlsx: 0.06s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_Mary_2.xlsx: 0.06s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_Mary_3.xlsx: 0.12s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_Mary_3.xlsx: 0.14s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_Mary_4.xlsx: 0.08s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_Mary_4.xlsx: 0.14s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_nutrition.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_nutrition.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_poverty_2.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_poverty_2.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_poverty_reduction.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_poverty_reduction.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_practice_change_2.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_practice_change_2.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_production.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_production.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_resilience.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_resilience.xlsx: 0.03s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_social_inclusion.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_social_inclusion.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_social_inclusion_2.xlsx: 0.04s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_social_inclusion_2.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_soil.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_soil.xlsx: 0.02s\n",
      "Read file ../tmp/outcomes_data\\train_outcome_water_3.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_outcome_water_3.xlsx: 0.01s\n",
      "Read file ../tmp/outcomes_data\\train_water_2.xlsx: 0.03s\n",
      "Processed file ../tmp/outcomes_data\\train_water_2.xlsx: 0.01s\n",
      "All data  2901\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "y = []\n",
    "outcomes_data_folder = \"../tmp/outcomes_data\"\n",
    "for file in os.listdir(outcomes_data_folder):\n",
    "    df_outcome_mary = excel_reader.ExcelReader().read_df_from_excel(os.path.join(outcomes_data_folder, file))\n",
    "    for i in range(len(df_outcome_mary)):\n",
    "        outcomes = []\n",
    "        outcomes_per_label = []\n",
    "        outcomes_labels = []\n",
    "        for column in ['Soil health', 'Fertilizer use', 'Water use', 'Gender',\n",
    "           'Greenhouse gas emissions', 'Livelihood', 'Market access', 'Nutrition',\n",
    "           'Production', 'Resilience', 'Knowledge sharing', 'Practice change',\n",
    "           'Social inclusion','Poverty reduction' ,'Environment impact']:\n",
    "            outcomes_found = set([outcome for outcome in df_outcome_mary[column].values[i].split(\";\") if outcome.strip()])\n",
    "            outcomes.extend(outcomes_found)\n",
    "            for outcome in outcomes_found:\n",
    "                outcomes_per_label.append((outcome, column))\n",
    "            \n",
    "            outcomes_labels.append(1 if len(outcomes_found) else 0)\n",
    "        y.append(outcomes_labels)\n",
    "        outcomes_found = set()\n",
    "        for sent in nltk.sent_tokenize(df_outcome_mary[\"Sentence\"].values[i]):\n",
    "            found_entities = []\n",
    "            found_outcome_plus_labels = []\n",
    "            for outcome, label in outcomes_per_label:\n",
    "                outcome = outcome.strip().strip(\",\").strip(\".\").strip()\n",
    "                if outcome.lower() in sent.lower():\n",
    "                    start_ind = sent.lower().rfind(outcome.lower())\n",
    "                    end_ind = start_ind + len(outcome)\n",
    "                    if sent[start_ind: end_ind].lower() != outcome.lower():\n",
    "                        print(sent)\n",
    "                        print(start_ind, end_ind)\n",
    "                        print(sent[start_ind: end_ind])\n",
    "                        print(sent[start_ind: end_ind].lower(), outcome.lower())\n",
    "                    found_entities.append((start_ind, end_ind, 'OUTCOME'))\n",
    "                    outcomes_found.add(outcome)\n",
    "                    found_outcome_plus_labels.append((outcome, label))\n",
    "            all_data.append((sent, {'entities': found_entities}, found_outcome_plus_labels))\n",
    "        if len(outcomes_found) != len(set(outcomes)):\n",
    "            print(outcomes, outcomes_found)\n",
    "            print(i)\n",
    "print(\"All data \", len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.asarray(all_data), np.asarray(y), test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 275\n",
      "Test data 275\n"
     ]
    }
   ],
   "source": [
    "def split_outcomes_data(merged_data):\n",
    "    train_data = []\n",
    "    train_data_outcomes = []\n",
    "    for data in merged_data:\n",
    "        train_data.append((data[0], data[1]))\n",
    "        train_data_outcomes.extend(data[2])\n",
    "    return train_data, train_data_outcomes\n",
    "        \n",
    "\n",
    "TRAIN_DATA, outcomes_train_label_data = split_outcomes_data(all_data)\n",
    "EVAL_DATA, outcomes_eval_label_data = split_outcomes_data(all_data)\n",
    "print(\"Train data\", len(TRAIN_DATA))\n",
    "print(\"Test data\", len(EVAL_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 1427\n",
      "Test data 159\n"
     ]
    }
   ],
   "source": [
    "def split_outcomes_data(merged_data):\n",
    "    train_data = []\n",
    "    train_data_outcomes = []\n",
    "    for data in merged_data:\n",
    "        train_data.append((data[0], data[1]))\n",
    "        train_data_outcomes.extend(data[2])\n",
    "    return train_data, train_data_outcomes\n",
    "        \n",
    "\n",
    "TRAIN_DATA, outcomes_train_label_data = split_outcomes_data(X_train)\n",
    "EVAL_DATA, outcomes_eval_label_data = split_outcomes_data(X_test)\n",
    "print(\"Train data\", len(TRAIN_DATA))\n",
    "print(\"Test data\", len(EVAL_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn==0.2.0\n",
      "  Using cached scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
      "Installing collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-multilearn==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Water infrastructure                   68\n",
       "Policy                                 60\n",
       "Sanitation/Hygiene                     60\n",
       "Sustainability/Environmental health    57\n",
       "Community and behavior                 53\n",
       "Assessment tool or program             29\n",
       "Human health                           22\n",
       "Water quality                          12\n",
       "Agriculture                             5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outcomes_train_label_data, columns=[\"Text\", \"Label\"])[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Water infrastructure                   85\n",
       "Water quality/Human health             76\n",
       "Community and behavior                 48\n",
       "Sanitation/Hygiene                     46\n",
       "Sustainability/Environmental health    30\n",
       "Assessment tool or program             28\n",
       "Policy                                 26\n",
       "Agriculture                            14\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outcomes_eval_label_data, columns=[\"Text\", \"Label\"])[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_DATA, outcomes_train_label_data, outcomes_sentences_train_data, EVAL_DATA, outcomes_eval_label_data, outcomes_sentences_eval_data = pickle.load(open(\"../tmp/usaid_entity-recognition-model-more-2960_train_data\", \"rb\"))\n",
    "TRAIN_DATA = shuffle(TRAIN_DATA)\n",
    "outcomes_train_label_data = shuffle(outcomes_train_label_data)\n",
    "outcomes_sentences_train_data = shuffle(outcomes_sentences_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "output_dir=\"../tmp/entity-recognition-model-more-2252\"\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = spacy.load(\"../tmp/usaid_entity-recognition-model-more-3012-169_iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "if model is not None:\n",
    "    ner_model = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "# this will create a blank english model\n",
    "    ner_model = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in ner_model.pipe_names:\n",
    "    ner = ner_model.create_pipe('ner')\n",
    "    ner_model.add_pipe(ner, last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner_model = ner_model.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.71it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 252.77400120003972}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.93it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 149.35247996075466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.62it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 113.43863248983962}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.29it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 125.42573908997446}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.09it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 123.08307451592299}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.19it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 82.93344484614198}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.07it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 93.18786227462151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.31it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 277.74337925113895}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.92it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 139.42081500371606}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.76it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 179.9816812584046}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.14it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 308.95151429902603}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.17it/s]\n",
      " 10%|████████▎                                                                              | 2/21 [00:00<00:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 115.90853848430162}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.34it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 196.53070268449258}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.89it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 197.8040173984967}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.93it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 167.03322577625312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.31it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 217.4057930364157}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.13it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 147.65809705793518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.47it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 209.04482847405356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.54it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 264.4526462699272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.02it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 227.90850728066533}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.87it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 378.6186274921988}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.96it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 366.0558375349873}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.40it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 147.4450091779791}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.31it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 176.2580693945749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.69it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 168.68995277085563}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.36it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 178.14279138630877}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.99it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 133.05164458687028}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.27it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 143.18868830428423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.86it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 131.80530417761477}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.04it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 170.187085133609}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.78it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 146.1196416073715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.32it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 142.66416800796628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.82it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 110.53133822415792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.96it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 129.0039791568771}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.67it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 131.3598766101335}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.73it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 155.00338412835305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.12it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 128.083752359262}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.80it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 100.57533221511092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.15it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 92.44489153947133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.11it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 107.53501087138798}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.45it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 81.53965295634947}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.43it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 86.7593117554884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.87it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 95.48951639916277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.86it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 81.81359288944277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.70it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 70.61072846756132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.86it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 60.04854236346983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.05it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 65.82353925100479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.98it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 35.34071530218244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.04it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 36.06086223855525}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.51it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 47.941360499970884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.53it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 41.37080181326292}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.25it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 52.5878801612654}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.68it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 50.990923001773155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.50it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 37.644711662349636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.55it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 39.67735440047436}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.47it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 53.42422329332297}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.64it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 41.34838403403864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.48it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 22.222939161397395}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.20it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 37.896798416855574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.47it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 40.34776868336425}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.93it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 18.03006471049622}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.03it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 18.739947440167178}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.70it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 51.13664805243512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.36it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 26.721476994883556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.35it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 33.85643823211067}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.14it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 55.5200470990734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.15it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 25.60191824876416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.18it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 62.32048718987265}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.02it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 50.905796239271126}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.04it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 27.36515301568913}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.13it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 11.875247736376505}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.12it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 32.51852094462002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.27it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 15.689676359802768}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.02it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 9.076225846259137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.26it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 17.97333224853285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.24it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 11.517690541945605}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.38it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 31.66443750479525}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.39it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 16.95774921502892}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.74it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 16.271082846527783}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.14it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 15.69312804500042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.21it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 14.541442321207118}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.18it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 19.434385257752453}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.75it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 4.965162397068147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.10it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 22.897114280875414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.12it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 18.142334636604847}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.96it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 12.89568492433887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.18it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 18.944748968778267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.20it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 14.178580464282128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.17it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 10.897955915885523}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.80it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 2.047072900486871}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.14it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 2.6397857867354633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.09it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 9.394044055411205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.22it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 1.4161849083895637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.22it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:02,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 4.532403426883416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.50it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 6.552329043970507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.42it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 36.5092015974365}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.23it/s]\n",
      "  5%|████▏                                                                                  | 1/21 [00:00<00:03,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 10.759063849611213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.52it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 16.56836942807715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:04<00:00,  5.12it/s]\n",
      "  0%|                                                                                               | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 9.660111616167711}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 15.29699359339359}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm # loading bar\n",
    "# add labels, Trains data based on annotations \n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in ner_model.pipe_names if pipe != 'ner']\n",
    "with ner_model.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = ner_model.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            ner_model.update(\n",
    "                [text],  # batch of texts\n",
    "                [annotations],  # batch of annotations\n",
    "                drop=0.5,  # dropout \n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "def evaluate(model, examples):\n",
    "    scorer = Scorer()\n",
    "    cnt = 0\n",
    "    for input_, annot in examples:\n",
    "        doc_gold_text = model.make_doc(input_)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot['entities'])\n",
    "        pred_value = model(input_)\n",
    "        \n",
    "        if len(annot['entities']) == 0 and len([(ent.text, ent.label_) for ent in pred_value.ents]) == 0:\n",
    "            scorer.ner.tp += 1\n",
    "            for label in scorer.ner_per_ents:\n",
    "                scorer.ner_per_ents[label].tp += 1\n",
    "            cnt += 1\n",
    "        else:\n",
    "            try:\n",
    "                scorer.score(pred_value, gold)\n",
    "            except:\n",
    "                print(input_)\n",
    "                pass\n",
    "    return scorer.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Development The Market Development Program (MDP) should continue to work aggressively to assist women's associations to open retail shops in nearby markets for the sale of their produce.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 39.51762523191095,\n",
       " 'ents_r': 37.83303730017762,\n",
       " 'ents_f': 38.656987295825765,\n",
       " 'ents_per_type': {'OUTCOME': {'p': 39.51762523191095,\n",
       "   'r': 37.83303730017762,\n",
       "   'f': 38.656987295825765}},\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = spacy.load(\"../tmp/usaid_entity-recognition-model-more-2685-158_iter\")\n",
    "evaluate(ner_model, EVAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Development The Market Development Program (MDP) should continue to work aggressively to assist women's associations to open retail shops in nearby markets for the sale of their produce.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 36.706689536878216,\n",
       " 'ents_r': 38.07829181494662,\n",
       " 'ents_f': 37.37991266375546,\n",
       " 'ents_per_type': {'OUTCOME': {'p': 36.706689536878216,\n",
       "   'r': 38.07829181494662,\n",
       "   'f': 37.37991266375546}},\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = spacy.load(\"../tmp/usaid_entity-recognition-model-more-2685\")\n",
    "evaluate(ner_model, EVAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Development The Market Development Program (MDP) should continue to work aggressively to assist women's associations to open retail shops in nearby markets for the sale of their produce.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 37.93677204658902,\n",
       " 'ents_r': 40.7871198568873,\n",
       " 'ents_f': 39.310344827586206,\n",
       " 'ents_per_type': {'OUTCOME': {'p': 37.93677204658902,\n",
       "   'r': 40.7871198568873,\n",
       "   'f': 39.310344827586206}},\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model = spacy.load(\"../tmp/usaid_entity-recognition-model-more-2685-135_iter\")\n",
    "evaluate(ner_model, EVAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\AppData\\Local\\Continuum\\anaconda3\\envs\\cornell\\lib\\site-packages\\smart_open\\smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google word2vec loaded\n",
      "Fast text loaded\n",
      "Phrases loaded\n",
      "####  Water infrastructure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Sanitation/Hygiene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Water quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Human health\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Sustainability/Environmental health\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Community and behavior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Assessment tool or program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Policy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####  Agriculture\n",
      "F1 measure:  0.7372852233676982\n",
      "Accuracy:  0.8298969072164949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\interventions_labeling_lib\\intervention_labeling.py:172: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res = x / np.sum(x, axis=1)[:, None]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for r in outcomes_train_label_data:\n",
    "    test_data.append((r[0], r[0], r[1]))\n",
    "test_data = pd.DataFrame(test_data, columns=[\"Narrow concept\", \"Broad concepts\", \"Label\"])\n",
    "\n",
    "test_data[\"Label\"] = [usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_LABEL_TO_NUMBER[test_data[\"Label\"].values[i]] for i in range(len(test_data))]\n",
    "deduplicated2labels = deduplicate([test_data])\n",
    "\n",
    "intervention_labeling = reload(intervention_labeling)\n",
    "intervention_labeler = intervention_labeling.InterventionLabeling(google_models_folder=\"../model/synonyms_retrained_new\",\n",
    "                                                                 label_non_intervention=2, class_weights={}, binary=True)\n",
    "common_folder = \"../model/usaid_interventions_multi\"\n",
    "test_labels = []\n",
    "for label in usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL:\n",
    "    if label != 10:\n",
    "        print(\"#### \", usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL[label])\n",
    "        test_copy = test_data.copy()\n",
    "        test_copy[\"Label\"] = [1 if label in deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[i])] else 2 for i in range(len(test_copy))]\n",
    "        label_folder = os.path.join(common_folder, usaid_intervention_labels.USAIDInterventionLabels.INTERVENTION_NUMBER_TO_LABEL[label])\n",
    "        intervention_labeler.load_previous_models(label_folder)\n",
    "        res_label, res_prob = intervention_labeler.predict_class(test_copy.values, return_probs=True)\n",
    "        test_labels.append([r[0] for r in res_prob])\n",
    "\n",
    "print(\"F1 measure: \", get_f1_multi_label(test_labels, [deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[i])] for i in range(len(test_data))]))\n",
    "print(\"Accuracy: \",get_accuracy_multi_label(test_labels, [deduplicated2labels[normalize_full(test_copy[\"Narrow concept\"].values[i])] for i in range(len(test_data))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We, therefore, pooled household data from two Sustainable Water Effectiveness Reviews conducted by Oxfam GB in Zambia (n ¼ 997) and the Democratic Republic of Congo (DRC, n ¼ 1,071) to assess the relationship between perceived water governance (using a 12-item indicator), water insecurity [using the Household Water Insecurity Experiences (HWISE) Scale], and four indicators of well-being: life satisfaction, drinking unsafe water, diarrhea, and resilience to cholera outbreak.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 16.666666666666664,\n",
       " 'ents_r': 2.380952380952381,\n",
       " 'ents_f': 4.166666666666666,\n",
       " 'ents_per_type': {'OUTCOME': {'p': 16.666666666666664,\n",
       "   'r': 2.380952380952381,\n",
       "   'f': 4.166666666666666}},\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ner_model, EVAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referring back to the complexity of water and sanitation, there is a view that seems pervasive amongst Rotarians that development workers make issues needlessly complicated and that what is needed is simply more charity and voluntary initiatives.\n",
      "Real:  {'charity and voluntary initiatives'}\n",
      "OK:  set()\n",
      "Not OK result:  {'simply more charity and voluntary initiatives'}\n",
      "Not FOUND result:  {'charity and voluntary initiatives'}\n",
      "Good water governance was also directly associated with greater odds of life satisfaction (aOR 1.24) and lower odds of both drinking unsafe water (aOR 0.91) and severe cholera impact (aOR 0.92).\n",
      "Real:  {'water governance'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water governance'}\n",
      "Understanding the factors influencing decision of farmers to implement disease control programmes is therefore a key element in informing future policies aimed at improving CBPP management.\n",
      "Real:  {'disease control programmes'}\n",
      "OK:  {'disease control programmes'}\n",
      "Not OK result:  {'policies aimed at improving CBPP management'}\n",
      "Not FOUND result:  set()\n",
      "The Team will coordinate with USAID’s Water Communications and Knowledge Management (CKM) on World Water Week 2017 outreach tasks, materials, and representation.\n",
      "Real:  {'Water Communications and Knowledge Management (CKM)'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Water Communications'}\n",
      "Not FOUND result:  {'Water Communications and Knowledge Management (CKM)'}\n",
      "Our assessment took into account both formal and informal sanitation components of the water and wastewater management cycle and included a multi-institutional analysis of the entire system.\n",
      "Real:  {'sanitation', 'water and wastewater management', 'multi-institutional analysis'}\n",
      "OK:  {'multi-institutional analysis'}\n",
      "Not OK result:  {'informal sanitation components of the water and wastewater management cycle'}\n",
      "Not FOUND result:  {'sanitation', 'water and wastewater management'}\n",
      "Attainment of goals, however, will likely require a project extension, resolution of DGF budgetary problems, a shrimp extension program, an inventory and distribution system, and a marketing/quality control program.\n",
      "Real:  {'inventory and distribution system', 'marketing/quality control program', 'shrimp extension program'}\n",
      "OK:  {'marketing/quality control program'}\n",
      "Not OK result:  {'extension program'}\n",
      "Not FOUND result:  {'inventory and distribution system', 'shrimp extension program'}\n",
      "However, the integrated ultraviolet radiation-ultrasonic technique was highly efficient and is recommended in the removal of antibiotic resistant E. coli from wastewater.\n",
      "Real:  {'integrated ultraviolet radiation-ultrasonic technique'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'integrated ultraviolet radiation-ultrasonic technique'}\n",
      "The odor control strategies aim to minimize odor nuisance beyond the treatment plant facilities' boundaries.\n",
      "Real:  {'odor control strategies', 'treatment plant facilities'}\n",
      "OK:  {'treatment plant facilities'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'odor control strategies'}\n",
      "Until the mid-1990s crop protection programmes were dominated by organophosphate (OP) insecticides needed to meet phytosanitary requirements alone.\n",
      "Real:  {'organophosphate (OP) insecticides', 'crop protection programmes'}\n",
      "OK:  set()\n",
      "Not OK result:  {'mid-1990s crop protection programmes'}\n",
      "Not FOUND result:  {'organophosphate (OP) insecticides', 'crop protection programmes'}\n",
      "We analyze the relationship between exposure to sewage from overflowed sanitation infrastructure and the incidence of diarrhea in children under age five.\n",
      "Real:  {'overflowed sanitation infrastructure'}\n",
      "OK:  set()\n",
      "Not OK result:  {'sanitation infrastructure'}\n",
      "Not FOUND result:  {'overflowed sanitation infrastructure'}\n",
      "Of 299 clients (mothers with one child under five), 57.2% demonstrated proper water treatment knowledge, 93.3% reported ever using water treatment products, 16.4% had detectable chlorine residual in stored water, and 89.0% demonstrated proper handwashing technique.\n",
      "Real:  {'handwashing', 'water treatment'}\n",
      "OK:  set()\n",
      "Not OK result:  {'water treatment knowledge', 'handwashing technique', 'water treatment products'}\n",
      "Not FOUND result:  {'handwashing', 'water treatment'}\n",
      "In the wastewater sector, USAID projects have led to a much higher percentage of urban Egypt being serviced by sewerage and treatment facilities, thus greatly reducing the levels of effluent reentering the water system.\n",
      "Real:  {'water system', 'sewerage and treatment facilities'}\n",
      "OK:  {'sewerage and treatment facilities'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water system'}\n",
      "It has been shown that thermal coupling of the two stages creates a self-sustained reactor that can combust wet fecal material containing up to 3.2 parts water to 1 part dry matter – equivalent of water content in healthy human feces – without the need for external heating, known as the ultimate challenge in direct combustion of human feces.\n",
      "Real:  {'combustion of human feces', 'self-sustained reactor'}\n",
      "OK:  {'self-sustained reactor'}\n",
      "Not OK result:  {'heating'}\n",
      "Not FOUND result:  {'combustion of human feces'}\n",
      "Focus group discussions (FGDs) were employed for qualitative content analysis (n ¼ 10).\n",
      "Real:  {'qualitative content analysis', 'Focus group discussions (FGDs)'}\n",
      "OK:  {'qualitative content analysis'}\n",
      "Not OK result:  {'Focus group discussions'}\n",
      "Not FOUND result:  {'Focus group discussions (FGDs)'}\n",
      "An examination is presented of the Tono Irrigation Project (TIP) in Upper East Ghana to show the potentials and limits of irrigation development programmes in Africa.\n",
      "Real:  {'irrigation development programmes'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Tono Irrigation Project (TIP)', 'potentials and limits of irrigation development programmes'}\n",
      "Not FOUND result:  {'irrigation development programmes'}\n",
      "This qualitative midterm evaluation of the Maternal and Child Survival Program (MCSP), a five-year global program (March 2014 March 2019), was conducted to provide the U.s. Agency for International Development's (USAID) Global Health Bureau's Maternal and Child Health and Nutrition Office (MCHN) with an assessment of the progress of its flagship program, to make recommendations to improve implementation of the current program, and to inform follow-on award design.\n",
      "Real:  {'qualitative midterm evaluation of the Maternal and Child Survival Program (MCSP)'}\n",
      "OK:  {'qualitative midterm evaluation of the Maternal and Child Survival Program (MCSP)'}\n",
      "Not OK result:  {'Maternal and Child Health and Nutrition Office (MCHN)', 'inform follow-on award design', 'five-year global program', \"provide the U.s. Agency for International Development's (USAID)\", 'assessment of the progress of its flagship program'}\n",
      "Not FOUND result:  set()\n",
      "AMREF will implement a PHC program in Luuq town and the 11 villages in the district and in nomadic areas, and working with the local authorities will develop an environmental health program for safe water and sanitation.\n",
      "Real:  {'PHC program', 'environmental health program', 'working with the local authorities', 'safe water and sanitation'}\n",
      "OK:  {'environmental health program', 'PHC program'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'working with the local authorities', 'safe water and sanitation'}\n",
      "Recognizing that RI/F is keen to play a role in and make a contribution to the water and sanitation sector, USAID staff have clearly seen an opportunity to influence and shape that contribution, seeking to help shift some of RI/F’s approach away from a smaller series of one-off infrastructure investments towards a wider reaching more influential body of work.\n",
      "Real:  {'infrastructure investments', 'make a contribution to the water and sanitation sector'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'infrastructure investments', 'make a contribution to the water and sanitation sector'}\n",
      "High concentrations of thermotolerant coliforms were found in many of the dug wells and even in the deeper drilled bores.\n",
      "Real:  {'deeper drilled bores', 'dug wells'}\n",
      "OK:  {'dug wells'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'deeper drilled bores'}\n",
      "Distributive justice requires parity in access to sustainable and climate resilient agricultural programs, and i identify some ongoing systemic barriers for these small Hmong producers to access two recent programs: NRCS EQIP and CDFA SWEEP.\n",
      "Real:  {'sustainable and climate resilient agricultural programs'}\n",
      "OK:  set()\n",
      "Not OK result:  {'access to sustainable and climate resilient agricultural programs'}\n",
      "Not FOUND result:  {'sustainable and climate resilient agricultural programs'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He joined Joy Jochico of USAID/Philippines and Almud Weitz of the World Bank Water and Sanitation Program (WSP) in handing over the following documents to the League of Cities and League of Provinces of the Philippines: “Operations Manual on the Rules and Regulations Governing Domestic Sludge and Septage,” published by DOH with support from ECO-Asia; “Economic Impacts of Sanitation in the Philippines” published by the World Bank Water and Sanitation Program (WSP) with co-funding from ECO-Asia; “Universal Sanitation in East Asia,” a joint WSP-WHO-UNICEF publication; and “Sanitation Technology Information Kit” prepared by PSA.\n",
      "Real:  {'Operations Manual on the Rules and Regulations Governing Domestic Sludge and Septage', 'Water and Sanitation Program (WSP)', 'Sanitation Technology Information Kit', 'Economic Impacts of Sanitation', 'Universal Sanitation'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Water and Sanitation Program (WSP) with co-funding from ECO-Asia; “Universal Sanitation in East Asia,” a joint WSP-WHO-UNICEF publication', 'Water and Sanitation Program (WSP) in handing'}\n",
      "Not FOUND result:  {'Operations Manual on the Rules and Regulations Governing Domestic Sludge and Septage', 'Water and Sanitation Program (WSP)', 'Sanitation Technology Information Kit', 'Universal Sanitation', 'Economic Impacts of Sanitation'}\n",
      "Even M&E systems, only now being developed in earnest, are not yet geared to larger activities and there is no clear sense of how best to encourage such a wide range of small projects to add up toa more sustained contribution to sustainable development challenges.\n",
      "Real:  {'M&E systems'}\n",
      "OK:  {'M&E systems'}\n",
      "Not OK result:  {'small projects'}\n",
      "Not FOUND result:  set()\n",
      "In view of this situation, the paper suggests: an aid-the-poor programme for agricultural development, the transformation of low-yield farmland, major efforts to develop animal husbandry, rational irrigation to avoid secondary salinization, the selection of development projects which strengthen the collective economy of the townships and villages, improving the quality of drinking water to prevent disease and medical conditions, develop education, and enhance afforestation and environmental protection efforts\n",
      "Real:  {'environmental protection', 'rational irrigation', 'secondary salinization', 'afforestation', 'develop animal husbandry', 'prevent disease and medical conditions', 'improving the quality of drinking water', 'aid-the-poor programme', 'agricultural development'}\n",
      "OK:  {'agricultural development', 'rational irrigation', 'prevent disease and medical conditions'}\n",
      "Not OK result:  {'enhance afforestation', 'environmental protection efforts', 'animal husbandry', 'the transformation of low-yield farmland', 'selection of development projects'}\n",
      "Not FOUND result:  {'environmental protection', 'secondary salinization', 'afforestation', 'develop animal husbandry', 'improving the quality of drinking water', 'aid-the-poor programme'}\n",
      "handwashing, boiling water) but limited evidence of practice.\n",
      "Real:  {'handwashing', 'boiling water'}\n",
      "OK:  {'handwashing'}\n",
      "Not OK result:  {'boiling'}\n",
      "Not FOUND result:  {'boiling water'}\n",
      "EEC established the Latin America Water Task Force to work with broad interests to generate discussion about improving these municipal services in Brazil.\n",
      "Real:  {'improving these municipal services'}\n",
      "OK:  set()\n",
      "Not OK result:  {'municipal services'}\n",
      "Not FOUND result:  {'improving these municipal services'}\n",
      "(1) Local government is an effective vehicle for prioritizing and implementing multi-sectoral investments.\n",
      "Real:  {'implementing multi-sectoral investments'}\n",
      "OK:  set()\n",
      "Not OK result:  {'multi-sectoral investments'}\n",
      "Not FOUND result:  {'implementing multi-sectoral investments'}\n",
      "ANNEX B: FINAL QUANTATIVE PROJECT ACCOMPLISHMENTS — PERFORMANCE MONTIROING PLAN AND TRAINING IMPACT ASSESSMENT A. IWSMR Performance Monitoring Indicators Program Objective: Improved water and sanitation services in the MENA region Quality of W/WW treated: Noncompliance citations per year at participating utilities PR 1: Increased ACWUA capacity to carry out its mandate Milestone: ACWUA business plan updated; annual business plan targets met; certification unit established IR 1.1: Improved management and information systems within ACWUA Milestone: Training and certification information system (CIS) launched Milestone: USAID Responsibility Determination secured IR 1.2: Improved reliability of ACWUA’s year-to-year revenue streams Revenues generated from ACWUA Operator Certification and Training Program PR 2: Scaled up operator certification programs to a regional level Milestone: Interim regional certification platform established Number of countries participating in the regional certification program Number of operators obtaining regionally recognized certification Percentage of operators passing standardized certification tests Number of certified trainers (Training of Trainers - TOT graduates) Number of certified operators obtaining new positions, promotions, or added incentives Number of certified operators working in markets outside of their country of origin and country of certification Change in technical and management skills due to obtaining operator certification Change in job performance due to obtaining operator certification Change in attitude, confidence and self-esteem due to obtaining operator certification IR 2.1: Enhanced training materials and certification framework Number of courses (materials) and tests approved by ACWUA and finalized for regional certification PR 3: Improved performance of regional water and wastewater utilities by leveraging USAID-funded improvements Utility performance measures selected for each twinning pair based on scope of partnership, e.g., collection rates, non-revenue water (NRW) rates IR 3.1: Increased exchange between water and wastewater utilities Number of twinning arrangements piloted Change in technical and management skills attributed to twinning exchange Change in job performance attributed to twinning exchange IWSMR COMPLETION REPORT 60\n",
      "Real:  {'Improved water and sanitation services', 'Interim regional certification platform', 'ACWUA Operator Certification and Training Program', 'regional water and wastewater utilities', 'IWSMR Performance Monitoring', 'Improved reliability of ACWUA’s year-to-year revenue streams', 'Training and certification information system (CIS)', 'certification programs'}\n",
      "OK:  {'Training and certification information system (CIS)', 'Improved water and sanitation services'}\n",
      "Not OK result:  {'Increased exchange between water and wastewater utilities', 'obtaining operator certification Change in job performance due to obtaining operator certification Change in attitude', 'Improved reliability of ACWUA’s year-to-year revenue streams Revenues generated', 'operator certification programs', 'piloted Change in technical and management skills attributed', 'Improved management and information systems', 'W/WW treated', 'certification tests', 'improvements Utility performance measures', 'non-revenue water (NRW)', 'exchange Change in job performance attributed', 'certification unit', 'Improved performance of regional water and wastewater utilities', 'regional certification program', 'obtaining operator certification'}\n",
      "Not FOUND result:  {'Interim regional certification platform', 'ACWUA Operator Certification and Training Program', 'regional water and wastewater utilities', 'IWSMR Performance Monitoring', 'Improved reliability of ACWUA’s year-to-year revenue streams', 'certification programs'}\n",
      "We analysed how these three approaches were employed in the WASH-climate change nexus literature, and discuss the implications for WASH research, policy, and development work.\n",
      "Real:  {'WASH research', 'WASH-climate change'}\n",
      "OK:  set()\n",
      "Not OK result:  {'WASH'}\n",
      "Not FOUND result:  {'WASH research', 'WASH-climate change'}\n",
      "Indicators aA Qi Q2 Q3 Q4 Reporting GT GS GE) Frequency PV aTaere | Target Q= Quarterly trom eV a | = protection (HL8.3.1) Comments Land Use Management Committees and Water Users Groups) and a larger number of people than anticipated were trained and educated on approaches, tools and/or methods for water security, integrated water resource management, and/or water source protection eel | Achieved Target FY18 (%) Ke) me) LOP Achievements Percent to Date Achieved (%) management IR3 Private Sector: Increased livelihoods through private sector investment opportunit ies for sustainable water services and resource 3.1 Percent of | 55% 53% 50% 74% 66% women and youth participating in USG assisted programs designed to increase access to productive economic resources (contributes to Standard) Q By the end of year three, youth and women have been reached in TFCG agricultural activities and WARIDI-led livelihood activities.\n",
      "Real:  {'integrated water resource management', 'access to productive economic resources', 'TFCG agricultural activities', 'sustainable water services', 'water source protection', 'WARIDI-led livelihood activities', 'private sector investment', 'methods for water security'}\n",
      "OK:  {'TFCG agricultural activities', 'water source protection', 'WARIDI-led livelihood activities', 'sustainable water services'}\n",
      "Not OK result:  {'water resource management'}\n",
      "Not FOUND result:  {'methods for water security', 'private sector investment', 'integrated water resource management', 'access to productive economic resources'}\n",
      "After joining SFDP micro credit program, there were positive significant improvement in income, employment and asset position for the different sample beneficiaries in the study area\n",
      "Real:  {'micro credit program'}\n",
      "OK:  set()\n",
      "Not OK result:  {'employment and asset position'}\n",
      "Not FOUND result:  {'micro credit program'}\n",
      "This study examined how sand grain size affects biological sand water filtration and how the combination of biological sand filtration and ultraviolet (UV) disinfection affects drinking water quality.\n",
      "Real:  {'sand water filtration', 'biological sand filtration', 'ultraviolet (UV) disinfection'}\n",
      "OK:  {'biological sand filtration'}\n",
      "Not OK result:  {'biological sand water filtration', 'disinfection affects', 'UV'}\n",
      "Not FOUND result:  {'sand water filtration', 'ultraviolet (UV) disinfection'}\n",
      "A combination of key informant interviews and a copious desk-top study of official documentary reports were analysed in the context of the polluter-pays principle.\n",
      "Real:  {'copious desk-top study of official documentary reports', 'key informant interviews'}\n",
      "OK:  {'key informant interviews'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'copious desk-top study of official documentary reports'}\n",
      "WFP indicates that without additional funding it would have to curtail feeding programs that meet the needs of more than 70 million people in 80 countries.\n",
      "Real:  {'feeding programs'}\n",
      "OK:  set()\n",
      "Not OK result:  {'curtail feeding programs'}\n",
      "Not FOUND result:  {'feeding programs'}\n",
      "Identify how to safely dispose of materials soiled with menstrual blood that will not be re-used and identify how to properly clean cloth soiled with menstrual blood so that the cloth can be safely re-used.\n",
      "Real:  {'dispose of materials soiled with menstrual blood', 'clean cloth soiled with menstrual blood'}\n",
      "OK:  set()\n",
      "Not OK result:  {'properly clean cloth'}\n",
      "Not FOUND result:  {'dispose of materials soiled with menstrual blood', 'clean cloth soiled with menstrual blood'}\n",
      "2) The CFIR, originally developed for contextual assessment in high resource formal health systems, can be applied as well to assess implementation context of interventions which engage and rely on implementers from both formal health and informal community systems—a key approach in many development interventions.\n",
      "Real:  {'health and informal community systems', 'assessment in high resource formal health systems'}\n",
      "OK:  {'health and informal community systems'}\n",
      "Not OK result:  {'high resource formal health systems', 'contextual assessment', 'assess implementation'}\n",
      "Not FOUND result:  {'assessment in high resource formal health systems'}\n",
      "Our results suggest that, in the USA, private wells are relevant to giardiasis transmission; giardiasis risk factors might vary regionally; and up-to-date, location-specific national data on water sources and sanitation methods are needed\n",
      "Real:  {'private wells', 'sanitation methods', 'giardiasis transmission'}\n",
      "OK:  set()\n",
      "Not OK result:  {'wells'}\n",
      "Not FOUND result:  {'private wells', 'sanitation methods', 'giardiasis transmission'}\n",
      "Analysis of conservative political participation in local food initiatives tends to be critical and dismissive, positing this participation as self-serving, individualistic, exclusionary, nativist, or reactionary.\n",
      "Real:  {'food initiatives'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'food initiatives'}\n",
      "The success evinced by community participation in development programs has proven hard to duplicate in primary health care (PHC) projects, according to this study, which is based on lessons learned from 35 PHC projects displaying elements of community participation.\n",
      "Real:  {'primary health care (PHC) projects', 'community participation'}\n",
      "OK:  {'community participation'}\n",
      "Not OK result:  {'community participation in development programs', 'hard to duplicate in primary health care (PHC) projects'}\n",
      "Not FOUND result:  {'primary health care (PHC) projects'}\n",
      "the Initial Environmental Examination and Environmental Mitigation and Monitoring Plan Activity Monitoring and Within 90 days after contract award.\n",
      "Real:  {'Initial Environmental Examination and Environmental Mitigation and Monitoring Plan Activity Monitorin'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Environmental Mitigation and Monitoring Plan'}\n",
      "Not FOUND result:  {'Initial Environmental Examination and Environmental Mitigation and Monitoring Plan Activity Monitorin'}\n",
      "The findings also suggest that poultry breeding programmes aiming to provide readily acceptable breed technology by farmers need to prioritize traits of adaptive and socio-cultural importance instead of focusing on egg productivity only.\n",
      "Real:  {'breed technology', 'poultry breeding programmes'}\n",
      "OK:  {'poultry breeding programmes'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'breed technology'}\n",
      "Preservation of water quality and prevention of waterborne disease is a complicated task requiring a coordinated effort from many diverse disciplines including physicians, healthcare providers, epidemiologists, microbiologists, academic scientists, science researchers, local and national health authorities, public and environmental health specialists, water engineers and water purveyors.\n",
      "Real:  {'Preservation of water quality', 'prevention of waterborne disease'}\n",
      "OK:  {'Preservation of water quality', 'prevention of waterborne disease'}\n",
      "Not OK result:  {'academic scientists'}\n",
      "Not FOUND result:  set()\n",
      "Considering low population, poor geographical accessibility and lack of electricity, a small-scaled water treatment system capable of producing clean fresh water associated with solar thermal/photovoltaic applications, which is characterized with low capital cost, easy operation and less need of maintenance, is employed in the techno-economic study.\n",
      "Real:  {'small-scaled water treatment system', 'producing clean fresh water'}\n",
      "OK:  {'small-scaled water treatment system'}\n",
      "Not OK result:  {'solar thermal/photovoltaic applications'}\n",
      "Not FOUND result:  {'producing clean fresh water'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDA's new incentive based programmes are reviewed (environmental quality incentives programme and Conservation Reserve programme).\n",
      "Real:  {'Conservation Reserve programme', 'incentive based programmes', 'environmental quality incentives programme'}\n",
      "OK:  {'incentive based programmes', 'environmental quality incentives programme'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Conservation Reserve programme'}\n",
      "This chapter describes how the processes of community participation (including participatory extension) were field tested and became an integral part of two major agricultural development projects and one natural resource management project in the highlands of northern Thailand.\n",
      "Real:  {'community participation', 'agricultural development projects', 'participatory extension', 'natural resource management project'}\n",
      "OK:  {'agricultural development projects', 'natural resource management project'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'community participation', 'participatory extension'}\n",
      "9 % ongoing a Number of sanitation facilities 0 4 # 0 0% augding Enhanced access to basic drinking | constructed Output 1.2.1 water and public — sanitation facilities in target communities arite collecti ates Fee/tariff collection rates for newly 0 tba's # nla n/a notsiaited constructed supply systems % increase in water operators’ income | 0 tbd!7 % n/a n/a not started Output 1.2.2 Improved access to sustainable | Number of beneficiaries with improved 0 1,131 # 0 aA ongoing renewable energy sources energy services due to USG assistance Improved performance of targeted ke or nla Strategic Objective 2.\n",
      "Real:  {'Enhanced access to basic drinking', 'sanitation facilities', 'increase in water operators’ income'}\n",
      "OK:  {'sanitation facilities'}\n",
      "Not OK result:  {'energy sources energy services', 'constructed supply systems', 'Improved performance of targeted ke or nla Strategic Objective'}\n",
      "Not FOUND result:  {'Enhanced access to basic drinking', 'increase in water operators’ income'}\n",
      "Menstrual hygiene management was also identified as a priority for improving the health, welfare and dignity of women and girls (WHO/UNICEF, 201 5a).\n",
      "Real:  {'Menstrual hygiene management'}\n",
      "OK:  {'Menstrual hygiene management'}\n",
      "Not OK result:  {'improving the health'}\n",
      "Not FOUND result:  set()\n",
      "(4) Research will include adaptive trials and demonstration plots focusing on plant varieties, soil management, fertilizer use, irrigation/water management, pesticide testing, crop protection, multiple cropping and intercropping, and agroforestry.\n",
      "Real:  {'irrigation/water management', 'agroforestry', 'pesticide testing', 'crop protection', 'soil management', 'fertilizer', 'intercropping', 'multiple cropping'}\n",
      "OK:  {'agroforestry', 'crop protection', 'soil management', 'pesticide testing'}\n",
      "Not OK result:  {'water management', 'fertilizer use', 'on plant varieties', 'irrigation', 'adaptive trials and demonstration plots', 'multiple cropping and intercropping'}\n",
      "Not FOUND result:  {'irrigation/water management', 'intercropping', 'multiple cropping', 'fertilizer'}\n",
      "Evaluates Family Life Education Project (FLEP) to provide learner-centered nonformal education in rural Ghanaian communities.\n",
      "Real:  {'Family Life Education Project (FLEP)'}\n",
      "OK:  set()\n",
      "Not OK result:  {'provide learner-centered nonformal education'}\n",
      "Not FOUND result:  {'Family Life Education Project (FLEP)'}\n",
      "These events/actions were ranked by intensity, using precise definitions of conflict and cooperation as suggested by the Transboundary Freshwater Dispute Database under the Basins at Risk project formulated at Oregon State University.\n",
      "Real:  {'Basins at Risk project'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Basins at Risk project'}\n",
      "Layout and pipe size optimisation of sanitary sewer networks requires optimal determination of pipe locations, pipe diameters and pipe slopes leading to a highly constrained mixed-integer nonlinear programming (MINLP) problem presenting a challenge even to the modern heuristic search methods.\n",
      "Real:  {'pipe size optimisation', 'sanitary sewer networks'}\n",
      "OK:  set()\n",
      "Not OK result:  {'modern heuristic search methods'}\n",
      "Not FOUND result:  {'pipe size optimisation', 'sanitary sewer networks'}\n",
      "Output 3.1.2: Private and communitybased agricultural input supply systems developed Output 3.1.3: Farmers associations/g roups established # of farmers (F/M) in the target area accessing input supply and business development services # of farmers in the target area (F/M) belonging to associations Measures the # of farmers accessing inputs and business development services including fodder, seeds, fertilizers, plants, root stocks, tools, other equipment, animal medicine and vaccines, and supplementary feed for livestock Measures the # of new farmers joining association groups including water user associations, pasture management committees, watershed committees, and natural resources management committees Input supplier records, Business 219,697 estimated Membership total # of farmers Organization in target districts records, and CDCs NRM program reports/records NRM MIS Database 150 farmers 1.\n",
      "Real:  {'Private and communitybased agricultural input supply systems', 'input supply and business development services', 'fertilizers', 'animal medicine and vaccines', 'natural resources management'}\n",
      "OK:  set()\n",
      "Not OK result:  {'agricultural input supply systems', 'natural resources management committees', 'NRM program', 'business development services', 'pasture management committees', 'water user associations', 'animal medicine', 'vaccines', 'supplementary feed for livestock Measures', 'input supply'}\n",
      "Not FOUND result:  {'Private and communitybased agricultural input supply systems', 'input supply and business development services', 'fertilizers', 'animal medicine and vaccines', 'natural resources management'}\n",
      "The study finds that rural people like to dispose of wastewater offsite as a good network of drains is found in the villages.\n",
      "Real:  {'dispose of wastewater offsite', 'good network of drains'}\n",
      "OK:  set()\n",
      "Not OK result:  {'dispose of wastewater offsite as a good network of drains'}\n",
      "Not FOUND result:  {'dispose of wastewater offsite', 'good network of drains'}\n",
      "All spring water samples and 29.2% of private tap water had the highest TC load (18 most probable number/100 mL, 95% CI: 100).\n",
      "Real:  {'spring water', 'tap water'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'spring water', 'tap water'}\n",
      "The problem of developing optimal IUWS control strategies is formulated here as a two objective optimisation problem, with both objectives aiming at improving the water quality in the recipient: minimise the Ammonium concentration and maximise the Dissolved Oxygen concentration in the river.\n",
      "Real:  {'minimise the Ammonium concentration', 'optimal IUWS control strategies', 'improving the water quality', 'maximise the Dissolved Oxygen concentration'}\n",
      "OK:  {'maximise the Dissolved Oxygen concentration'}\n",
      "Not OK result:  {'IUWS control strategies'}\n",
      "Not FOUND result:  {'minimise the Ammonium concentration', 'optimal IUWS control strategies', 'improving the water quality'}\n",
      "HIV/AIDS and WSH programmes need to be integrated for better intervention activities in Ethiopia\n",
      "Real:  {'HIV/AIDS and WSH programmes'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'HIV/AIDS and WSH programmes'}\n",
      "C3 BACKGROUND The Middle East Bureau supports regional activities in water and environment to address the Mission Objective “Long-term sustainable access to water in the region improved.” Regional activities are funded through the Middle East Regional (MER) budget, and in the past through the Middle East Regional Program (MERP) Office’s predecessor, the Office of Middle East Programs (OMEP) that was based out of Cairo.\n",
      "Real:  {'regional activities in water and environment', 'funded through the Middle East Regional (MER) budget', 'sustainable access to water'}\n",
      "OK:  {'regional activities in water and environment', 'sustainable access to water'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'funded through the Middle East Regional (MER) budget'}\n",
      "Eliminating stock-outs through improved supplies chain management — The evaluation team also noted continuous stock outs for HIV/TB drugs and commodities at some of the health facility stores visited.\n",
      "Real:  {'supplies chain management'}\n",
      "OK:  set()\n",
      "Not OK result:  {'improved supplies chain management'}\n",
      "Not FOUND result:  {'supplies chain management'}\n",
      "Long-term overuse of antibiotics has driven the propagation and spreading of antibiotic resistance genes (ARGs) such as efflux pumps in the environment, which can be transferred to clinically relevant pathogens.\n",
      "Real:  {'antibiotics', 'efflux pumps'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'antibiotics', 'efflux pumps'}\n",
      "It concludes that conventional sewer systems are in most cases the most expensive sanitation options, followed, in order of cost, by sanitation systems comprising septic tanks, ventilated improved pit latrines (VIP), urine diversion dry toilets and pour-flush pit latrines.\n",
      "Real:  {'pour-flush pit latrines', 'urine diversion dry toilets', 'ventilated improved pit latrines (VIP)', 'sanitation systems', 'septic tanks', 'conventional sewer systems'}\n",
      "OK:  {'pour-flush pit latrines', 'urine diversion dry toilets', 'ventilated improved pit latrines (VIP)', 'septic tanks', 'sanitation systems', 'conventional sewer systems'}\n",
      "Not OK result:  {'expensive sanitation options'}\n",
      "Not FOUND result:  set()\n",
      "The nine hypotheses tested commonly assumed that improved infant and maternal nutrition increases infant survival and decreases the number of children desired; that providing food supplements at FP clinics increases the number of clients; and that decreased infant mortality resulting from improved maternal nutrition lengthens the birth interval, thus reducing birth rates.\n",
      "Real:  {'improved maternal nutrition', 'providing food supplements at FP clinics'}\n",
      "OK:  set()\n",
      "Not OK result:  {'food supplements at FP clinics increases', 'improved infant and maternal nutrition'}\n",
      "Not FOUND result:  {'improved maternal nutrition', 'providing food supplements at FP clinics'}\n",
      "COMMERCIAL FINANCING FOR WATER UTILITY INFRASTRUCTURE REQUIRES SIGNIFICANT ENABLING ENVIRONMENT AND MARKET PRECONDITIONS USAID can facilitate short-term commercial financing for water utility service expansion in Africa as evidenced by SUWASA achievements with utilities in Kenya.\n",
      "Real:  {'commercial financing for water utility service expansion'}\n",
      "OK:  set()\n",
      "Not OK result:  {'COMMERCIAL FINANCING FOR WATER UTILITY INFRASTRUCTURE', 'short-term commercial financing for water utility service expansion'}\n",
      "Not FOUND result:  {'commercial financing for water utility service expansion'}\n",
      "Access to safely managed water is a basic human right, yet rural water supply still remains a challenge in Zimbabwe.\n",
      "Real:  {'rural water supply', 'safely managed water'}\n",
      "OK:  {'rural water supply'}\n",
      "Not OK result:  {'Access to safely managed water'}\n",
      "Not FOUND result:  {'safely managed water'}\n",
      "Calbayog City constructed sanitation systems in its new housing resettlement site and health clinic with help from the PSA and the US Naval Construction Regiment.\n",
      "Real:  {'sanitation systems'}\n",
      "OK:  set()\n",
      "Not OK result:  {'housing resettlement site', 'Calbayog City constructed sanitation systems'}\n",
      "Not FOUND result:  {'sanitation systems'}\n",
      "The City Development Plan of 2006 points out two clear policy and governance issues in sewerage management: a) lack of clarity regarding sewer tariffs; and b) absence of coordinated planning among various agencies involved in land use planning in order to allocate space within the city for STPs/SPSs.\n",
      "Real:  {'sewerage management', 'land use planning'}\n",
      "OK:  {'sewerage management', 'land use planning'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not OK result:  {'absence of coordinated planning', 'sewer tariffs'}\n",
      "Not FOUND result:  set()\n",
      "Outside temperature had a limited effect on both the temperature and the microbiological quality of the water in the reservoirs, which did not comply with Dutch drinking water legislation and should thus not be consumed without treatment.\n",
      "Real:  {'reservoirs', 'Dutch drinking water legislation'}\n",
      "OK:  {'reservoirs'}\n",
      "Not OK result:  {'treatment'}\n",
      "Not FOUND result:  {'Dutch drinking water legislation'}\n",
      "yada SELECTION, FEASBILITY STUDIES, AND P. Advise and train utilities on best practices for commercial performance, including gender equity and leadership training Collaborators (MuniWASH partners, NGOs, Caan a1 hoe | RE-INTERMEDIATE RESULT ACTIVITIES SODECI, SONEB, private service providers, SEGURA, STTA Advise utilities on cost-reducing measures from non revenue water, asset management, O&M, energy efficiency, and information systems Responsible Party (MuniWASH team lead) ES/BPAs, F&IAs, GESI Specialist SODECI, SONEB, private service providers, SEGURA, STTA Link financial performance to pro-poor goals ES/BPAs Selected municipalities, ONEP, DG EAU, SODECI, SONEB, private service providers RCI CM, Benin CM, ES/BPAs Task 1.6: Improve government financial planning and oversight - Benin and Céte d’Ivoire Work with national authorities to prepare for capital raising with donors and private sector ONEP, DGIHH, DG EAU Support national authorities in a tariff review and stakeholder dialogue RCI CM, Benin CM, F&lAs ONEP, DGIHH, DG EAU Perform review of utility service contracts and recommend performance-based contracts and incentives RCI CM, Benin CM, F&lAs ONEP, DGIHH, DG EAU, SODECI, SONEB, STTA Support national authorities to improve asset management and financial accounting practices RCI CM, Benin CM, F&lAs ONEP, DGIHH, DGDDL, DG EAU, DGCL, DNSP RCI CM, Benin CM, ES/BPAs Task 1.7: Expand service provider and customer access to financial products - Benin and Céte d’Ivoire Organize training for MFls and commercial banks in sanitation service business model viability MFls, commercial investors, STTA F&lAs IR2: IMPROVED OPERATIONAL RELIABILITY OF WATER AND SANITATION UTILITIES/SERVICE PROVIDERS Task 2.1: Conduct market mapping and customer satisfaction reviews — Benin and Céte d’lvoire Perform market mapping of service coverage with stakeholders (part of feasibility studies) including review of sanitation issues impacting scale/uptake elected municipalities, util , service providers, PSI, SEGURA Complete customer surveys to capture customer feedback on service quality and coverage elected municipalities, lutilities, service ers, PSI, SEGURA Create GIS mapping to visualize service gaps Utilities, service Identify capacity needs to improve business practices of water and sanitation utilities and service providers ers, PSI, SEGURA Develop TOT programs with training centers and AfWA FWA, training centers, PSI, SEGURA Develop hands-on training and technology- and video-based trainings for service providers Train MFI agents who promote sanitation-based financial products Establish women’s task force/gender focal points to review hiring/promotion criteria/other disparities Utilities, service roviders, PSI, AfWA Task 2.4: Expand and diversify pro-poor services — Benin and Céte d’Ivoire Catalogue affordable and context-appropriate emerging innovations for pro-poor services Utilities, service ers, AfWA, PSI USAID/WEST AFRICA MUNICIPAL WASH : YEAR | QUARTERLY REPORT 3, APRIL-JUNE 2020 DCOP, RCI CM, Benin CM, SMAs, SSD, home office STTA DCOP, ES/BPAs, SMAs, home office STTA Home office STTA ES/BPA, SMAs, SSDS KSLA, ES/BPAs, SMAs, SSDS KSLA, ES/BPAs, SMAs, SSDS KSLA, SMAs, F&IAs, Comms Specialist ES/BPAs, SMAs, GESI Specialist ES/BPAs, SMAs, SSDS 29\n",
      "Real:  {'Perform market mapping of service coverage', 'Conduct market mapping and customer satisfaction reviews', 'Organize training for MFls and commercial banks', 'promote sanitation-based financial products', 'recommend performance-based contracts and incentives', 'Support national authorities in a tariff review', 'Perform review of utility service contracts', 'Develop hands-on training and technology- and video-based trainings', 'Improve government financial planning', 'gender equity and leadership training', 'improve business practices of water and sanitation utilities', 'Complete customer surveys to capture customer feedback', 'Advise utilities on cost-reducing measures', 'Expand service provider and customer access to financial products', 'Support national authorities to improve asset management and financial accounting practices', 'sanitation service business'}\n",
      "OK:  {'Perform market mapping of service coverage', 'Conduct market mapping and customer satisfaction reviews'}\n",
      "Not OK result:  {'pro-poor services', 'Expand and diversify pro-poor services', 'WATER AND SANITATION UTILITIES/SERVICE PROVIDERS Task 2.1', 'hands-on training and technology-', 'capital raising', 'water and sanitation utilities', 'sanitation service business model', 'government financial planning', 'leadership training', 'information systems', 'recommend performance-based contracts', 'asset management and financial accounting practices RCI CM', 'video-based trainings', 'business practices of', 'customer surveys', 'promote sanitation-based financial products Establish women’s task force/gender focal points'}\n",
      "Not FOUND result:  {'Organize training for MFls and commercial banks', 'recommend performance-based contracts and incentives', 'promote sanitation-based financial products', 'Support national authorities in a tariff review', 'Perform review of utility service contracts', 'Develop hands-on training and technology- and video-based trainings', 'Improve government financial planning', 'gender equity and leadership training', 'improve business practices of water and sanitation utilities', 'Complete customer surveys to capture customer feedback', 'Advise utilities on cost-reducing measures', 'Expand service provider and customer access to financial products', 'Support national authorities to improve asset management and financial accounting practices', 'sanitation service business'}\n",
      "The foundations of IPM practices should be taught as early as possible in existing agricultural education programs\n",
      "Real:  {'agricultural education programs', 'IPM practices'}\n",
      "OK:  {'agricultural education programs'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'IPM practices'}\n",
      "[Probe: implementation plans, cooperation with the government, with the water utility).\n",
      "Real:  {'water utility'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water utility'}\n",
      "Application to Handwashing Pregnancy, onset of menstruation, new parenthood, moving residence, are all examples of context changes that may create a window of opportunity to change handwashing behavior.\n",
      "Real:  {'handwashing', 'change handwashing behavior'}\n",
      "OK:  {'change handwashing behavior'}\n",
      "Not OK result:  {'Handwashing'}\n",
      "Not FOUND result:  {'handwashing'}\n",
      "WASH practices were significantly associated with age, education, marital status, and WASH knowledge.\n",
      "Real:  {'WASH practices'}\n",
      "OK:  {'WASH practices'}\n",
      "Not OK result:  {'WASH knowledge'}\n",
      "Not FOUND result:  set()\n",
      "Also discussed are supply chain initiatives by companies, such as Walmart's direct farm programme, ITC's e-Choupal programme, and EID Parry's Indiagriline portal\n",
      "Real:  {'supply chain initiatives', 'direct farm programme'}\n",
      "OK:  {'supply chain initiatives', 'direct farm programme'}\n",
      "Not OK result:  {'ITC'}\n",
      "Not FOUND result:  set()\n",
      "We find that a two-thirds share of cellulosic biofuel in the mandated level could reduce nitrate run-off by 20% while reducing GHG emissions by 88-100% but would reduce profits by 15-27% depending on whether a GHG policy or a Nitrate policy is used relative to the case where the mandate is met by corn ethanol alone.\n",
      "Real:  {'GHG policy', 'Nitrate policy', 'Nitrate'}\n",
      "OK:  {'GHG policy', 'Nitrate policy'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Nitrate'}\n",
      "A non-governmental organisation has distributed point-of-use water filtering units in the Western Division of Fiji.\n",
      "Real:  {'point-of-use water filtering units'}\n",
      "OK:  set()\n",
      "Not OK result:  {'point-of-use water filtering'}\n",
      "Not FOUND result:  {'point-of-use water filtering units'}\n",
      "Climate change will not have significant impact on Tono irrigation project because future irrigation abstraction when maximum land areas between 1985 and 2006 are cultivated will be about 33 - 35 % of the maximum storage of the reservoir.\n",
      "Real:  {'reservoir', 'irrigation project'}\n",
      "OK:  {'reservoir'}\n",
      "Not OK result:  {'Tono irrigation project'}\n",
      "Not FOUND result:  {'irrigation project'}\n",
      "By analyzing the core issues existing in China's current land consolidation engineering construction standards based on the case study of Shanghai, using literature analysis and system engineering method, we put forward the following key points for the compilation of land consolidation engineering construction standards during the strategic transformation period: the land consolidation engineering system reconstruction, green improvement land consolidation project, village renovation project, and modern agriculture support engineering.\n",
      "Real:  {'green improvement land consolidation project', 'land consolidation engineering system reconstruction', 'village renovation project', 'modern agriculture support engineering', 'land consolidation engineering construction standards'}\n",
      "OK:  {'land consolidation engineering system reconstruction', 'green improvement land consolidation project', 'village renovation project', 'land consolidation engineering construction standards'}\n",
      "Not OK result:  {'agriculture support engineering', 'system engineering method', 'transformation'}\n",
      "Not FOUND result:  {'modern agriculture support engineering'}\n",
      "The WARIDI grant awarded and described in Task 3.2 below will, in Q3, begin to revitalize natural resource committees and develop village land use plans (in the Mngeta sub-catchment of the Kilombero upper catchment) that explicitly take account of IWRM issues, including protection of water sources, and riverside demarcation and conservation in line with the national water policy.\n",
      "Real:  {'riverside demarcation and conservation', 'develop village land use plans', 'protection of water sources', 'national water policy', 'revitalize natural resource committees'}\n",
      "OK:  {'revitalize natural resource committees', 'protection of water sources'}\n",
      "Not OK result:  {'conservation in line with the national water policy', 'village land use plans'}\n",
      "Not FOUND result:  {'riverside demarcation and conservation', 'develop village land use plans', 'national water policy'}\n",
      "This approach is logical as guidance from the center needs to be accommodating at the local/national level where the day-to-day majority of the funding and programmatic decisions are taken.\n",
      "Real:  {'accommodating at the local/national level'}\n",
      "OK:  set()\n",
      "Not OK result:  {'day-to-day majority of the funding and'}\n",
      "Not FOUND result:  {'accommodating at the local/national level'}\n",
      "The range of values for pH, total dissolved solids (TDS), dissolved oxygen (do), biochemical oxygen demand (BOD), total suspended solids (TSS), nitrate, ammonium, phosphate, and oil/grease in river water and sediment were higher than recommended limits prescribed by the World Health Organization's Guidelines for Drinking-water Quality (GDWQ).\n",
      "Real:  {\"World Health Organization's Guidelines for Drinking-water Quality (GDWQ)\"}\n",
      "OK:  {\"World Health Organization's Guidelines for Drinking-water Quality (GDWQ)\"}\n",
      "Not OK result:  {'phosphate', 'biochemical oxygen demand (BOD)'}\n",
      "Not FOUND result:  set()\n",
      "Their quality might also influence the decision whether to visit a health facility.\n",
      "Real:  {'health facility'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'health facility'}\n",
      "Having completed the stakeholder workshops for the four cities and three industry sectors, the project staff will work with these partners to implement the action plans and recommendations developed.\n",
      "Real:  {'stakeholder workshops'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'stakeholder workshops'}\n",
      "The Project is therefore working with both landlords and tenants to leverage the cost-based interest in reducing water consumption; this is done in the form of Project-sponsored agreements in which landlords pass on any cost savings through water conservation as rebates on their tenants’ rent.\n",
      "Real:  {'Project-sponsored agreements in which landlords', 'cost savings through water conservation', 'rebates on their tenants’ rent'}\n",
      "OK:  set()\n",
      "Not OK result:  {'rent', 'water conservation'}\n",
      "Not FOUND result:  {'Project-sponsored agreements in which landlords', 'rebates on their tenants’ rent', 'cost savings through water conservation'}\n",
      "RI/F has a history of partnering for fundraising and even for raising awareness around an issue (like polio).\n",
      "Real:  {'fundraising', 'raising awareness'}\n",
      "OK:  set()\n",
      "Not OK result:  {'raising awareness around an issue (like polio)'}\n",
      "Not FOUND result:  {'fundraising', 'raising awareness'}\n",
      "The audit should cover drinking water, handwashing, latrines, facilities, and products for MHM, and pay attention to the quality of the facilities and whether the practices are being done.\n",
      "Real:  {'handwashing', 'MHM', 'latrines'}\n",
      "OK:  {'handwashing', 'MHM', 'latrines'}\n",
      "Not OK result:  {'practices are being done'}\n",
      "Not FOUND result:  set()\n",
      "More finance and better use of financing instruments would extend and improve WaSH services.\n",
      "Real:  {'WaSH services', 'better use of financing instruments', 'More finance'}\n",
      "OK:  {'WaSH services'}\n",
      "Not OK result:  {'financing instruments'}\n",
      "Not FOUND result:  {'better use of financing instruments', 'More finance'}\n",
      "Filtration of larger sample volumes facilitates increased detection sensitivity.\n",
      "Real:  {'Filtration'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Filtration'}\n",
      "A classification of resilient and non-resilient households was based on respondents’ perception scores of their water systems before the earthquake and one month after.\n",
      "Real:  {'water systems', 'classification of resilient and non-resilient households'}\n",
      "OK:  {'water systems'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'classification of resilient and non-resilient households'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "follow-up support will TEST methods OF continuing communication and support OF trainees to assist them in implementing national environmental policy goals.\n",
      "Real:  {'national environmental policy', 'communication and support OF trainees'}\n",
      "OK:  {'national environmental policy'}\n",
      "Not OK result:  {'methods OF continuing communication'}\n",
      "Not FOUND result:  {'communication and support OF trainees'}\n",
      "This study analyses the rural communities’ choice and perception of WSM infrastructure and their willingness to pay (WTP) for their improvement and maintenance.\n",
      "Real:  {'rural communities’ choice', 'their willingness to pay (WTP)', 'perception of WSM infrastructure'}\n",
      "OK:  set()\n",
      "Not OK result:  {'WSM infrastructure'}\n",
      "Not FOUND result:  {'rural communities’ choice', 'their willingness to pay (WTP)', 'perception of WSM infrastructure'}\n",
      "The following re technologies, identified as high priority by the Government of Egypt (GOE), will be field tested at public sector sites: (1) solar applications, including solar water heating for a milk products plant and for metal processing; solar-assisted fruit dehydration; and solar energy and waste heat recovery for poultry processing and textile dyeing; (2) photovoltaic power applications for fishermen's shelters, small farm irrigation, and a reverse osmosis water desalinization (ROWD) plant; (3) wind-powered systems for village electrification and for a ROWD system to provide fresh water along the Red Sea coast; and (4) a solar-powered Rankine cycle cold storage system.\n",
      "Real:  {'solar-assisted fruit dehydration', 'small farm irrigation', 'solar-powered Rankine cycle cold storage system', 'solar water heating', 'reverse osmosis water desalinization (ROWD) plant', 'solar applications', \"photovoltaic power applications for fishermen's shelters\", 'provide fresh water', 'wind-powered systems for village electrification', 'solar energy and waste heat recovery for poultry processing and textile dyeing'}\n",
      "OK:  {'solar-powered Rankine cycle cold storage system', 'solar applications', 'solar-assisted fruit dehydration'}\n",
      "Not OK result:  {'solar water heating for a milk products plant and for metal processing', 're technologies', 'wind-powered systems', 'solar energy and waste heat recovery for poultry processing'}\n",
      "Not FOUND result:  {'small farm irrigation', 'solar water heating', 'reverse osmosis water desalinization (ROWD) plant', \"photovoltaic power applications for fishermen's shelters\", 'provide fresh water', 'wind-powered systems for village electrification', 'solar energy and waste heat recovery for poultry processing and textile dyeing'}\n",
      "Three characteristics of a water resilient household were: (i) use of greater number of water sources, (ii) use of multiple reliable water sources such as piped water, groundwater, and (iii) use of effective adaptive strategies such as water storage in a bigger container.\n",
      "Real:  {'water storage in a bigger container', 'piped water', 'groundwater'}\n",
      "OK:  {'piped water'}\n",
      "Not OK result:  {'water storage'}\n",
      "Not FOUND result:  {'water storage in a bigger container', 'groundwater'}\n",
      "Using purposive sampling, we conducted key informant interviews and focus group discussions with scientists, journalists and members of the public in Ghana and Uganda to identify issues associated with the promotion of public engagement with WASH and other environmental health issues.\n",
      "Real:  {'focus group discussions', 'public engagement with WASH and other environmental health issues', 'key informant interviews'}\n",
      "OK:  {'key informant interviews'}\n",
      "Not OK result:  {'promotion of public engagement with WASH', 'focus group discussions with scientists'}\n",
      "Not FOUND result:  {'focus group discussions', 'public engagement with WASH and other environmental health issues'}\n",
      "A number of interacting issues influence the effectiveness of filtration for the removal of Cryptosporidium oocysts from swimming pools.\n",
      "Real:  {'filtration for the removal of Cryptosporidium oocysts from swimming pools'}\n",
      "OK:  set()\n",
      "Not OK result:  {'filtration for the removal of Cryptosporidium oocysts'}\n",
      "Not FOUND result:  {'filtration for the removal of Cryptosporidium oocysts from swimming pools'}\n",
      "Collectively water, sanitation and hygiene (WASH) are seen as a key focus area for both organizations and are embedded in their current strategies.\n",
      "Real:  {'water, sanitation and hygiene (WASH)'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water, sanitation and hygiene (WASH)'}\n",
      "It will include technical assistance to be provided by Valu Add Management Services (subcontracted by DAI), a grant to AMCOW and ongoing support by WALIS team and Senior Institutional Development and Program Implementation Advisor.\n",
      "Real:  {'Valu Add Management Services', 'Senior Institutional Development'}\n",
      "OK:  set()\n",
      "Not OK result:  {'technical assistance'}\n",
      "Not FOUND result:  {'Valu Add Management Services', 'Senior Institutional Development'}\n",
      "Although some constraints remain, the projects in Ghana are mainly regarded as successful and there is scope to scaleup or replicate the activities — especially if there is more creative engagement with government agencies (and their national policies and important regional offices) and if better sequencing of activities is promoted.\n",
      "Real:  {'national policies'}\n",
      "OK:  set()\n",
      "Not OK result:  {'policies and important regional offices'}\n",
      "Not FOUND result:  {'national policies'}\n",
      "The SCIP strategy is a continuum of complementary activities involving all existing levels in order to create “more” sustainability for water access and positive individual and collective hygiene and sanitation behavior.\n",
      "Real:  {'SCIP strategy', 'create “more” sustainability for water access', 'positive individual and collective hygiene and sanitation behavior'}\n",
      "OK:  set()\n",
      "Not OK result:  {'sanitation behavior'}\n",
      "Not FOUND result:  {'SCIP strategy', 'create “more” sustainability for water access', 'positive individual and collective hygiene and sanitation behavior'}\n",
      "As a signatory to the un Goals, Australia has a commitment to ensure the access and quality of these resources is attained for all, including Indigenous Australians living in remote communities.\n",
      "Real:  {'access and quality of these resources'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'access and quality of these resources'}\n",
      "d. Prepare EMMP On-going Management Program management will take place through four levels of responsibility to ensure quality implementation and rapid problem solving: |) a multi-stakeholder technical advisory group (WITAC); 2) an internal program steering committee; 3) a program management unit (PMU); and 4) field implementation teams.\n",
      "Real:  {'Prepare EMMP On-going Management Program management'}\n",
      "OK:  set()\n",
      "Not OK result:  {'ensure quality implementation', 'an internal program', 'program management unit (PMU)'}\n",
      "Not FOUND result:  {'Prepare EMMP On-going Management Program management'}\n",
      "Involvement of political leaders and government officials from the council level to the lowest governmental unit offered important support for CLTS implementation.\n",
      "Real:  {'CLTS implementation', 'Involvement of political leaders and government officials'}\n",
      "OK:  set()\n",
      "Not OK result:  {'support for CLTS implementation'}\n",
      "Not FOUND result:  {'CLTS implementation', 'Involvement of political leaders and government officials'}\n",
      "Results of water quality tests and the consumer survey revealed risk in direct drinking of tap water and a need to improve tap water quality by managing free residual chlorine and leakage reduction.\n",
      "Real:  {'managing free residual chlorine and leakage reduction', 'improve tap water quality', 'water quality tests', 'consumer survey', 'free residual chlorine'}\n",
      "OK:  {'consumer survey', 'water quality tests'}\n",
      "Not OK result:  {'tap water', 'tap water quality', 'managing free residual chlorine'}\n",
      "Not FOUND result:  {'managing free residual chlorine and leakage reduction', 'free residual chlorine', 'improve tap water quality'}\n",
      "This chapter describes measures studied for a case study area in Rotterdam, gives an analysis of the policies, laws, and regulations relating to these measures, and examines the implications for urban flood management.\n",
      "Real:  {'urban flood management'}\n",
      "OK:  {'urban flood management'}\n",
      "Not OK result:  {'regulations relating'}\n",
      "Not FOUND result:  set()\n",
      "To date, WADA funding has supported the installation of subsidized household latrines (425), public sanitation facilities (9), and miniboreholes (103), as well as activities related to CLTS.\n",
      "Real:  {'activities related to CLTS', 'public sanitation facilities', 'miniboreholes', 'subsidized household latrines', 'WADA funding'}\n",
      "OK:  {'public sanitation facilities', 'subsidized household latrines', 'WADA funding'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'miniboreholes', 'activities related to CLTS'}\n",
      "This multidisciplinary initiative focused on three objectives: e Integrating water, sanitation, food hygiene, and hand washing into nutrition and Feed the Future activities e Incorporating water, sanitation, food hygiene, menstrual hygiene, and hand washing into community and clinically based HIV activities e Strengthening the capacity of local districts to plan, budget, implement, and monitor water, sanitation, and hygiene (WASH)-related activities As a strategy for sustainability and scale, WASHplus bolstered district government and USAID implementing partner services and programs, rather than implementing its own activities.\n",
      "Real:  {'hand washing', 'menstrual hygiene', 'monitor water, sanitation, and hygiene (WASH)-related activities', 'food hygiene', 'community and clinically based HIV activities', 'partner services and programs', 'water, sanitation'}\n",
      "OK:  {'hand washing', 'menstrual hygiene', 'monitor water, sanitation, and hygiene (WASH)-related activities', 'food hygiene', 'water, sanitation'}\n",
      "Not OK result:  {'services and programs', 'Strengthening the capacity of local districts to plan'}\n",
      "Not FOUND result:  {'partner services and programs', 'community and clinically based HIV activities'}\n",
      "Conducting simulations and drills is the most effective way to evaluate and test disaster preparedness plans; these exercises are used widely by organizations and institutions working in development and in disaster response.\n",
      "Real:  {'disaster preparedness plans'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Conducting simulations and drills', 'evaluate and test disaster preparedness plans'}\n",
      "Not FOUND result:  {'disaster preparedness plans'}\n",
      "The Paddy Land-to-Dry Land (PLDL) program was a 10-year long (2006-2015) agricultural engineering program, initiated jointly by Beijing and Heibei Province, that was designed to increase urban water availability and improve household livelihoods in local farming communities.\n",
      "Real:  {'agricultural engineering program'}\n",
      "OK:  {'agricultural engineering program'}\n",
      "Not OK result:  {'Paddy Land-to-Dry Land (PLDL) program'}\n",
      "Not FOUND result:  set()\n",
      "The clines in growth and survival with regional rainfall patterns suggest that tree improvement and conservation programs should collect seeds from populations in the drier zones for planting and conservation in the West African Sahel.\n",
      "Real:  {'tree improvement', 'conservation programs'}\n",
      "OK:  {'conservation programs'}\n",
      "Not OK result:  {'tree improvement and', 'collect seeds'}\n",
      "Not FOUND result:  {'tree improvement'}\n",
      "The editors note that the guides, while developed for use within the context of environmental health projects, could be adapted to improve the community-related skills of field staff involved in other aspects of water supply and sanitation projects\n",
      "Real:  {'water supply', 'sanitation projects', 'environmental health projects'}\n",
      "OK:  {'water supply', 'sanitation projects', 'environmental health projects'}\n",
      "Not OK result:  {'improve the community-related skills of field staff'}\n",
      "Not FOUND result:  set()\n",
      "INTRODUCTION To see improvements in health, social, and economic well-being of families in the project districts in Southwest Bangladesh, the WASHplus activity works towards three objectives: Objective 1: Improved access to safe drinking water, improved sanitation, and hygiene practices of poor and marginalized people in the targeted upazilas (subdistricts) Objective 2: Build community and local government capacity to operate and maintain facilities, and demand increased allocation of funds to ensure sustainability and impact Objective 3: Strengthen the evidence base and programming guidance for coordinated WASH-nutrition programming in Bangladesh While the need for improved water and sanitation access is clear, there is consensus that no health or other development objectives can be achieved without the consistent and correct practice of a suite of water, sanitation, and hygiene (WASH) behaviors including: e Safe and hygienic disposal of feces, including infant feces e Consistent and correct handwashing at critical junctures, particularly after defecation and before food preparation and feeding/eating e Safe handling and storage of household water e Menstrual hygiene management (MHM) WASHplus is managed by FHI 360 and implemented in southwest Bangladesh through an agreement with WaterAid, who in turn have engaged local partner organizations (PNGOs) to implement in their respective upazilas or subdistricts.\n",
      "Real:  {'sanitation', 'hygiene practices', 'Build community and local government capacity', 'improved water and sanitation', 'engaged local partner organizations (PNGOs)', 'Improved access to safe drinking water', 'handwashing', 'Safe handling and storage of household water', 'hygienic disposal of feces', 'Menstrual hygiene management (MHM)', 'improved water and sanitation access', 'increased allocation of funds', 'WASH-nutrition programming', 'water, sanitation, and hygiene (WASH) behaviors'}\n",
      "OK:  {'hygiene practices', 'Improved access to safe drinking water', 'Menstrual hygiene management (MHM)', 'improved water and sanitation access', 'WASH-nutrition programming', 'water, sanitation, and hygiene (WASH) behaviors'}\n",
      "Not OK result:  {'Safe and hygienic disposal of feces', 'before food preparation', 'improved sanitation', 'feeding/eating e Safe handling and storage of household water', 'correct handwashing', 'programming guidance for coordinated'}\n",
      "Not FOUND result:  {'sanitation', 'Build community and local government capacity', 'improved water and sanitation', 'engaged local partner organizations (PNGOs)', 'handwashing', 'Safe handling and storage of household water', 'hygienic disposal of feces', 'increased allocation of funds'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main part of this issue consists of 10 papers on various aspects of participatory extension in developing countries: (1) Supporting farmer extension and research ; (2) Andean community planning - encouraging Andean rationality and bridging over to western rationality - in Ecuador; (3) Participatory pre-test method in community forestry management training - in Nepal; (4) Greening the barren slopes: silvopastoral promotion in an arid Himalayan region - a case study - in Nepal; (5) Listening to farmers: indigenous technical knowledge - an important tool for community forestry development - in Nepal; (6) Putting community forestry into the curriculum; a case study from Nepal ; (7) The process continues - implementing the new community forestry curriculum at IOF - the Institute of Forestry in Nepal; (8) Participatory tools for enhancing local initiatives -an account of a 6-wk training course held in the Netherlands in 1992; (9) Of people and trees - experiences of addressing population/environment issues in a social forestry project in Senegal ; and (10) From the journal of an extension worker - in Ethiopia\n",
      "Real:  {'Greening the barren slopes', 'social forestry project', 'community planning', 'community forestry management training', 'Supporting farmer extension and research', 'Putting community forestry into the curriculum', 'community forestry development', 'silvopastoral promotion'}\n",
      "OK:  {'Greening the barren slopes', 'social forestry project', 'community planning', 'community forestry management training', 'Supporting farmer extension and research'}\n",
      "Not OK result:  {'community forestry development - in Nepal'}\n",
      "Not FOUND result:  {'community forestry development', 'silvopastoral promotion', 'Putting community forestry into the curriculum'}\n",
      "This pump is now undergoing field trials across East Africa with a view to it being marketed and sold to pit-emptying entrepreneurs by Sanitation Solutions Group\n",
      "Real:  {'marketed and sold to pit-emptying entrepreneurs', 'field trials', 'pump'}\n",
      "OK:  set()\n",
      "Not OK result:  {'pit-emptying entrepreneurs by Sanitation Solutions'}\n",
      "Not FOUND result:  {'pump', 'marketed and sold to pit-emptying entrepreneurs', 'field trials'}\n",
      "The project built the capacities of i) 11 LNGOs who were trained in community entry and animation, community _ profiling, analyzing techniques, action plan development, participatory methodologies, and communication and presentation skills; ii) 277 WatSan Committees (operation and maintenance of the water facilities) and 467 Community Based Hygiene Picture 1 : Ghana Wash project field staff interact with school children Promoters (effective use of the ‘ring SHEP activity hygiene facilitation tools/methods) ; iii) 300 teachers and School based health coordinators (SHEP training); iv) 442 food vendors in food hygiene and safety practices, basic nutrition and healthy eating, as well as hand-washing techniques; v) 332 artisans in latrine construction; and vi) two drilling enterprises in manual drilling.\n",
      "Real:  {'food hygiene and safety practices', 'SHEP activity hygiene facilitation tools/methods', 'artisans in latrine construction', 'water facilities', 'basic nutrition and healthy eating', 'hand-washing techniques'}\n",
      "OK:  {'hand-washing techniques'}\n",
      "Not OK result:  {'latrine construction', 'Community Based Hygiene Picture', 'Wash project'}\n",
      "Not FOUND result:  {'food hygiene and safety practices', 'SHEP activity hygiene facilitation tools/methods', 'artisans in latrine construction', 'water facilities', 'basic nutrition and healthy eating'}\n",
      "The SCIP team focused on strengthening community systems to bring about behavior change and community services to contribute to better health outcomes, while simultaneously addressing social determinants of health.\n",
      "Real:  {'community services to contribute to better health outcomes', 'strengthening community systems to bring about behavior change'}\n",
      "OK:  set()\n",
      "Not OK result:  {'community services'}\n",
      "Not FOUND result:  {'community services to contribute to better health outcomes', 'strengthening community systems to bring about behavior change'}\n",
      "During the life of the sens project, participating NGOs have grown rapidly, dramatically increasing their environmental activities, as illustrated by the following trends: (1) The 8 primary sens NGOs carried out more than 3 times as much environmental work (based on financial investment) in 1994 as in 1992.\n",
      "Real:  {'environmental activities', 'financial investment'}\n",
      "OK:  set()\n",
      "Not OK result:  {'increasing their environmental activities', 'financial investment)'}\n",
      "Not FOUND result:  {'environmental activities', 'financial investment'}\n",
      "The wastewater treatment system includes an anaerobic baffled reactor that will reduce about 70% of the pollution from the sewage and a secondary treatment system, which utilizes cocopeat as a filtration medium.\n",
      "Real:  {'wastewater treatment system', 'cocopeat', 'filtration', 'treatment system', 'anaerobic baffled reactor'}\n",
      "OK:  {'treatment system', 'wastewater treatment system'}\n",
      "Not OK result:  {'anaerobic', 'filtration medium'}\n",
      "Not FOUND result:  {'cocopeat', 'filtration', 'anaerobic baffled reactor'}\n",
      "Approaches adopted have been: orientation camps; training sessions; study trips; awareness raising programmes for NGO leaders, organizers and small/marginal farmers and schoolchildren; and two village level experiments established in close collaboration with NGOs who are members of the SFIP.\n",
      "Real:  {'orientation camps', 'training sessions', 'study trips', 'awareness raising programmes'}\n",
      "OK:  {'training sessions', 'awareness raising programmes'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'orientation camps', 'study trips'}\n",
      "“ Consensus-based decision-making has allowed both organizations to move at its own pace and within its own comfort levels.\n",
      "Real:  {'Consensus-based decision-making'}\n",
      "OK:  {'Consensus-based decision-making'}\n",
      "Not OK result:  {'move at its own pace and within its own comfort levels'}\n",
      "Not FOUND result:  set()\n",
      "For future marine bioprospecting activities, a harmonized legal position was put together in collaboration with other EU-FP7 blue biotechnology projects\n",
      "Real:  {'biotechnology projects'}\n",
      "OK:  set()\n",
      "Not OK result:  {'harmonized', 'blue biotechnology projects', 'marine bioprospecting activities'}\n",
      "Not FOUND result:  {'biotechnology projects'}\n",
      "The construction of 4014 wells, 755 tanks, and 786 dams in Ranchi, and 1256 wells, 245 tanks, and 765 dams in Chandwa resulted in increased cropping intensity, higher yields per acre, and a corresponding increase in the marketable surplus for project beneficiaries, primarily small farmers holding 1-10 acres.\n",
      "Real:  {'tanks', 'wells', 'dams'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'tanks', 'wells', 'dams'}\n",
      "e Wash hands with soap before handling food (preparing food, feeding children, and eating) and after contact with human feces (cleaning up a child’s bottom, cleaning up the feces of a person who is chronically ill or defecating, visiting a toilet) e Treat drinking water using efficacious technologies including chlorination, filtration, or solar disinfection e Cover drinking water using a tight lid e Use a narrow neck container to store treated drinking water Wash blood-stained menstrual materials and dry in sun Specific WASHplus Program Activities Using the USAID-developed Hygiene Improvement Framework, WASHplus’s mandate in Kenya is to work on the framework’s three elements: enabling environment, access to hardware products and services, and hygiene promotion.\n",
      "Real:  {'tight lid', 'hygiene promotion', 'cleaning up the feces', 'Hygiene Improvement Framework', 'Wash blood-stained menstrual materials', 'Treat drinking water', 'cleaning up a child’s bottom', 'efficacious technologies', 'narrow neck container', 'filtration', 'access to hardware products and services', 'solar disinfection', 'Wash hands with soap', 'store treated drinking water', 'chlorination'}\n",
      "OK:  {'hygiene promotion', 'access to hardware products and services'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'tight lid', 'cleaning up the feces', 'Hygiene Improvement Framework', 'Wash blood-stained menstrual materials', 'Treat drinking water', 'cleaning up a child’s bottom', 'efficacious technologies', 'narrow neck container', 'filtration', 'solar disinfection', 'Wash hands with soap', 'store treated drinking water', 'chlorination'}\n",
      "Initially, 157 community health workers (CHWs) distributed chlorine tablets; ten months later, CHWs began selling locally manufactured solution.\n",
      "Real:  {'chlorine tablets'}\n",
      "OK:  {'chlorine tablets'}\n",
      "Not OK result:  {'community health workers (CHWs)'}\n",
      "Not FOUND result:  set()\n",
      "Notable differences include the limited access to heated water and negligible garden irrigation at the low-cost houses.\n",
      "Real:  {'negligible garden irrigation', 'access to heated water'}\n",
      "OK:  set()\n",
      "Not OK result:  {'access to heated water and negligible garden irrigation'}\n",
      "Not FOUND result:  {'negligible garden irrigation', 'access to heated water'}\n",
      "ae aie ongoing Improved agricultural Number of people benefitting from ; ; Output 2.2.1 technologies, infrastructure, and productive infrastructure and improved | 0 8,272 # 0 0% ongoing management practices promoted technologies Number of investments made in productive infrastructure projects and | 0 16 # 0 0% ongoing improved technologies Improved understanding of food Output 2.2.2 security and food systems in | Number of research projects completed | 0 1 # 0 0% ongoing Khatlon and GBAO 11\n",
      "Real:  {'infrastructure projects', 'investments'}\n",
      "OK:  {'investments'}\n",
      "Not OK result:  {'productive infrastructure', 'infrastructure', 'productive infrastructure projects', 'Output 2.2.1 technologies'}\n",
      "Not FOUND result:  {'infrastructure projects'}\n",
      "[tick four boxes] (¥] Hand washing I Proper handling and disposal of faeces O Hair combing O Car washing Diet Menstrual care MI Drinking safe water The goal of WASH care for PLHIV is to [tick one box]: Prevent malaria, increase bed net use, promote the eradication of mosquito breeding areas.\n",
      "Real:  {'promote the eradication of mosquito breeding areas', 'disposal of faeces', 'Hand washing', 'Menstrual care', 'WASH care', 'Prevent malaria'}\n",
      "OK:  {'Prevent malaria', 'disposal of faeces', 'Menstrual care'}\n",
      "Not OK result:  {'WASH', 'promote the eradication of mosquito breeding'}\n",
      "Not FOUND result:  {'promote the eradication of mosquito breeding areas', 'Hand washing', 'WASH care'}\n",
      "Again presumably Rotarians are not always very keen to use their influence in this way, would rather stick to the tangible hardware investments, but may also resent NGOs or other higher paid professionals intervening in their projects.\n",
      "Real:  {'hardware investments'}\n",
      "OK:  set()\n",
      "Not OK result:  {'higher paid professionals', 'tangible hardware investments'}\n",
      "Not FOUND result:  {'hardware investments'}\n",
      "Inaccessibility to treatment products in rural areas and use of bottled water in urban areas were among the reasons to discontinue point-ofuse water chlorination.\n",
      "Real:  {'bottled water', 'point-ofuse water chlorination'}\n",
      "OK:  {'bottled water'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'point-ofuse water chlorination'}\n",
      "Mid-term PES covers the period 9/82-6/85 and is based on several internal and external assessments.\n",
      "Real:  {'Mid-term PES'}\n",
      "OK:  set()\n",
      "Not OK result:  {'PES'}\n",
      "Not FOUND result:  {'Mid-term PES'}\n",
      "It also demonstrates the challenges of a city trying to influence land use outside its jurisdiction, the challenges of avoiding filtration in developed watersheds, and the role of regulations as forcing functions\n",
      "Real:  {'filtration in developed watersheds'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'filtration in developed watersheds'}\n",
      "The above methodology is tested on a semi-real case study aiming at improving the computational efficiency in development of optimal control strategies.\n",
      "Real:  {'optimal control strategies'}\n",
      "OK:  set()\n",
      "Not OK result:  {'development of optimal control strategies'}\n",
      "Not FOUND result:  {'optimal control strategies'}\n",
      "Many engineers managing sewerage services have traditional engineering training and are unfamiliar with the alternative approaches that are necessary to achieve largescale coverage and meet the SDGs.\n",
      "Real:  {'traditional engineering training', 'sewerage services'}\n",
      "OK:  {'traditional engineering training'}\n",
      "Not OK result:  {'managing sewerage services'}\n",
      "Not FOUND result:  {'sewerage services'}\n",
      "Advantage should be taken of the availability of this information to inform the process of policy formulation, planning, monitoring and evaluation of the HIV/AIDS and malaria programmes in Tanzania.\n",
      "Real:  {'monitoring and evaluation of the HIV/AIDS', 'malaria programmes'}\n",
      "OK:  set()\n",
      "Not OK result:  {'monitoring and evaluation of the HIV/AIDS and malaria programmes'}\n",
      "Not FOUND result:  {'monitoring and evaluation of the HIV/AIDS', 'malaria programmes'}\n",
      "The purpose of this study was twofold: first, to identify the challenges facing persons with physical disabilities in accessing safe household water and basic hygiene in rural Cambodia; and, second, to use these results to generate policy and practice recommendations for the water and sanitation hygiene sector implementing water treatment system interventions in rural settings.\n",
      "Real:  {'water treatment system interventions', 'water and basic hygiene'}\n",
      "OK:  {'water treatment system interventions'}\n",
      "Not OK result:  {'basic hygiene', 'water and sanitation hygiene', 'generate policy'}\n",
      "Not FOUND result:  {'water and basic hygiene'}\n",
      "Convention Baptiste d'Haiti (CBH) will utilize local resources and labor to construct the water systems, which will consist of drilled wells equipped with India Mark II handpumps.\n",
      "Real:  {'India Mark II handpumps', 'drilled wells', 'water systems'}\n",
      "OK:  {'drilled wells'}\n",
      "Not OK result:  {'utilize local resources and labor to construct the water systems'}\n",
      "Not FOUND result:  {'India Mark II handpumps', 'water systems'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAID was both daring and visionary to issue a request for applications (RFA) that integrated various technical components and funding streams, such as Water Supply and Sanitation, Agricultural Sector Capacity, Maternal and Child Health, Family Planning and Reproductive Health, Integrated Health Office, Malaria, Nutrition, etc.\n",
      "Real:  {'funding streams', 'Water Supply and Sanitation'}\n",
      "OK:  {'Water Supply and Sanitation'}\n",
      "Not OK result:  {'Maternal and Child Health'}\n",
      "Not FOUND result:  {'funding streams'}\n",
      "e Technical support and training to USAID implementing partners to integrate WASH into nutrition (SPRING Project assessment showed statistically significant differences in presence of at least 2 HW stations and observed HW practices) Integrated In work plan Delivered in reports Programming: WASH-Sanitation (including | CLTSplus (plus focuses on high coverage, low inclusive sanitation), _WASH- | quality latrines) Schools (including MHM), : : WASH-Nutrition, WASH. | SDAs for upgrading leaky latrines, HW) Hygiene.\n",
      "Real:  {'Technical support and training', 'sanitation', 'WASH into nutrition', 'CLTSplus', 'leaky latrines', 'WASH-Sanitation', 'quality latrines', 'Hygiene', 'leaky latrine', 'HW practices', 'HW stations', 'HW', 'MHM'}\n",
      "OK:  {'Technical support and training', 'WASH-Sanitation', 'MHM'}\n",
      "Not OK result:  {'WASH', 'leaky latrines, HW) Hygiene', 'observed HW practices) Integrated In work plan', 'low inclusive sanitation', 'WASH into nutrition (SPRING Project assessment'}\n",
      "Not FOUND result:  {'sanitation', 'WASH into nutrition', 'CLTSplus', 'leaky latrines', 'Hygiene', 'leaky latrine', 'HW practices', 'HW stations', 'HW', 'quality latrines'}\n",
      "In the United States, the national framework to address flood risk is the 50-year-old National Flood Insurance Program where the government bears the risk and private insurers handle customer policies.\n",
      "Real:  {'national framework to address flood risk'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'national framework to address flood risk'}\n",
      "Bottled water serves an increasingly large percentage of urban poor populations in lower-income countries, yet receives little attention within international development research and policy.\n",
      "Real:  {'Bottled water'}\n",
      "OK:  set()\n",
      "Not OK result:  {'water serves'}\n",
      "Not FOUND result:  {'Bottled water'}\n",
      "Construction of the two research stations in Darfur -- El Fasher and Ghazala Gawazat -- was delayed by four years due to governmental policy changes, material shortages, an adverse political climate, and poor management by the contractor.\n",
      "Real:  {'governmental policy changes'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'governmental policy changes'}\n",
      "Illustrative examples are given for each method of water conservation and reuse.\n",
      "Real:  {'water conservation and reuse'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water conservation and reuse'}\n",
      "The optimum yield was obtained from the application of 1:3 of urine and water, and comparable to the synthetic fertilizer (F ¼ 21.78; p ¼ 0.964).\n",
      "Real:  {'synthetic fertilizer', 'application of 1:3 of urine and water'}\n",
      "OK:  {'synthetic fertilizer'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'application of 1:3 of urine and water'}\n",
      "are generally resistant to common disinfection techniques and alternative control strategies are being sought.\n",
      "Real:  {'alternative control strategies', 'common disinfection techniques'}\n",
      "OK:  set()\n",
      "Not OK result:  {'control strategies'}\n",
      "Not FOUND result:  {'alternative control strategies', 'common disinfection techniques'}\n",
      "LWP will conduct an “Endline Citizen Perception and Satisfaction Survey” in Year 5 to evaluate how well water user needs have been met.\n",
      "Real:  {'Endline Citizen Perception and Satisfaction Survey'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Endline Citizen Perception and Satisfaction Survey'}\n",
      "A total of 2,552 glory pads (Kasole Secrets), 350 LIXIL SATO toilets, nine menstrual cups (Anuflo Industries), One Tembo filter (MSABI), two Nazava filters, two SON filters, and one money-maker pump (KickStart International) were sold in QI and Q2 as part of the WARIDI road show.\n",
      "Real:  {'money-maker pump', 'Nazava filters', 'glory pads', 'menstrual cups', 'toilets', 'SON filters', 'One Tembo filter'}\n",
      "OK:  {'money-maker pump', 'Nazava filters', 'glory pads', 'toilets', 'SON filters'}\n",
      "Not OK result:  {'nine menstrual cups'}\n",
      "Not FOUND result:  {'One Tembo filter', 'menstrual cups'}\n",
      "Objective: To understand the distribution and infection status of angiostrongyliasis transmission host in Jiangsu province Lake County and provide the basis for the development of angiostrongyliasis disease monitoring programs.\n",
      "Real:  {'angiostrongyliasis disease monitoring programs'}\n",
      "OK:  set()\n",
      "Not OK result:  {'development of angiostrongyliasis disease monitoring programs'}\n",
      "Not FOUND result:  {'angiostrongyliasis disease monitoring programs'}\n",
      "drought pri ion and modeling, water resources management, and walter conservation.\n",
      "Real:  {'water resources management', 'walter conservation', 'drought pri ion and modeling'}\n",
      "OK:  {'water resources management', 'walter conservation'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'drought pri ion and modeling'}\n",
      "A chemical pollution assessment and prioritisation model was developed for the Upper and Middle Vaal water management areas of South Africa in order to provide a simple and practical Pollution Index to assist with mitigation and rehabilitation activities.\n",
      "Real:  {'Upper and Middle Vaal water management', 'chemical pollution assessment', 'mitigation and rehabilitation activities'}\n",
      "OK:  set()\n",
      "Not OK result:  {'chemical pollution assessment and prioritisation model', 'Vaal water management', 'provide a simple and practical Pollution Index to assist with mitigation and rehabilitation activities'}\n",
      "Not FOUND result:  {'chemical pollution assessment', 'Upper and Middle Vaal water management', 'mitigation and rehabilitation activities'}\n",
      "A pilot study was undertaken to investigate the occurrence of Cryptosporidium in four very small drinking water systems supplying communities in rural Puerto Rico.\n",
      "Real:  {'small drinking water systems'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'small drinking water systems'}\n",
      "A model of the rate at which pit latrines fill was developed and compared with actual fill rates measured in latrines in Ifakara, Tanzania.\n",
      "Real:  {'pit latrines', 'latrines'}\n",
      "OK:  {'latrines'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'pit latrines'}\n",
      "Work during Year 1 was focused on start up activities such as stakeholder workshops and developing action plans, whereas Year 2 will focus more on wastewater treatment facility development.\n",
      "Real:  {'start up activities', 'stakeholder workshops', 'wastewater treatment facility development'}\n",
      "OK:  {'stakeholder workshops', 'wastewater treatment facility development'}\n",
      "Not OK result:  {'developing action'}\n",
      "Not FOUND result:  {'start up activities'}\n",
      "Force Majeure Risk Natural disaster Privatisation of off-taker Catastrophe, act of God events Political risk insurance Host government guarantee Insurance, to the extent possible Political risk War, riot, civil disturbance Insurance, to the extent possible Extreme weather Insurance, to the extent possible Prolonged force majeure 11.\n",
      "Real:  {'Extreme weather Insurance'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'Extreme weather Insurance'}\n",
      "The participatory forest fire prevention programme of Forest Fire Prevention Management Project (FFPMP) aims at intensive fuel management and fire control with the integrated green belt on community land on the boundary of Berbak National Park, Jambi Province, Sumatra.\n",
      "Real:  {'fuel management', 'fire control', 'forest fire prevention programme'}\n",
      "OK:  set()\n",
      "Not OK result:  {'participatory forest fire prevention programme', 'fire control with the integrated green belt on community land on the boundary of Berbak National Park, Jambi Province, Sumatra.', 'Prevention Management Project (FFPMP) aims at intensive fuel management'}\n",
      "Not FOUND result:  {'fuel management', 'fire control', 'forest fire prevention programme'}\n",
      "Women resorting to open defecation feel stressed and harassed by community leaders trying to enforce open defecation-free policies.\n",
      "Real:  {'open defecation-free policies', 'open defecation'}\n",
      "OK:  {'open defecation-free policies'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'open defecation'}\n",
      "The proposed bond was intended to finance four (4) infrastructure projects, including one for wastewater with the intention of DKI Jakarta channelling the funds as a grant to the wastewater '!2 PT Palyja is 51% ownd by Suez International (owner of Lyonnaise des Eaux and 49% by PT Astratel Nusantara, a subsidiary of PT Astra International '13 PT Pembangunan Jaya also has a 100 Ips WTP BOO in Bintaro Jaya, Kabupaten South Tangerang USAID INDONESIA URBAN WATER SANITATION AND HYGIENE WWW.IUWASH.OR.ID 29\n",
      "Real:  {'channelling the funds', 'proposed bond', 'grant to the wastewater', 'infrastructure projects'}\n",
      "OK:  {'infrastructure projects'}\n",
      "Not OK result:  {'WTP BOO'}\n",
      "Not FOUND result:  {'channelling the funds', 'proposed bond', 'grant to the wastewater'}\n",
      "Target operating conditions for the conical-augur device were 70 °C with a 6-s residence time; increasing the temperature allowed for reduced residence time to achieve A. suum inactivation\n",
      "Real:  {'conical-augur device'}\n",
      "OK:  {'conical-augur device'}\n",
      "Not OK result:  {'suum inactivation'}\n",
      "Not FOUND result:  set()\n",
      "The CASC approach features family life education; the BPESS approach links women's development, literacy, and income generation with FP; and the CEOSS SP provides FP within a comprehensive community development framework.\n",
      "Real:  {'family life education', 'BPESS approach', 'CASC approach'}\n",
      "OK:  {'family life education', 'CASC approach'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'BPESS approach'}\n",
      "A final section will relate these themes to some project-specific and transferable recommendations about the delivery of value chain projects with a particular focus on the concepts of governance, gender, and trust which are seen as central to the management of rural development projects\n",
      "Real:  {'rural development projects', 'value chain projects'}\n",
      "OK:  {'rural development projects'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'value chain projects'}\n",
      "It would develop a network of partners from Africa’s premier existing academic, training, and research institutions to provide the leadership development, change management, training, mentoring, and opportunities for learning and reflection on sanitation service provision.\n",
      "Real:  {'leadership development', 'training', 'change management', 'sanitation service provision', 'mentoring'}\n",
      "OK:  {'sanitation service provision'}\n",
      "Not OK result:  {'develop a network of partners', 'change management, training, mentoring, and opportunities for', 'academic, training, and research institutions to provide the leadership development'}\n",
      "Not FOUND result:  {'change management', 'leadership development', 'training', 'mentoring'}\n",
      "However, with the new water sector administration, WMI and other donors may have a renewed opportunity to see increased buy-in to pursue to establishment of a firewalled regulatory unit as an interim step, and move towards an independent regulator when service providers are fully privatized.\n",
      "Real:  {'establishment of a firewalled regulatory unit', 'water sector administration'}\n",
      "OK:  {'establishment of a firewalled regulatory unit'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not OK result:  {'water sector administration, WMI and'}\n",
      "Not FOUND result:  {'water sector administration'}\n",
      "DGs at RWEs will refer |N/A RWEs need to hire qualified engineers to to this document as their action plan to improve water security monitor the implementation.\n",
      "Real:  {'improve water security monitor'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'improve water security monitor'}\n",
      "Thus while Washington can suggest opportunities and help support Missions in delivering on its objectives and strategy, ultimately it is the Missions that require the capacity and interest to make these kinds of partnerships work.\n",
      "Real:  {'support Missions'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'support Missions'}\n",
      "Focus group discussions and key interviews were also held along with observation.\n",
      "Real:  {'Focus group discussions', 'key interviews'}\n",
      "OK:  {'Focus group discussions'}\n",
      "Not OK result:  {'interviews'}\n",
      "Not FOUND result:  {'key interviews'}\n",
      "These were reflected on the Project poster and brochure that were used for the duration of the Project and served to establish “SWSS” as a brand in its own right: e Project Tag Line: “Enabling communities to improve their health” e Project Vision: “Our mandate can be verified and will be realized as working when the following are accomplished: e Village councils take responsibility for maintaining clean water sources and monitor hygienic behavior and this continues after the completion of a subproject; e Household toilets of all types are used and safe; e¢ Communities become and remain open defecation free (ODF); e Each household uses and maintains a safe and clean place to go to the toilet; e Women’s groups promote health and hygiene education in communities; e Well users transport and handle their drinking water safely; and e¢ Communities recognize a reduction in waterborne diseases and health expenses.” The Project then focused on a very small set of key messages to enable consistency of communication.\n",
      "Real:  {'remain open defecation free (ODF)', 'transport and handle their drinking water safely', 'monitor hygienic behavior', 'maintaining clean water sources', 'toilet', 'Household toilets', 'promote health and hygiene education'}\n",
      "OK:  {'toilet', 'Household toilets'}\n",
      "Not OK result:  {'open defecation free (ODF)', 'communication', 'safe and clean place', 'health and hygiene education', 'drinking water safely'}\n",
      "Not FOUND result:  {'remain open defecation free (ODF)', 'transport and handle their drinking water safely', 'monitor hygienic behavior', 'maintaining clean water sources', 'promote health and hygiene education'}\n",
      "e Presented a peer reviewed paper at the WEDC conference in the United Kingdom in July on “Combining Sanitation and Hand Washing Promotion: An Example from Amhara, Ethiopia.” e Submitted abstracts on “Urban Fecal Sludge Management Solutions in Madagascar” and “Addressing the MDG Sanitation Gap: Lessons Learned from At-Scale Sanitation Promotion in Ethiopia,” which were presented as posters at the Water for Health conference in North Carolina in October.\n",
      "Real:  {'Urban Fecal Sludge Management', 'Sanitation and Hand Washing Promotion', 'At-Scale Sanitation Promotion'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Addressing the MDG Sanitation Gap', 'Fecal Sludge Management Solutions'}\n",
      "Not FOUND result:  {'Urban Fecal Sludge Management', 'Sanitation and Hand Washing Promotion', 'At-Scale Sanitation Promotion'}\n",
      "The most promising approaches involve community-based activities, creative use of food aid, and the improved multi-sectoral policy and planning that would arise from national and regional training.\n",
      "Real:  {'food aid', 'community-based activities', 'improved multi-sectoral policy and planning', 'national and regional training'}\n",
      "OK:  {'community-based activities', 'improved multi-sectoral policy and planning', 'national and regional training'}\n",
      "Not OK result:  {'creative use of food aid'}\n",
      "Not FOUND result:  {'food aid'}\n",
      "The primary objective of this study is to determine whether rainwater can be used as an alternative safe drinking water source in Girandurukotte area, Sri Lanka, which is known to be an area endemic for CKDu.\n",
      "Real:  {'rainwater'}\n",
      "OK:  set()\n",
      "Not OK result:  {'alternative safe drinking water source'}\n",
      "Not FOUND result:  {'rainwater'}\n",
      "Current armed conflict and fiscal restraints will make a large-scale land reform programme unworkable in the near future, but a peace package is likely to include a significant land access programme\n",
      "Real:  {'land reform programme', 'land access programme'}\n",
      "OK:  {'land access programme'}\n",
      "Not OK result:  {'make a large-scale land reform programme'}\n",
      "Not FOUND result:  {'land reform programme'}\n",
      "Sludge Management Options in Madagascar With the promise of improving public health and the environment, Practica’s study proposed innovative, lowcost, low-tech options for the safe disposal and management of fecal sludge.\n",
      "Real:  {'safe disposal and management of fecal sludge'}\n",
      "OK:  {'safe disposal and management of fecal sludge'}\n",
      "Not OK result:  {'Sludge Management', 'improving public health and the environment'}\n",
      "Not FOUND result:  set()\n",
      "These had eight associated criteria: (1) funds allocated for basic sanitation, (2) number of staff allocated to informal settlements, (3) disparities in access, (4) proportion of functioning sanitation facilities, (5) menstrual hygiene management (MHM) inclusion, (6) access to information, (7) meets users’ notions of dignity, and (8) integration of the perspectives of key stakeholders.\n",
      "Real:  {'basic sanitation', 'menstrual hygiene management (MHM) inclusion', 'integration of the perspectives of key stakeholders', 'access to information', 'sanitation facilities'}\n",
      "OK:  {'basic sanitation', 'access to information'}\n",
      "Not OK result:  {'proportion of functioning sanitation facilities', 'meets users’ notions', 'menstrual hygiene management (MHM)'}\n",
      "Not FOUND result:  {'integration of the perspectives of key stakeholders', 'sanitation facilities', 'menstrual hygiene management (MHM) inclusion'}\n",
      "Thus, it was necessary to investigate alternative ways to reconstruct the operation of the system and test the sensitivity of the system to various alternative operations.\n",
      "Real:  {'test the sensitivity of the system'}\n",
      "OK:  set()\n",
      "Not OK result:  {'alternative ways to reconstruct the operation of the system and test the sensitivity of the system'}\n",
      "Not FOUND result:  {'test the sensitivity of the system'}\n",
      "Water quality from RWH, however, depends on how well risk of contamination (ROC), from catchment to consumption, is managed.\n",
      "Real:  {'Water quality from RWH', 'risk of contamination (ROC)'}\n",
      "OK:  set()\n",
      "Not OK result:  {'catchment to consumption', 'Water quality from RWH, however'}\n",
      "Not FOUND result:  {'Water quality from RWH', 'risk of contamination (ROC)'}\n",
      "Catchments and aquatic ecosystems are under increasing pressure from a broad range of human activities, including urban growth, agricultural and industrial development, inadequate land use planning and management, land-based pollution, climate change, and poorly managed and overexploited fisheries and other aquatic resources.\n",
      "Real:  {'agricultural and industrial development'}\n",
      "OK:  {'agricultural and industrial development'}\n",
      "Not OK result:  {'land-based pollution', 'land use planning and management'}\n",
      "Not FOUND result:  set()\n",
      "Failure to account for such 'leakage' can upwardly bias econometric estimates of the effect of government fertiliser subsidy programmes on total fertiliser use.\n",
      "Real:  {'government fertiliser subsidy programmes'}\n",
      "OK:  set()\n",
      "Not OK result:  {'fertiliser subsidy programmes'}\n",
      "Not FOUND result:  {'government fertiliser subsidy programmes'}\n",
      "Morton Jaffray Water Treatment Works does not completely remove algae, and there is a carry-over of algae into the distribution system.\n",
      "Real:  {'distribution system', 'Morton Jaffray Water Treatment Works'}\n",
      "OK:  set()\n",
      "Not OK result:  {'Water Treatment Works'}\n",
      "Not FOUND result:  {'distribution system', 'Morton Jaffray Water Treatment Works'}\n",
      "Recommendations are future colonization projects are: better planning; additional research; less expensive infrastructure; more self-help measures; increased provision for spontaneous settlers; better interchange of information; and better publicity\n",
      "Real:  {'increased provision for spontaneous settlers', 'better interchange of information', 'self-help measures', 'better publicity'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'increased provision for spontaneous settlers', 'better interchange of information', 'self-help measures', 'better publicity'}\n",
      "The training/TA project has also taken other steps to facilitate the overall decentralization process, including: a \"Sharing Program\" by which city officials have the opportunity to learn about innovative techniques from the officials of other cities who have successfully implemented them; development of the national \"Urban Development Sector Review;\" and a program to train 15-20 NGO's in developing 200 sites for 10,000 households under the Community Mortgage Program\n",
      "Real:  {'decentralization process', 'Community Mortgage Program', 'training/TA project', 'Urban Development Sector Review'}\n",
      "OK:  {'Community Mortgage Program', 'training/TA project'}\n",
      "Not OK result:  {'development of the national \"Urban Development Sector Review', \"train 15-20 NGO's in developing 200 sites for 10,000 households\", 'facilitate the overall decentralization process'}\n",
      "Not FOUND result:  {'decentralization process', 'Urban Development Sector Review'}\n",
      "The tools are presented here as useful initial scoping instruments for use in advocacy around the need for a change in policy, funding, or indeed, a city’s overall approach to urban sanitation\n",
      "Real:  {'urban sanitation'}\n",
      "OK:  {'urban sanitation'}\n",
      "Not OK result:  {'scoping instruments', 'indeed'}\n",
      "Not FOUND result:  set()\n",
      "It is critical to develop a voluntary incentive program to induce a reduction in nitrogen fertilization levels that also avoids moral hazard and is politically acceptable to the farm community and legally enforceable.\n",
      "Real:  {'voluntary incentive program to induce a reduction in nitrogen fertilization levels that also avoids moral hazard and is politically acceptable to the farm community and legally enforceable'}\n",
      "OK:  set()\n",
      "Not OK result:  {'voluntary incentive program'}\n",
      "Not FOUND result:  {'voluntary incentive program to induce a reduction in nitrogen fertilization levels that also avoids moral hazard and is politically acceptable to the farm community and legally enforceable'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specifically, the report: (1) describes the three major nutritional deficiencies in Haiti (protein-energy malnutrition, vitamin A deficiency, and nutritional anemia) and the magnitude of these deficiencies, and identifies populations that are especially at risk; (2) describes the major factors related to these problems which may be susceptible to education interventions; (3) assesses related constraints to behavioral change (i.e., socioeconomic and attitudinal variables); (4) describes the five models of nutritional interventions currently used to assist Haitian preschoolers (targeted supplementation with education, nutrition programs integrated into survival programs, nutritional services integrated into health services, untargeted supplementation and education programs, and education-based programs with community participation); (5) develops a framework to assess these programs; (6) identifies potentially replicable educational/growth monitoring/promotion approaches; and (7) identifies gaps or problems in intervention strategies that might be filled by USAID/Haiti's future nutrition activities.\n",
      "Real:  {'nutrition activities', 'education interventions', 'untargeted supplementation and education programs', 'nutritional services integrated into health services', 'education-based programs with community participation', 'vitamin A deficiency', 'protein-energy malnutrition', 'nutrition programs integrated into survival programs', 'nutritional anemia', 'behavioral change', 'nutritional interventions', 'targeted supplementation with education'}\n",
      "OK:  {'nutrition activities', 'education interventions', 'behavioral change', 'targeted supplementation with education'}\n",
      "Not OK result:  {'education-based programs', 'health services', 'survival programs', 'nutritional services', 'nutrition programs', 'supplementation and education programs'}\n",
      "Not FOUND result:  {'untargeted supplementation and education programs', 'nutritional services integrated into health services', 'vitamin A deficiency', 'protein-energy malnutrition', 'nutrition programs integrated into survival programs', 'nutritional anemia', 'nutritional interventions', 'education-based programs with community participation'}\n",
      "To improve agro-tourism development and contribution to sustainable Bali economic growth, appropriate capacity building programs on agro-tourism for local community, supported by government budget and/or corporate social responsibility programs will be helpful and useful\n",
      "Real:  {'capacity building programs on agro-tourism'}\n",
      "OK:  set()\n",
      "Not OK result:  {'capacity building programs', 'social responsibility programs'}\n",
      "Not FOUND result:  {'capacity building programs on agro-tourism'}\n",
      "Based on outcomes of the workshop it was decided to create an online survey to capture more quantitative market data to integrate into the business plan to lay out the next steps which would be required to operationalize the ASA.\n",
      "Real:  {'online survey'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'online survey'}\n",
      "We recommend better digital data archiving with governmental water supply authorities and the assessment of potential well yields and sustainable yields\n",
      "Real:  {'assessment of potential well yields and sustainable yields', 'governmental water supply'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'assessment of potential well yields and sustainable yields', 'governmental water supply'}\n",
      "The City of Harare’s peri-urban settlement of Hopley predominantly uses pit latrines for excreta disposal.\n",
      "Real:  {'pit latrines', 'excreta disposal'}\n",
      "OK:  {'pit latrines'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'excreta disposal'}\n",
      "The papers included in this supplement address the following topics: effect of gasoline price on the buying habits of low-income, ethnically-diverse families in Southwest Michigan WIC programme; inclusion of older adults participating in the home-delivered meals programme in Northeast Georgia; sustainable agriculture; global movement to localizing our palate; perceived roles of fast foods and shokuiku in healthy and sustainable food practices in Japan; the implications for nutrition education of consumers globally sharing concerns about food; psychosocial impact of EFNEP training and work experience on the EFNEP paraprofessional; assessing the monthly food abundance-shortage cycle in food insecure overweight women; diet quality of Americans by SNAP participation status; perceived benefits and barriers to decreasing meat consumption and adopting a DASH-type diet among SNAP-eligible adults in Kalamazoo county; development of theory-based nutrition education curriculum to increase plant-based protein foods among SNAP-eligible adults; tailored nutrition intervention to reduce cardiovascular disease risk in low-income African American women; differences in lifestyle and dietary patterns among overweight/obese and normal BMI college students; ENAF diabetes module increases diabetes knowledge of older adults; older adult's attitudes and behaviours towards whole grain foods; an exercise education programme for people with diabetes; relationship between college students' eating competence and weight-related attitudes and behaviours; nutrition and lifestyle knowledge, attitudes and behaviours of student home economics teachers; association of sleep quality with eating behaviour in 18-24-year-old college students; length of time for cooking healthy meals; use of electronic group discussion method in assessing food-related educational needs among international college students; interteaching as a new innovative approach to facilitate university learning in the field of nutrition; relationship between food security and poor health among female WIC participants; link between emergency food programmes and fresh produce and quality nutrition services in New York City; international household food security measurement; inequalities in access to fruits and vegetables between low-income and middle-income region of the city of Atlanta, Georgia; educating consumers on how small changes add up; perspectives of food assistance programme personnel on utilizing GIS as a community food security tool; nutrition programme for Pre-K parents; mother's self-efficacy, picky eater perception, food choices and toddlers' fruit and vegetable consumption in low-income African American and Caucasian mothers; programme to reduce childhood obesity; household food security and fruit and vegetable intake among low-income fourth graders; mediation of behavioural outcomes in a middle school obesity risk reduction nutrition curriculum intervention; middle school students' reasons for selecting specific obesity risk reduction goals; development of a culinary intervention designed using the social cognitive theory to teach nutrition to adolescent girls; diet, nutrition and prevention of type 2 diabetes among Egyptian adolescents; excessive attention to food calories as a risk factor of eating disorders in teenagers; building collaboration to increase availability of fresh produce in a suburban emergency food system; factor analysis of EFNEP Behavior Checklist reveals six constructs; refrigerator and food thermometer use among households enrolled in EFNEP; comparison of factors influencing perceptions of body weight among diverse individuals receiving supplemental nutrition assistance programme benefits; food resource management education; Idaho's partnership for health promotion for the elderly; factors contributing to adoption and use of experiential foods curriculum; childhood hunger; promoting nutrition education and healthy lifestyles through teachable moments in Chicago community health centres; energy intake and overnight risk of full-term, low-income minority infants; maternal nutrition-related behaviours and infant health outcomes according to homeless and WIC participation status from 31 PRAMS states/cities; WIC toddlers offered a healthy start; three-year follow-up after \"Bring Some Fruit to School Study\"; and nutrition education programme \"Bring Some Fruit to School\"\n",
      "Real:  {'maternal nutrition-related behaviours', 'community food security tool', \"relationship between college students' eating competence and weight-related attitudes and behaviours\", 'emergency food system', 'supplemental nutrition assistance programme', 'picky eater perception', 'school obesity risk reduction nutrition curriculum intervention', \"mother's self-efficacy\", 'nutrition education programme', 'nutrition and lifestyle knowledge, attitudes and behaviours', 'healthy and sustainable food practices', 'inclusion of older adults participating in the home-delivered meals programme', 'assessing food-related educational needs', 'nutrition education', 'assessing the monthly food abundance-shortage cycle', 'development of theory-based nutrition education curriculum', 'food resource management education', 'international household food security measurement', 'food assistance programme', 'association of sleep quality with eating behaviour', 'quality nutrition services', 'programme to reduce childhood obesity', 'prevention of type 2 diabetes', 'increases diabetes knowledge of older adults', 'food choices', 'building collaboration', 'excessive attention to food calories', 'emergency food programmes', 'development of a culinary intervention', 'sustainable agriculture', 'health promotion', 'nutrition programme', \"older adult's attitudes and behaviours towards whole grain foods\", 'nutrition intervention', 'exercise education programme for people with diabetes', 'gasoline price'}\n",
      "OK:  {'assessing food-related educational needs', 'food resource management education', 'community food security tool', 'emergency food programmes', 'sustainable agriculture', 'health promotion', 'picky eater perception', 'assessing the monthly food abundance-shortage cycle', 'programme to reduce childhood obesity', 'nutrition and lifestyle knowledge, attitudes and behaviours', 'nutrition education programme', 'food choices'}\n",
      "Not OK result:  {'perspectives of food assistance programme personnel', 'increase plant-based protein foods', 'interteaching as a new innovative approach', 'theory-based nutrition education curriculum', 'sleep quality with eating behaviour', 'access to fruits', 'nutrition education of', 'nutrition programme for Pre-K parents', 'mediation of behavioural outcomes', 'nutrition assistance programme benefits', \"Idaho's partnership for\", 'work experience', 'building collaboration to increase availability of fresh', 'risk factor of eating disorders', 'graders', 'teenagers', 'facilitate university learning in the field of nutrition', 'nutrition and prevention of type', 'cardiovascular disease risk', 'suburban emergency food system', 'adoption and use of experiential foods curriculum', 'consumers globally sharing', 'sustainable food practices', 'promoting nutrition education', 'factor analysis', 'Southwest Michigan WIC programme', 'refrigerator and food thermometer use among households enrolled in EFNEP', 'length of time for cooking healthy meals', 'maternal nutrition-related behaviours and infant health outcomes', 'development of a culinary intervention designed', 'weight-related attitudes and behaviours'}\n",
      "Not FOUND result:  {'maternal nutrition-related behaviours', \"relationship between college students' eating competence and weight-related attitudes and behaviours\", 'emergency food system', 'supplemental nutrition assistance programme', 'school obesity risk reduction nutrition curriculum intervention', \"mother's self-efficacy\", 'healthy and sustainable food practices', 'inclusion of older adults participating in the home-delivered meals programme', 'nutrition education', 'development of theory-based nutrition education curriculum', 'international household food security measurement', 'food assistance programme', 'association of sleep quality with eating behaviour', 'quality nutrition services', 'prevention of type 2 diabetes', 'increases diabetes knowledge of older adults', 'building collaboration', 'excessive attention to food calories', 'development of a culinary intervention', 'nutrition programme', \"older adult's attitudes and behaviours towards whole grain foods\", 'nutrition intervention', 'exercise education programme for people with diabetes', 'gasoline price'}\n",
      "The study models farmer decision making regarding choice of best management practices (BMPs) under a US government programme of cross-compliance or integration of soil conservation programmes and farm income support programmes, including subsidized loan rates and target prices.\n",
      "Real:  {'soil conservation programmes', 'subsidized loan rates', 'farm income support programmes', 'target prices'}\n",
      "OK:  {'soil conservation programmes', 'farm income support programmes'}\n",
      "Not OK result:  {'government programme of cross-compliance or integration of'}\n",
      "Not FOUND result:  {'target prices', 'subsidized loan rates'}\n",
      "ASA would encourage 2 The term “academy” refers to an institution of higher learning, not in itself as extensive as a university, but one that draws together specialist expertise, gives its members the opportunity for indepth learning, promotes analysis, the exchange of ideas and encourages innovation.\n",
      "Real:  {'encourages innovation'}\n",
      "OK:  set()\n",
      "Not OK result:  {'institution of higher learning', 'promotes analysis'}\n",
      "Not FOUND result:  {'encourages innovation'}\n",
      "Implementation sequencing and confused roles and responsibilities: the differences between project management procedures (including the separate and non-pooled funding streams and subsequent reporting requirements) also served to pose some timing challenges on the ground.\n",
      "Real:  {'project management procedures', 'separate and non-pooled funding streams'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'separate and non-pooled funding streams', 'project management procedures'}\n",
      "The ill-provision of water and sanitation services poses the greatest risk to people living with HIV and AIDS in South Africa – a majority of whom reside in slum settlements.\n",
      "Real:  {'water and sanitation services'}\n",
      "OK:  set()\n",
      "Not OK result:  {'provision of water and sanitation services'}\n",
      "Not FOUND result:  {'water and sanitation services'}\n",
      "The study was designed for assessment of microbial diversity by culture-independent approaches placing emphasis on exploring the total coliform diversity in two drinking water reservoirs, Raman Pahad and Koilsagar of Mahabubnagar district, Telangana, India.\n",
      "Real:  {'assessment of microbial diversity', 'culture-independent approaches', 'drinking water reservoirs'}\n",
      "OK:  {'drinking water reservoirs'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'assessment of microbial diversity', 'culture-independent approaches'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main objective of this paper is to shed new light on such relationships by exploring organic producers' satisfaction from extension providers and their willingness to participate in agricultural education programmes.\n",
      "Real:  {'agricultural education programmes', \"exploring organic producers' satisfaction from extension providers\"}\n",
      "OK:  {'agricultural education programmes'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {\"exploring organic producers' satisfaction from extension providers\"}\n",
      "Economic opportunities were generated for business and small enterprise owners due to the new water supply infrastructure, and piped water infrastructure had additional positive effects for both public and private sanitation facilities\n",
      "Real:  {'public and private sanitation facilities', 'piped water infrastructure', 'new water supply infrastructure'}\n",
      "OK:  {'public and private sanitation facilities', 'piped water infrastructure'}\n",
      "Not OK result:  {'water supply infrastructure'}\n",
      "Not FOUND result:  {'new water supply infrastructure'}\n",
      "WALIS will provide support in the areas of financial management, personnel management, and planning.\n",
      "Real:  {'personnel management', 'planning', 'financial management'}\n",
      "OK:  {'personnel management', 'financial management'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'planning'}\n",
      "Page 16 of the 2015 Strategic Plan suggests that “ACWUA depends on available revenue streams comprising mainly training courses and O&M certification and training programs and consulting assignments, in addition to membership fees and grants from donor agencies and Arab governments...” Did ISWMR activities help in identifying these sources as main sources of revenue to ensure sustainability?\n",
      "Real:  {'training programs', 'membership fees and grants from donor agencies', 'O&M certification'}\n",
      "OK:  set()\n",
      "Not OK result:  {'training programs and consulting assignments', 'training courses', 'Did ISWMR activities'}\n",
      "Not FOUND result:  {'training programs', 'membership fees and grants from donor agencies', 'O&M certification'}\n",
      "The current status-quo therefore reflects a capacity gap amongst the set water point committees.\n",
      "Real:  {'water point committees'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'water point committees'}\n",
      "A high level of unsustainable properties (52%) was observed, indicating that the national Agrarian Reform Program is not being accompanied by technical training programs, does not stimulate a good sense of responsibility for small farmers and does not follow essential norms for food that aims ensure the safety of foods produced in sustainable environments\n",
      "Real:  {'technical training programs'}\n",
      "OK:  {'technical training programs'}\n",
      "Not OK result:  {'safety of foods produced in sustainable environments'}\n",
      "Not FOUND result:  set()\n",
      "Under agroforestry, the SP will: (1) help participants evaluate and improve land use; (2) demonstrate the multiple uses of trees, introduce fast-growing and disease-resistant tree varieties, and promote multi-purpose legumes; (3) promote soil stabilization and water conservation practices (e.g., windbreaks, live barriers, shade trees, and use of selective reforestation); (4) stimulate small agroforestry businesses by promoting the sale of fruit products and the use of ecologically sound commercial wood production and by improving pine resining techniques; and (5) solve water catchment and distribution problems by evaluating water entrapment options, identifying the land characteristics most favorable for constructing hand dug wells, and promoting construction of higher well walls and well covers to protect water sources from animal contamination and evaporation\n",
      "Real:  {'water catchment and distribution', 'water conservation', 'shade trees', 'hand dug wells', 'evaporation', 'live barriers', 'water entrapment', 'construction of higher well walls', 'windbreaks', 'selective reforestation', 'soil stabilization'}\n",
      "OK:  {'hand dug wells', 'live barriers', 'shade trees', 'windbreaks'}\n",
      "Not OK result:  {'water catchment and distribution problems', 'stimulate small agroforestry businesses', 'promoting the sale of fruit products and the use of ecologically sound commercial wood production', 'higher well walls and well covers', 'water conservation practices', 'protect water sources from animal contamination and evaporation', 'use of selective reforestation'}\n",
      "Not FOUND result:  {'water catchment and distribution', 'water conservation', 'water entrapment', 'evaporation', 'construction of higher well walls', 'selective reforestation', 'soil stabilization'}\n",
      "The next meeting will be hosted by USAID WASHPaLS, Arlington, VA. e Finally, for outreach and communications the Team started to have a presence in digital media.\n",
      "Real:  {'have a presence in digital media'}\n",
      "OK:  set()\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'have a presence in digital media'}\n",
      "The WIT project conducted interviews to help in scoring the CBOs that will partner with the Project to adopt the new water technologies within the targeted communities.\n",
      "Real:  {'adopt the new water technologies within the targeted communities', 'interviews'}\n",
      "OK:  {'interviews'}\n",
      "Not OK result:  {'help in scoring the CBOs', 'water technologies'}\n",
      "Not FOUND result:  {'adopt the new water technologies within the targeted communities'}\n",
      "However, more than 33.3% of rural water services in Ethiopia are not functioning and hence sustainability of rural drinking water points in the country is under question.\n",
      "Real:  {'rural water services', 'sustainability of rural drinking water points'}\n",
      "OK:  {'rural water services'}\n",
      "Not OK result:  {'hence sustainability of rural drinking water points'}\n",
      "Not FOUND result:  {'sustainability of rural drinking water points'}\n",
      "This paper also highlights differences amongst different ways to promote nutrition-sensitive agriculture through food-acquisition programs from family farmers, experiences in agro-ecology and bio-fortification programs.\n",
      "Real:  {'agro-ecology and bio-fortification programs', 'food-acquisition programs', 'promote nutrition-sensitive agriculture'}\n",
      "OK:  {'agro-ecology and bio-fortification programs', 'food-acquisition programs'}\n",
      "Not OK result:  {'nutrition-sensitive agriculture'}\n",
      "Not FOUND result:  {'promote nutrition-sensitive agriculture'}\n",
      "The farm management and records program will be extended initially to 40 farmers currently diversifying into asparagus production; the project studies component will examine the feasibility of selected crops in the Valley and devise an AAI development plan\n",
      "Real:  {'records program', 'farm management'}\n",
      "OK:  {'farm management'}\n",
      "Not OK result:  {'diversifying into asparagus production', 'AAI development plan'}\n",
      "Not FOUND result:  {'records program'}\n",
      "Water resources planning and management has evolved in the United States through several distinct stages over the past two centuries, transitioning from a concern for inland waterways transportation to single purpose flood control and finally to multiple purpose large reservoirs.\n",
      "Real:  {'reservoirs', 'inland waterways transportatio', 'Water resources planning and management', 'flood control'}\n",
      "OK:  {'reservoirs', 'Water resources planning and management', 'flood control'}\n",
      "Not OK result:  set()\n",
      "Not FOUND result:  {'inland waterways transportatio'}\n",
      "The village has been supported by a variety of external agents through agricultural development, natural resource management, and food security programs, including some large donor programs, and received in-kind support as well as direct agriculture input subsidies.\n",
      "Real:  {'agricultural developmen', 'direct agriculture input subsidies', 'food security programs', 'natural resource management', 'donor programs'}\n",
      "OK:  {'food security programs', 'natural resource management'}\n",
      "Not OK result:  {'agriculture input subsidies', 'agricultural development'}\n",
      "Not FOUND result:  {'direct agriculture input subsidies', 'donor programs', 'agricultural developmen'}\n",
      "Key informant interviews conducted revealed operational drought management challenges that emanate from communication barriers, coordination inconsistences, and undefined, unclear actor roles and responsibilities during disasters.\n",
      "Real:  {'drought management', 'Key informant interviews'}\n",
      "OK:  {'drought management', 'Key informant interviews'}\n",
      "Not OK result:  {'undefined'}\n",
      "Not FOUND result:  set()\n",
      "The goal of this paper is to evaluate the current inter-regional virtual water trade (VWT) structure and to assess the implications of these trade patterns for water use and water conservation strategies in China.\n",
      "Real:  {'inter-regional virtual water trade (VWT)', 'water use and water conservation strategies', 'trade patterns for water use'}\n",
      "OK:  set()\n",
      "Not OK result:  {'inter-regional virtual water trade (VWT) structure', 'water use', 'water conservation strategies'}\n",
      "Not FOUND result:  {'inter-regional virtual water trade (VWT)', 'water use and water conservation strategies', 'trade patterns for water use'}\n",
      "Had officials acted earlier and more aggressively to impose mandatory lawn watering restrictions and other proven water-saving strategies, the reservoir’s cool, dark waters would have been preserved over the buried stone structures during the drought\n",
      "Real:  {'water-saving strategies', 'buried stone structures during the drought', 'the reservoir’s cool, dark waters', 'impose mandatory lawn watering restrictions'}\n",
      "OK:  {'water-saving strategies'}\n",
      "Not OK result:  {'reservoir'}\n",
      "Not FOUND result:  {'impose mandatory lawn watering restrictions', 'buried stone structures during the drought', 'the reservoir’s cool, dark waters'}\n",
      "Recommended control strategies include cultural, chemical, and quarantine pest management programs and research emphasizing breeding for hostplant resistance and biological control.\n",
      "Real:  {'control strategies', 'pest management'}\n",
      "OK:  {'control strategies'}\n",
      "Not OK result:  {'cultural, chemical, and quarantine pest management programs'}\n",
      "Not FOUND result:  {'pest management'}\n",
      "In this study, the principles of water saving were determined by the evaluation of the water conservation programmes, xeriscape and irrigation systems in green space applications\n",
      "Real:  {'green space applications', 'water saving', 'irrigation systems', 'xeriscape', 'water conservation programmes'}\n",
      "OK:  {'green space applications', 'irrigation systems'}\n",
      "Not OK result:  {'evaluation of the water conservation programmes'}\n",
      "Not FOUND result:  {'water conservation programmes', 'water saving', 'xeriscape'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As noted by participants in the debriefing meeting in Evanston, part of the challenge around finding the matching funding was due to the timing, when economic downturns were causing organizations like Rotary to tap into their reserves to support commitments to grants programs.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'grants programs', 'tap into their reserves'}\n",
      "Not FOUND result:  set()\n",
      "There are, however, few studies of packaged water production.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'packaged water production'}\n",
      "Not FOUND result:  set()\n",
      "Prime contractors must write pesticide compliance requirements as set out above into each grant or subcontract that will involve support for pesticide use Develop or adapt existing record keeping land monitoring program.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'land monitoring program'}\n",
      "Not FOUND result:  set()\n",
      "Now that many women are taking the ARV AIDS drugs, even women who had previously stopped menstruating are now returning to their menses.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'ARV AIDS drugs'}\n",
      "Not FOUND result:  set()\n",
      "committees to resolve conflicts.3 UNDP Yemen is implementing a local governance program that focuses on community-based governance and developing community resilience.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'local governance program', 'community-based governance', 'developing community resilience'}\n",
      "Not FOUND result:  set()\n",
      "The Federal Democratic Republic of Ethiopia Rural Land Administration and Land Use Proclamation (Proclamation N0.456/2005) emphasizes the importance of sustainably conserving and developing natural resources and passing over to the coming generation through the development and implementation of a sustainable rural land use planning.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'sustainable rural land use planning', 'sustainably conserving'}\n",
      "Not FOUND result:  set()\n",
      "Increasingly the water and sanitation sectors are engaged in a debate about how best to ensure sustainable services at scale.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'water and sanitation sectors', 'sustainable services'}\n",
      "Not FOUND result:  set()\n",
      "This research examines the roles of two factors related to water quality, namely the quality of drinking water termed ‘water’ and the quality of sanitation termed ‘sanitation’.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'namely the quality of drinking water termed ‘water’', 'quality of sanitation termed ‘sanitation'}\n",
      "Not FOUND result:  set()\n",
      "Main question: What more can be done to increase sanitation and hygiene in your household and community and to ensure sustainable access to clean drinking water?\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'increase sanitation and hygiene', 'sustainable access to clean drinking water'}\n",
      "Not FOUND result:  set()\n",
      "The case of improved institutional delivery coverage over the course of the project is a prime example: community leaders became empowered following discussions on maternal and SRH, recognizing the power they have over maternal health outcomes, and established new community norms of adhering to HFs for antenatal care and institutional deliveries.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'improved institutional delivery coverage'}\n",
      "Not FOUND result:  set()\n",
      "According to the report, Madagascar and the Comoros suffer from substantial soil erosion and deforestation due to rising population densities and poor cultivation practices.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'Comoros suffer'}\n",
      "Not FOUND result:  set()\n",
      "In 2008 PSA conducted four city stakeholders’ consultation and planning workshops in Zamboanga City, Santa Rosa City, Cagayan de Oro City and Meycauayan City.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'workshops'}\n",
      "Not FOUND result:  set()\n",
      "The delineation workshop convened all key stakeholders in Mozambique, from the public sector (National Directorate for Environment (DINAB), the National Directorate for Spatial / Land Use Planning (DINOTER) and ANAC; civil society, including Centro Terra Viva and BirdLife International; the private sector, particularly the gas operators; and international representatives from the International Union for the Conservation of Nature (IUCN), the South African National Biodiversity Institute and the South African Institute for Aquatic Biodiversity.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'delineation workshop'}\n",
      "Not FOUND result:  set()\n",
      "A t-test revealed significant gender differences in grades 5–8 when many girls start to experience their menstrual cycle.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'grades 5–8'}\n",
      "Not FOUND result:  set()\n",
      "Both reports were only available in English thus limiting The Team commissioned French translations of both In addition to translating the reports, WWALIS RWSNISKAT colleagues to determine areas for JSR process of refining the JSR support fund concept note colleagues from USAID, SKAT, and WaterAid.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'JSR support fund', 'English thus limiting', 'translating the reports', 'determine areas for JSR process', 'WaterAid'}\n",
      "Not FOUND result:  set()\n",
      "6.2.7 HIGH LEVELS OF POVERTY AND LACK OF DIVERSE LIVELIHOODS Mali’s economy relies heavily on the use of natural resources and, between low-quality education facilities and conflict-driven instability, the prospects for significant poverty reduction and creation of diverse livelihoods are limited.\n",
      "Real:  set()\n",
      "OK:  set()\n",
      "Not OK result:  {'low-quality education facilities'}\n",
      "Not FOUND result:  set()\n"
     ]
    }
   ],
   "source": [
    "ner_model = spacy.load(\"../tmp/usaid_entity-recognition-model-more-2960\")\n",
    "for text, entities in EVAL_DATA:\n",
    "    res = set([ent.text for ent in ner_model(text).ents])\n",
    "    real = set([text[t[0]:t[1]] for t in entities[\"entities\"]])\n",
    "    if (len(res) == 0 and len(real) == 0) or (len(res.intersection(real)) == len(res.union(real))):\n",
    "        continue\n",
    "    print(text)\n",
    "    print(\"Real: \", real)\n",
    "    print(\"OK: \", res.intersection(real))\n",
    "    print('Not OK result: ', res - real)\n",
    "    print('Not FOUND result: ', real - res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background: The rapid global adoption of mobile health (mHealth) smartphone apps by healthcare providers presents challenges and opportunities in medicine.\n",
      "Entities []\n",
      "Challenges include ensuring the delivery of high-quality, up-to-date and optimised information.\n",
      "Entities [('ensuring the delivery of high-quality', 'OUTCOME')]\n",
      "Opportunities include the ability to study global practice patterns, access to medical and surgical care and continuing medical education needs.\n",
      "Entities []\n",
      "Methods: We studied users of a free anaesthesia calculator app used worldwide.\n",
      "Entities []\n",
      "We combined traditional app analytics with in-app surveys to collect user demographics and feedback.\n",
      "Entities []\n",
      "Results: 31173 subjects participated.\n",
      "Entities [('31173 subjects participated', 'OUTCOME')]\n",
      "Users were from 206 countries and represented a spectrum of healthcare provider roles.\n",
      "Entities []\n",
      "Low-income country users had greater rates of app use (p<0.001) and ascribed greater importance of the app to their practice (p<0.001).\n",
      "Entities []\n",
      "Physicians from low-income countries were more likely to adopt the app (p<0.001).\n",
      "Entities []\n",
      "The app was used primarily for paediatric patients.\n",
      "Entities []\n",
      "The app was used around the clock, peaking during times typical for first start cases.\n",
      "Entities []\n",
      "Conclusions: This mHealth app is a valuable decision support tool for global healthcare providers, particularly those in more resource-limited settings and with less training.\n",
      "Entities []\n",
      "App adoption and use may provide a mechanism for measuring longitudinal changes in access to surgical care and engaging providers in resource-limited settings.\n",
      "Entities [('engaging providers in resource-limited settings', 'OUTCOME')]\n",
      "In-app surveys and app analytics provide a window into healthcare provider behaviour at a breadth and level of detail previously impossible to achieve.\n",
      "Entities []\n",
      "Given the potentially immense value of crowdsourced information, healthcare providers should be encouraged to participate in these types of studies\n",
      "Entities []\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "for text in nltk.sent_tokenize(df[\"abstract\"].values[10]):\n",
    "    doc = ner_model(text)\n",
    "    print(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
